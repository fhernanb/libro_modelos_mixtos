[
<<<<<<< HEAD
["reg-diagnos.html", "6 DiagnÃ³stico del modelo de regresiÃ³n de efectos mixtos 6.1 Los residuos 6.2 Iniciando con el diagnÃ³stico: prueba de hipÃ³tesis e inferencia visual", " 6 DiagnÃ³stico del modelo de regresiÃ³n de efectos mixtos El diagnÃ³stico del modelo de regresiÃ³n es un mÃ©todo que permite determinar si un modelo de regresiÃ³n ajustado representa adecuadamente los datos. El objetivo de este capitulo consiste en introducir al lector los distintos mÃ©todos de diagnostico del modelo, los cuales permitiran identificar aquel modelo que represente sus datos con una mayor precisiÃ³n. 6.1 Los residuos Los residuos son la base de la mayorÃ­a de los mÃ©todos de diagnÃ³stico. Estos pueden ser de distinto tipo. Los residuos mÃ¡s bÃ¡sicos son los denominados residuos ordinarios, \\(\\hat{\\epsilon}_{i}\\), el cual se define como la diferencia entre el valor observado, \\(y_{i}\\), y su correspondiente valor estimado por el modelo, \\(\\hat{\\mu}_{i}\\), asÃ­: \\[\\begin{align*} \\hat{\\epsilon}_{i} = y_{i} - \\hat{\\mu}_{i}, i = 1, 2, ..., n \\end{align*}\\] donde \\(\\hat{\\mu}_{i}\\) es igual a \\(x^{&#39;}_{i}\\hat{\\beta}\\). A continuaciÃ³n, se presenta una representaciÃ³n grÃ¡fica de \\(\\hat{\\epsilon}_{i}\\): Figure 6.1: RepresentaciÃ³n grÃ¡fica de los residuos, del valor estimado y del valor observado. Luego los residuos ordinarios se escalan con el fin de que su interpretaciÃ³n no dependa de las unidades de medida de la variable dependiente. El proceso de estandarizaciÃ³n consiste en dividir el residuo ordinario, \\(\\hat{\\epsilon}_{i}\\), por la expresiÃ³n \\(\\sigma\\sqrt{(1-h_{i})}\\), donde \\({\\sigma}\\) corresponde a la desviaciÃ³n estandar verdadera y \\(h_{i}\\) al apalancamiento o valor de sombrero. Los residuos obtenidos de esta manera se denominan como residuos estandarizados. Sin embargo la verdadera desviaciÃ³n estÃ¡ndar rara vez se conoce. Por lo tanto, el escalado se puede realizar utilizando un estimador del mismo, es decir \\(\\hat{\\sigma}\\). Los residuos obtenidos de esta manera se denominan como residuos estudentizados, los cuales a su vez se dividen en dos: los residuos internamente estudentizados y los residuos externamente estudentizados. La tabla a continuaciÃ³n, resume las formas bÃ¡sicas de los residuos escalados: Formula matemÃ¡tica Estandarizado \\(\\frac{\\hat\\epsilon_i}{\\sigma\\sqrt{(1-h_i)}}\\) Internamente estudentizado \\(\\frac{\\hat\\epsilon_i}{\\hat\\sigma\\sqrt{(1-h_i)}}\\) Externamente estudentizado \\(\\frac{\\hat\\epsilon_i}{\\hat\\sigma_{(-i)}\\sqrt{(1-h_i)}}\\) * En el residuo internamente estudentizado, \\(\\hat\\sigma\\) denota una estimaciÃ³n de \\(\\sigma\\) basada en todas las observaciones; â€  En el residuo externamente estudentizado, \\(\\hat\\sigma_{(-i)}\\) es una estimaciÃ³n obtenida luego de excluir la i-Ã©sima observaciÃ³n de los cÃ¡lculos. Se usara la base de datos hsb del paquete merTools para entender mejor de que tratan los residuos, asÃ­ como tambiÃ©n los mÃ©todos de diagnosticos que explicaremos mÃ¡s adelante en este capitulo. A continuaciÃ³n podra ver la base de datos a usar: Se puede entender bien la lÃ³gica de los que son los residuos ajustando un modelo de regresiÃ³n simple. El diagnÃ³stico del modelo de regresiÃ³n aborda la adecuaciÃ³n de un modelo estadÃ­stico una vez se han ajustado los datos. De hecho, el ajuste de un modelo debe verse como un proceso iterativo en el que se ajusta el modelo, se evalÃºan sus residuos y se mejora. AsÃ­ hasta llegar a un modelo Ã³ptimo. Suponga que se quiere poner en relaciÃ³n dos variables: la variable \\(x_{1}\\) que representa el nivel socio-econÃ³mico de los alumnos (ses), y la variable \\(y\\), que es el rendimiento de los mismos alumnos en una prueba de matemÃ¡ticas (mathach). Para facilitar este anÃ¡lisis (y los posteriores) se asumira que \\(x_{1}\\) es una variable continua que toma valores entre -4 y +4, donde valores cercanos a 0 indican nivel socio-econÃ³mico medio, cercanos a +4 indican nivel socio-econÃ³mico alto y cercanos a -4 indican nivel socio-econÃ³mico bajo. El modelo de regresiÃ³n simple aplicado a este ejemplo se puede representar asÃ­: \\[\\begin{align} \\label{mod2} y_i &amp;\\sim N(\\mu_i, \\sigma^2), \\\\ \\mu_i &amp;= \\beta_0 + \\beta_1 x_{1i}, \\\\ \\sigma^2 &amp;= \\text{constante} \\end{align}\\] El codigÃ³ en R para ajustar el anterior modelo se presenta a continuaciÃ³n: Modelo_simple &lt;- lm(mathach ~ ses, data = hsb) #summary(Modelo_simple) Luego, los residuos (en este caso los residuos ordinarios) se pueden obtener con las siguientes funciones genericas: muestra_aleatoria$val_predicho &lt;- predict(Modelo_simple) muestra_aleatoria$res_ordinario &lt;- residuals(Modelo_simple) La grÃ¡fica a continuaciÃ³n presenta los valores observados y estimados en el rendimiento de los alumnos en una prueba de matemÃ¡ticas segÃºn su nivel socio-econÃ³mico, siendo la misma una representaciÃ³n grÃ¡fica similar a la presentada en la Figura 6.1: Tenga en cuenta que se bien el modelo se ajusto con las 7185 valores observados, la grÃ¡fica a continuaciÃ³n solo presenta 150 valores. Esto debido a que al no restringir por este valor, la grÃ¡fica se presentaba muy saturada de valores observados y estimados. Figure 6.2: Valores obserados y estimados en el rendimiento en una prueba matemÃ¡tica segÃºn el nivel socio-econÃ³mico del estudiante. La grÃ¡fica anterior representa la relaciÃ³n existente entre el rendimiento acadÃ©mico y el nivel socio-econÃ³mico del alumno. Claramente se puede observar que a mayor nivel socio-econÃ³mico, mejor es el rendimiento del alumno. Una vez ajustado el modelo de regresiÃ³n, y como se puede observar en la anterior grÃ¡fica, se tienen los valores observados (puntos con relleno), los valores estimados (puntos sin relleno) y el residuo (representado por una lÃ­nea vertical que une a los valores observados con los estimados). Por tanto, puede imaginar ahora que cada dato (valor observado) tiene un valor estimado y un residuo (residuo ordinario en este caso) como se detalla a continuaciÃ³n: Rendimiento real Rendimiento estimado Residuo ordinario 23.580 14.070564 9.509436 2.322 15.614683 -13.292683 2.006 9.673748 -7.667748 8.645 14.751023 -6.106023 Luego dichos residuos se consideran como elementos clave en la evaluaciÃ³n del modelo ajustado. Estos suelen emplearse en los mÃ©todos de diagnosticos del modelo de regresiÃ³n mediante pruebas de hipÃ³tesis acompaÃ±adas de inferencia visual (grÃ¡ficos). Por ejemplo, la figura a continuaciÃ³n muestra una de las grÃ¡ficas comunmente usadas en los mÃ©todos de diagnostico: Existe una gran variedad de grÃ¡ficos (como la presentada anteriormente) lo que refleja el hecho de que ningÃºn grÃ¡fico de diagnÃ³stico es apropiado para todos los propÃ³sitos. Veremos la interpretaciÃ³n de la misma con mÃ¡s detalle a continuaciÃ³n. 6.2 Iniciando con el diagnÃ³stico: prueba de hipÃ³tesis e inferencia visual Como es sabido, la inferencia estadÃ­stica clÃ¡sica consiste en formular inicialmente un juego de hipÃ³tesis (hipÃ³tesis nula y alternativa), y calcular posteriormente un estadÃ­stico de prueba del cual se deriva un valor p que permitira concluir en relaciÃ³n a las hipÃ³tesis planteadas. Este proceso tiene su anÃ¡logo en inferencia visual. Suponga que el interÃ©s consiste en verificar alguna suposiciÃ³n sobre el modelo ajustado: por ejemplo, la homogeneidad de la varianza residual. Para ello se plantea como hipÃ³tesis nula el cumplimiento de dicha homogeneidad, mientras que la hipÃ³tesis alternativa abarca cualquier violaciÃ³n de este supuesto. Para la inferencia visual, el estadÃ­stico de prueba corresponde a una grÃ¡fica que muestra un aspecto del supuesto que se desea verifcar, y permite al observador distinguir entre escenarios bajo la hipÃ³tesis nula y la alternativa. No obstante los mÃ©todos grÃ¡ficos permiten al analista descubrir no solo cuÃ¡ndo el modelo ajustado no cumple con el supuesto planteado, sino que tambiÃ©n permite detectar cuÃ¡l puede ser la causa del mismo, lo cual serÃ­a casi imposible a travÃ©s de unicamente pruebas de hipÃ³tesis. "]
=======
["index.html", "Modelos Mixtos con R Bienvenido Estructura del libro Software y convenciones Bloques informativos", " Modelos Mixtos con R Freddy HernÃ¡ndez Barajas Jorge Leonardo LÃ³pez MartÃ­nez 2020-02-18 Bienvenido Este libro estÃ¡ destinado para usuarios de R interesados en aplicar modelos mixtos. Freddy HernÃ¡ndez Barajas Jorge Leonardo LÃ³pez MartÃ­nez Estructura del libro En el capÃ­tulo 1 se hace un repaso bÃ¡sico del modelo de regresiÃ³n lineal clÃ¡sico. En el capÃ­tulo 2 se presentan los modelos mixtos. En el capÃ­tulo 3 se presenta el paquete lme4 y sus principales funciones para modelaciÃ³n, mientras que en el capÃ­tulo 4 se presenta el paquete nlme y sus principales funciones para modelaciÃ³n. Software y convenciones Para realizar este libro usamos los paquetes knitr (Xie 2015) y bookdown (Xie 2019) que permiten unir la ventajas de LaTeX y R en un mismo archivo. En todo el libro se presentarÃ¡n cÃ³digos que el lector puede copiar y pegar en su consola de R para obtener los mismos resultados aquÃ­ del libro. Los cÃ³digos se destacan en una caja de color similar a la mostrada a continuaciÃ³n. 4 + 6 a &lt;- c(1, 5, 6) 5 * a 1:10 Los resultados o salidas obtenidos de cualquier cÃ³digo se destacan con dos sÃ­mbolos de nÃºmeral (##) al inicio de cada lÃ­nea o renglÃ³n, esto quiere decir que todo lo que inicie con ## son resultados obtenidos y NO los debe copiar. Abajo se muestran los resultados obtenidos luego de correr el cÃ³digo anterior. ## [1] 10 ## [1] 5 25 30 ## [1] 1 2 3 4 5 6 7 8 9 10 Bloques informativos En varias partes del libro usaremos bloques informativos para resaltar algÃºn aspecto importante. Abajo se encuentra un ejemplo de los bloques y su significado. Nota aclaratoria. Sugerencia. Advertencia. References "],
["reg-lin.html", "1 RegresiÃ³n lineal 1.1 Modelo estadÃ­stico 1.2 Verosimilitud del modelo", " 1 RegresiÃ³n lineal En este capÃ­tulo se presenta el modelo de regresiÃ³n lineal clÃ¡sico. 1.1 Modelo estadÃ­stico El modelo estadÃ­stico en regresiÃ³n lineal clÃ¡sico permite modelar la media de una variable \\(Y\\) en funciÃ³n de \\(k\\) covariables. El modelo se puede expresar como sigue. \\[\\begin{align} \\label{mod2} y_i &amp;\\sim N(\\mu_i, \\sigma^2), \\\\ \\mu_i &amp;= \\beta_0 + \\beta_1 x_{1i} + \\beta_2 x_{2i} + \\cdots + \\beta_k x_{ki}, \\\\ \\sigma^2 &amp;= \\text{constante} \\end{align}\\] donde \\(i=1, 2, \\ldots, n\\) es el Ã­ndice que identifica las \\(n\\) observaciones del conjunto de entrenamiento. El vector de parÃ¡metros del modelo es \\(\\boldsymbol{\\theta}=(\\beta_0, \\beta_1, \\cdots, \\beta_k, \\sigma)^\\top\\). 1.2 Verosimilitud del modelo La funciÃ³n de verosimilitud \\(L\\) para el modelo es la siguiente: \\[ L(\\boldsymbol{\\theta}) = \\prod_i^n f(y_i \\vert \\beta_0, \\beta_1, \\cdots, \\beta_k, \\sigma), \\] donde \\(f\\) corresponde a la funciÃ³n de densidad de la normal. Para estimar el vector de parÃ¡metros \\(\\boldsymbol{\\theta}\\) del modelo se usa el mÃ©todo de MÃ¡xima Verosimilitud sobre la funciÃ³n \\(L\\) o sobre la funciÃ³n de log-verosimilitud siguiente: \\[ l(\\boldsymbol{\\theta}) = \\sum_i^n \\log(f(y_i \\vert \\beta_0, \\beta_1, \\cdots, \\beta_k, \\sigma)), \\] Ejemplo Como ilustraciÃ³n vamos a usar los datos del ejemplo 3.1 del libro de Montgomery, Peck and Vining (2003). En el ejemplo 3.1 los autores ajustaron un modelo de regresiÃ³n lineal mÃºltiple para explicar el Tiempo necesario para que un trabajador haga el mantenimiento y surta una mÃ¡quina dispensadora de refrescos en funciÃ³n de las variables NÃºmero de Cajas y Distancia. Los datos del ejemplo estÃ¡n disponibles en el paquete MPV (por los apellidos de los autores). A continuaciÃ³n el cÃ³digo para cargar los datos y una muestra de las 6 primeras observaciones de la base de datos, en total se disponen de 20 observaciones. require(MPV) colnames(softdrink) &lt;- c(&#39;tiempo&#39;, &#39;cantidad&#39;, &#39;distancia&#39;) head(softdrink) ## tiempo cantidad distancia ## 1 16.68 7 560 ## 2 11.50 3 220 ## 3 12.03 3 340 ## 4 14.88 4 80 ## 5 13.75 6 150 ## 6 18.11 7 330 Un grÃ¡fico en 3d es obligratorio para explorar la relaciÃ³n entre las variables, este diagrama de puede obtener usando el paquete scatterplot3d. A continuaciÃ³n el cÃ³digo para construirlo. library(scatterplot3d) attach(softdrink) scatterplot3d(x=cantidad, y=distancia, z=tiempo, pch=16, cex.lab=1, highlight.3d=TRUE, type=&quot;h&quot;, xlab=&#39;Cantidad de cajas&#39;, ylab=&#39;Distancia (pies)&#39;, zlab=&#39;Tiempo (min)&#39;) De la figura anterior se ve claramente que a medida que aumenta el nÃºmero de cajas y la distancia los tiempos tienden a ser mayores. A continuaciÃ³n se define la funciÃ³n de menos log-verosimilitud para el modelo anterior. A pesar de que nos interesa maximizar la funciÃ³n de log-verosimilitud hemos creado su negativo, esto porque la mayorÃ­a de las funciones de optimizaciÃ³n minimizan y no maximizan; maximizar \\(f(x)\\) es equivalente a minimizar \\(-f(x)\\). minusll &lt;- function(theta, y, x1, x2) { media &lt;- theta[1] + theta[2] * x1 + theta[3] * x2 # Se define la media desvi &lt;- theta[4] # Se define la desviaciÃ³n. - sum(dnorm(x=y, mean=media, sd=desvi, log=TRUE)) } Ahora vamos a usar la funciÃ³n optim para encontrar los valores que maximizan la funciÃ³n de log-verosimilitud, el cÃ³digo para hacer eso se muestra a continuaciÃ³n. En el parÃ¡metro par se coloca un vector de posibles valores de \\(\\boldsymbol{\\Theta}\\) para iniciar la bÃºsqueda, en fn se coloca la funciÃ³n de interÃ©s, en lower y upper se colocan vectores que indican los lÃ­mites de bÃºsqueda de cada parÃ¡metro, los \\(\\beta_k\\) pueden variar entre \\(-\\infty\\) y \\(\\infty\\) mientras que el parÃ¡metro \\(\\sigma\\) toma valores en el intervalo \\((0, \\infty)\\). Como la funciÃ³n minusll tiene argumentos adicionales y, x1 y x2, estos pasan a la funciÃ³n optim al final como se muestra en el cÃ³digo. mod1 &lt;- optim(par=c(0, 0, 0, 1), fn=minusll, method=&#39;L-BFGS-B&#39;, lower=c(-Inf, -Inf, -Inf, 0), upper=c(Inf, Inf, Inf, Inf), y=softdrink$tiempo, x1=softdrink$cantidad, x2=softdrink$distancia) En el objeto res1 estÃ¡ el resultado de la optimizaciÃ³n, para explorar los resultados usamos mod1 ## $par ## [1] 2.34103296 1.61590757 0.01438512 3.05769678 ## ## $value ## [1] 63.41469 ## ## $counts ## function gradient ## 58 58 ## ## $convergence ## [1] 0 ## ## $message ## [1] &quot;CONVERGENCE: REL_REDUCTION_OF_F &lt;= FACTR*EPSMCH&quot; De esta forma el vector de parÃ¡metros estimados del modelo es \\(\\hat{\\boldsymbol{\\theta}}=(2.34, 1.62, 0.01, 3.06)^\\top\\). Usualmente en la prÃ¡ctica se usa la funciÃ³n lm para estimar el vector de parÃ¡metros, a continuaciÃ³n el cÃ³digo necesario para usar la funcion lm. mod2 &lt;- lm(tiempo ~ cantidad + distancia, data=softdrink) summary(mod2) ## ## Call: ## lm(formula = tiempo ~ cantidad + distancia, data = softdrink) ## ## Residuals: ## Min 1Q Median 3Q Max ## -5.7880 -0.6629 0.4364 1.1566 7.4197 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 2.341231 1.096730 2.135 0.044170 * ## cantidad 1.615907 0.170735 9.464 3.25e-09 *** ## distancia 0.014385 0.003613 3.981 0.000631 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 3.259 on 22 degrees of freedom ## Multiple R-squared: 0.9596, Adjusted R-squared: 0.9559 ## F-statistic: 261.2 on 2 and 22 DF, p-value: 4.687e-16 De la salida anterior vemos que el vector de parÃ¡metros estimados del modelo es \\(\\hat{\\boldsymbol{\\theta}}=(2.34, 1.62, 0.01, 3.26)^\\top\\). Para profundizar en el modelo de regresion lineal se recomienda consultar libro Modelos de RegresiÃ³n con R "],
["mod-mix.html", "2 Modelos Mixtos", " 2 Modelos Mixtos Los modelos mixtos fueron propuestos por (Laird and Ware 1982) y en ellos se asume que existe una relaciÃ³n entre el vector de observaciones \\(\\boldsymbol{Y}_i\\) del sujeto o grupo \\(i\\) y las covariables por medio de la siguiente expresiÃ³n \\[\\begin{equation} \\begin{aligned} \\label{mixedmodel1} \\boldsymbol{Y}_i \\mid \\boldsymbol{b}_i &amp;\\sim \\mathcal{N}(\\boldsymbol{X}_i \\boldsymbol{\\beta} + \\boldsymbol{Z}_i \\boldsymbol{b}_i, \\boldsymbol{\\Sigma}_i), \\\\ \\boldsymbol{b}_i &amp;\\sim \\mathcal{N}(\\boldsymbol{0}, \\boldsymbol{D}), \\end{aligned} \\end{equation}\\] donde \\(\\boldsymbol{X}_i\\) y \\(\\boldsymbol{Z}_i\\) son matrices de diseÃ±o conocidas con la informaciÃ³n de las covariables, siendo \\(\\boldsymbol{X}_i\\) de dimensiÃ³n \\(n_i \\times p\\) y \\(\\boldsymbol{Z}_i\\) de dimensiÃ³n \\(n_i \\times q\\). El elemento \\(\\boldsymbol{\\beta}\\) representa el vector de efectos fijos general, \\(\\boldsymbol{b}_i\\) el vector de efectos aleatorios exclusivos para el grupo \\(i\\) y las matrices. El vector \\(\\boldsymbol{b}_i\\) en la expresiÃ³n es llamado efecto aleatorio porque Ã©ste cambia la media de sujeto a sujeto y su funciÃ³n es la de mejorar el ajuste general dado por el elemento \\(\\boldsymbol{X}_i \\boldsymbol{\\beta}\\) al agregar la cantidad \\(\\boldsymbol{Z}_i \\boldsymbol{b}_i\\). El modelo dado en la expresiÃ³n es llamado tambiÃ©n modelo mixto porque involucra tanto efectos fijos (\\(\\boldsymbol{\\beta}\\)) como efectos aleatorios (\\(\\boldsymbol{b}_i\\)). La distribuciÃ³n marginal de \\(\\boldsymbol{Y}_i\\) estÃ¡ dada por \\[\\begin{equation} f_i(\\boldsymbol{Y}_i) = \\int f(\\boldsymbol{Y}_i | \\boldsymbol{b}_i) f(\\boldsymbol{b}_i) \\, d \\boldsymbol{b}_i \\end{equation}\\] donde \\(f(\\boldsymbol{Y}_i | \\boldsymbol{b}_i)\\) y \\(f(\\boldsymbol{b}_i)\\) corresponden a las densidades normales mostradas en la expresiÃ³n . Esta distribuciÃ³n marginal tiene forma cerrada y se puede mostrar fÃ¡cilmente que la distribuciÃ³n de \\(\\boldsymbol{Y}_i\\) es una normal multivariada con vector de medias y matriz de covarianzas como se muestra a continuaciÃ³n. \\[\\begin{equation} \\boldsymbol{Y}_i \\sim \\mathcal{N}(\\boldsymbol{X}_i \\boldsymbol{\\beta}, \\boldsymbol{V}_i), \\end{equation}\\] donde \\(\\boldsymbol{V}_i=\\boldsymbol{Z}_i \\boldsymbol{D} \\boldsymbol{Z}_i^\\top + \\boldsymbol{\\Sigma}_i\\). El vector de parÃ¡metros en este caso es \\(\\boldsymbol{\\theta}=(\\boldsymbol{\\beta}, \\boldsymbol{\\alpha})^\\top\\) donde \\(\\boldsymbol{\\alpha}\\) consiste de los \\(q(q+1)/2\\) elementos diferentes de la matriz \\(\\boldsymbol{D}\\) y todos los elementos de la matriz \\(\\boldsymbol{\\Sigma}_i\\). References "],
["pac-lme4.html", "3 Paquete lme4 3.1 FunciÃ³n lmer Ejemplo: modelo con intercepto aleatorio", " 3 Paquete lme4 El paquete lme4 (Bates et al. 2019) es uno de los paquetes mÃ¡s completos para modelos mixtos. Al visitar este enlace se encontrarÃ¡ la pÃ¡gina de apoyo del paquete, allÃ­ se puede consultar el manual de referencia y las viÃ±etas. 3.1 FunciÃ³n lmer La funciÃ³n lmer es la principal funciÃ³n del paquete (Bates et al. 2019). Esta funciÃ³n sirve para ajustar un modelo mixto y su estructura es la siguiente: lmer(formula, data = NULL, REML = TRUE, control = lmerControl(), start = NULL, verbose = 0L, subset, weights, na.action, offset, contrasts = NULL, devFunOnly = FALSE, ...) Los principales argumentos de la funciÃ³n son: formula: es una fÃ³rmula similar a la usada en el modelo lineal clÃ¡sico. Un ejemplo de fÃ³rmula serÃ­a y ~ 1 + x1 + x2 + (1 + x2) con la cual se indican los efectos fijos y los efectos aleatorios del modelo. MÃ¡s abajo hay una tabla con mÃ¡s detalles sobre la fÃ³rmula. data: marco de datos donde estÃ¡n las variables. REML: valor lÃ³gico que sirve para indicar si queremos estimaciones maximizando la verosimilitud restringida o la verosimilitud usual. La siguiente imagen corresponde a la tabla 2 de la viÃ±eta Fitting Linear Mixed-Effects Models using lme4. En esa tabla las dos primeras columnas muestran formas equivalentes de incluir las estructuras de modelos mixtos mÃ¡s comunes. Ejemplo: modelo con intercepto aleatorio En este ejemplo vamos a simular observaciones \\(ni=50\\) observaciones para \\(G=10\\) grupos (en total 500 obs) que tengan la estructura mostrada abajo. El objetivo del ejemplo es ilustrar el uso de la funciÃ³n lmer para estimar los parÃ¡metros del modelo. \\[\\begin{align*} y_{ij} &amp;\\sim N(\\mu_{ij}, \\sigma^2_y) \\\\ \\mu_{ij} &amp;= 4 - 6 x_{ij} + b_{0i} \\\\ \\sigma^2_y &amp;= 16 \\\\ b_{0} &amp;\\sim N(0, \\sigma^2_{b0}=625) \\\\ x_{ij} &amp;\\sim U(-5, 6) \\end{align*}\\] El vector de parÃ¡metros de este modelo es \\(\\boldsymbol{\\Theta}=(\\beta_0=4, \\beta_1=-6, \\sigma_y=4, \\sigma_{bo}=25)^\\top\\). SoluciÃ³n El cÃ³digo para simular las 500 observaciones se muestra a continuaciÃ³n. Observe que se fijÃ³ la semilla en dos ocasiones para que el lector pueda replicar el ejemplo y obtener los mismos resultados. ni &lt;- 50 G &lt;- 10 nobs &lt;- ni * G grupo &lt;- factor(rep(x=1:G, each=ni)) obs &lt;- rep(x=1:ni, times=G) set.seed(1234567) x &lt;- runif(n=nobs, min=-5, max=6) b0 &lt;- rnorm(n=G, mean=0, sd=sqrt(625)) # Intercepto aleatorio b0 &lt;- rep(x=b0, each=ni) # El mismo intercepto aleatorio pero repetido media &lt;- 4 - 6 * x + b0 set.seed(123456) y &lt;- rnorm(n=nobs, mean=media, sd=sqrt(16)) datos &lt;- data.frame(grupo, obs, b0, x, media, y) El siguiente paso es dibujar los datos para explorar si serÃ­a apropiado usar un modelo con intercepto aleatorio (obvio porque asÃ­ se simularon los datos). El cÃ³digo para dibujar los datos se muestra abajo. library(ggplot2) ggplot(datos, aes(x, y, color=grupo) ) + geom_point() + labs(colour=&quot;Grupo/Cluster&quot;) En la figura anterior se observa un patrÃ³n claro, todas las 10 nubes de puntos tienen la misma pendiente pero diferente intercepto con el eje vertical, eso se debe a que en la simulaciÃ³n se incluyÃ³ un \\(b_0\\). Para estimar los parÃ¡metros del modelos se usa la funciÃ³n mler de la siguiente forma. library(lme4) fit &lt;- lmer(y ~ x + (1 | grupo), data=datos) La funciÃ³n summary se puede usar sobre el objeto fit para obtener una tabla de resumen, a continuaciÃ³n se ilustra el uso y la salida de summary. summary(fit) SegÃºn el resultado anterior \\(\\hat{\\boldsymbol{\\Theta}}=(\\hat{\\beta}_0=3.53363, \\hat{\\beta}_1=-5.97805, \\hat{\\sigma}_y=4.012, \\hat{\\sigma}_{bo}=21.507)^\\top\\) mientras que el vector real de parÃ¡metros es \\(\\boldsymbol{\\Theta}=(\\beta_0=4, \\beta_1=-6, \\sigma_y=4, \\sigma_{bo}=25)^\\top\\). Compare los resultados de la tabla anterior obtenida con la funciÃ³n lmer anterior con los resultados obtenidos con la funciÃ³n lme de capÃ­tulo 4. Â¿Hay alguna similitud? References "],
["pac-nlme.html", "4 Paquete nlme 4.1 FunciÃ³n lme Ejemplo: modelo con intercepto aleatorio", " 4 Paquete nlme El paquete nlme (Pinheiro, Bates, and R-core 2019) es otro de los paquetes para modelos mixtos. Al visitar este enlace se encontrarÃ¡ la pÃ¡gina de apoyo del paquete, allÃ­ se puede consultar el manual de referencia. 4.1 FunciÃ³n lme La funciÃ³n lme es la principal funciÃ³n del paquete (Pinheiro, Bates, and R-core 2019). Esta funciÃ³n sirve para ajustar un modelo mixto y su estructura es la siguiente: lme(fixed, data, random, correlation, weights, subset, method, na.action, control, contrasts = NULL, keep.data = TRUE) Los principales argumentos de la funciÃ³n son: formula: es una fÃ³rmula similar a la usada en el modelo lineal clÃ¡sico. Un ejemplo de fÃ³rmula serÃ­a y ~ 1 + x1 + x2 con la cual se indican los efectos fijos del modelo. data: marco de datos donde estÃ¡n las variables. random: es una fÃ³rmula solo con lado derecho. Si queremos indicar intercepto aleatorio se escribe ~ 1 | group y si se desea intercepto y pendiente aleatoria se escribe ~ 1 + x2 | group. correlation: es un parÃ¡metro opcional para indicar la estructura de correlaciÃ³n entre las observaciones de cada grupo. Para mÃ¡s detalles consulte la ayuda de la funciÃ³n corClasses. method: valor lÃ³gico que sirve para indicar si queremos estimaciones maximizando la verosimilitud restringida o la verosimilitud usual, las dos opciones son ML o REML. Ejemplo: modelo con intercepto aleatorio En este ejemplo vamos a simular observaciones \\(ni=50\\) observaciones para \\(G=10\\) grupos (en total 500 obs) que tengan la estructura mostrada abajo. El objetivo del ejemplo es ilustrar el uso de la funciÃ³n lmer para estimar los parÃ¡metros del modelo. \\[\\begin{align*} y_{ij} &amp;\\sim N(\\mu_{ij}, \\sigma^2_y) \\\\ \\mu_{ij} &amp;= 4 - 6 x_{ij} + b_{0i} \\\\ \\sigma^2_y &amp;= 16 \\\\ b_{0} &amp;\\sim N(0, \\sigma^2_{b0}=625) \\\\ x_{ij} &amp;\\sim U(-5, 6) \\end{align*}\\] El vector de parÃ¡metros de este modelo es \\(\\boldsymbol{\\Theta}=(\\beta_0=4, \\beta_1=-6, \\sigma_y=4, \\sigma_{b0}=25)^\\top\\). SoluciÃ³n El cÃ³digo para simular las 500 observaciones se muestra a continuaciÃ³n. Observe que se fijÃ³ la semilla en dos ocasiones para que el lector pueda replicar el ejemplo y obtener los mismos resultados. ni &lt;- 50 G &lt;- 10 nobs &lt;- ni * G grupo &lt;- factor(rep(x=1:G, each=ni)) obs &lt;- rep(x=1:ni, times=G) set.seed(1234567) x &lt;- runif(n=nobs, min=-5, max=6) b0 &lt;- rnorm(n=G, mean=0, sd=sqrt(625)) # Intercepto aleatorio b0 &lt;- rep(x=b0, each=ni) # El mismo intercepto aleatorio pero repetido media &lt;- 4 - 6 * x + b0 set.seed(123456) y &lt;- rnorm(n=nobs, mean=media, sd=sqrt(16)) datos &lt;- data.frame(grupo, obs, b0, x, media, y) El siguiente paso es dibujar los datos para explorar si serÃ­a apropiado usar un modelo con intercepto aleatorio (obvio porque asÃ­ se simularon los datos). El cÃ³digo para dibujar los datos se muestra abajo. library(ggplot2) ggplot(datos, aes(x, y, color=grupo) ) + geom_point() + labs(colour=&quot;Grupo/Cluster&quot;) En la figura anterior se observa un patrÃ³n claro, todas las 10 nubes de puntos tienen la misma pendiente pero diferente intercepto con el eje vertical, eso se debe a que en la simulaciÃ³n se incluyÃ³ un \\(b_0\\). Para estimar los parÃ¡metros del modelos se usa la funciÃ³n mler de la siguiente forma. library(nlme) fit &lt;- lme(y ~ x, random = ~ 1 | grupo, data=datos) La funciÃ³n summary se puede usar sobre el objeto fit para obtener una tabla de resumen, a continuaciÃ³n se ilustra el uso y la salida de summary. summary(fit) SegÃºn el resultado anterior \\(\\hat{\\boldsymbol{\\Theta}}=(\\hat{\\beta}_0=3.533631, \\hat{\\beta}_1=-5.978053, \\hat{\\sigma}_y=4.01157, \\hat{\\sigma}_{b0}=21.50711)^\\top\\) mientras que el vector real de parÃ¡metros es \\(\\boldsymbol{\\Theta}=(\\beta_0=4, \\beta_1=-6, \\sigma_y=4, \\sigma_{b0}=25)^\\top\\). Compare los resultados de la tabla anterior obtenida con la funciÃ³n lme anterior con los resultados obtenidos con la funciÃ³n lmer de capÃ­tulo 3. Â¿Hay alguna similitud? References "],
["ph.html", "5 Pruebas de hipÃ³tesis 5.1 Prueba razÃ³n de verosimilitud 5.2 Prueba de Wald 5.3 Prueba de hipÃ³tesis sobre los efectos fijos 5.4 Prueba de hipÃ³tesis sobre componentes de varianza Ejercicios", " 5 Pruebas de hipÃ³tesis En este capÃ­tulo se muestran las pruebas de hipÃ³tesis para comparar modelo mixtos. 5.1 Prueba razÃ³n de verosimilitud Supongamos que queremos estudiar \\(H_0: \\theta \\in \\boldsymbol{\\Theta}_0\\) versus \\(H_A: \\theta \\in \\boldsymbol{\\Theta}\\). La prueba razÃ³n de verosimilitud (\\(LR\\)) para \\(H_0\\) estÃ¡ dada por: \\[ LR = -2 \\log \\left( \\frac{ sup_{\\theta \\in \\boldsymbol{\\Theta}_0} L(\\theta)}{ sup_{\\theta \\in \\boldsymbol{\\Theta}} L(\\theta)} \\right) \\] Usualmente la prueba de razÃ³n de verosimilitud se expresa en funciÃ³n de los valores de log-verosimilitud del modelo asi: \\[ LR = -2 ( l(\\Theta_0) - l(\\hat{\\Theta}) ) \\] y el estadÃ­stico \\(LR \\sim \\chi^2_{k-k_0}\\), donde \\(k\\) es el nÃºmero de parÃ¡metros del modelo estimado y \\(k_0\\) el nÃºmero de parÃ¡metros del modelo asumiendo \\(H_0\\) verdadera. 5.2 Prueba de Wald Si el interÃ©s es estudiar \\(H_0: \\beta_k = \\beta_{k0}\\) contra \\(H_A: \\beta_k \\neq \\beta_{k0}\\) se puede usar la prueba de Wald que tiene el siguiente estadÃ­stico: \\[ t = \\frac{\\hat{\\beta}_k - \\beta_{k0}}{se(\\hat{\\beta}_k)}, \\] donde \\(se(\\hat{\\beta}_k)\\) corresponde al error estÃ¡ndar de la estimaciÃ³n \\(\\hat{\\beta}_k\\), todo esto disponible en el summary del modelo ajustado. Si \\(H_0\\) es verdadera, \\(t \\sim t_{n-p}\\), siendo \\(n\\) el nÃºmero de observaciones y \\(p\\) el nÃºmero de efectos fijos estimados (no el nÃºmero de variables) en el modelo. 5.3 Prueba de hipÃ³tesis sobre los efectos fijos La prueba razÃ³n de verosimilitud puede ser usada para comparar modelos ajustados por el mÃ©todo ML y que difieran en su estructura de efectos fijos, pero con la mismas componentes de varianza. Los valores-P de la prueba pueden ser anticonservativos, es decir, mÃ¡s pequeÃ±os de lo normal y por lo tanto se podrÃ­a rechazar \\(H_0\\) mÃ¡s fÃ¡cilmente (Pinheiro and Bates 2000). En lugar de usar la distribuciÃ³n \\(\\chi^2\\) para el estadÃ­stico de la prueba razÃ³n de verosimilitud, se recomienda usar la distribuciÃ³n empÃ­rica del estadÃ­stico, obtenida al ajustar los modelos nulo y alternativo con mÃºltiples conjuntos de datos simulados (Galecki and Burzykowski 2012). Ejemplo La base de datos ChickWeight contiene informaciÃ³n sobre el peso de un grupo de pollos versus el tiempo bajo diferentes dietas. Abajo una ilustraciÃ³n de los datos. library(ggplot2) ggplot(data = ChickWeight, aes(x = Time, y = weight, color = Diet)) + geom_point() + theme_bw() + facet_wrap(~ Chick) El objetivo es comparar los siguientes dos modelos. Modelo 1 \\[\\begin{align*} Weight_{ij} &amp;\\sim N(\\mu_{ij}, \\sigma^2_{weight}) \\\\ \\mu_{ij} &amp;= \\beta_0 + \\beta_1 tiempo_{ij} + b_{0i} \\\\ b_{0} &amp;\\sim N(0, \\sigma^2_{b0}) \\end{align*}\\] Modelo 2 \\[\\begin{align*} Weight_{ij} &amp;\\sim N(\\mu_{ij}, \\sigma^2_{weight}) \\\\ \\mu_{ij} &amp;= \\beta_0 + \\beta_1 tiempo_{ij} + \\beta_2 dieta2_{i} + \\beta_3 dieta3_{i} + \\beta_4 dieta4_{i} + b_{0i} \\\\ b_{0} &amp;\\sim N(0, \\sigma^2_{b0}) \\end{align*}\\] SoluciÃ³n El problema de este ejercicio se puede resumir con \\(H_0:\\) la variable Dieta no aporta al modelo, versus, \\(H_A:\\) la variable Dieta si aporta al modelo. Para ajustar ambos modelos se usa el siguiente cÃ³digo. library(nlme) mod1 &lt;- lme(weight ~ Time, data = ChickWeight, random = ~ 1 | Chick, method=&#39;ML&#39;) mod2 &lt;- lme(weight ~ Time + Diet, data = ChickWeight, random = ~ 1 | Chick, method=&#39;ML&#39;) Para calcular la prueba razÃ³n de verosimilitud se usa el siguiente cÃ³digo. lrt &lt;- -2 * (logLik(mod1) - logLik(mod2)) lrt ## &#39;log Lik.&#39; 17.14349 (df=4) pchisq(q=lrt, df=7-4, lower.tail=FALSE) ## &#39;log Lik.&#39; 0.000660304 (df=4) De la salida anterior se tiene que el valor-P = 0.000660304 y menor que cualquier \\(\\alpha\\). Sin embargo, como este valor-P puede ser â€œanticonservativoâ€ (mÃ¡s pequeÃ±o de lo que deberÃ­a ser), es mejor no sacar conclusiones apresuradas y rechazar \\(H_0\\). La prueba de verosimilitud se puede obtener tambiÃ©n asÃ­: anova(mod1, mod2) ## Model df AIC BIC logLik Test L.Ratio p-value ## mod1 1 4 5630.344 5647.782 -2811.172 ## mod2 2 7 5619.201 5649.718 -2802.600 1 vs 2 17.14349 7e-04 Para obtener un valor-P mÃ¡s acorde al problema podemos usar simulaciÃ³n. La funciÃ³n simulate.lme simula datos de modelos especificados por medio de los argumentos object y m2, ajusta los modelos, y entrega los valores de log-verosimilitud, con los se puede obtener el estadÃ­stico de la prueba de razÃ³n de verosimilitud. A continuaciÃ³n el cÃ³digo para obtener el valor-P con simulaciÃ³n. simul &lt;- simulate.lme(object=mod1, m2=mod2, method = &#39;ML&#39;, nsim=1000) lrts_nlme &lt;- -2 * (simul$null$ML[, 2] - simul$alt$ML[, 2]) acumulada1 &lt;- ecdf(x=lrts_nlme) # F(x) para los valores LRT 1 - acumulada1(17.14349) ## [1] 0.001 De la salida anterior se tiene que el valor-P = 0.001 y ya no es tan pequeÃ±o como el valor-P anterior. Por esta razÃ³n hay evidencias rechazar \\(H_0\\) y por lo tanto la variable Dieta si aporta al modelo. Ejemplo La base de datos Orthodont contiene informaciÃ³n sobre una medida de distancia intrafacial para jÃ³venes sometidos a ortodoncia. data(Orthodont, package=&quot;nlme&quot;) library(ggplot2) ggplot(data = Orthodont, aes(x = age, y = distance, color = Sex)) + geom_point() + theme_bw() + facet_wrap(~ Subject) El objetivo es comparar los siguientes dos modelos. Modelo 1 \\[\\begin{align*} Distance_{ij} &amp;\\sim N(\\mu_{ij}, \\sigma^2_{distance}) \\\\ \\mu_{ij} &amp;= \\beta_0 + \\beta_1 age_{ij} + b_{0i} \\\\ b_{0} &amp;\\sim N(0, \\sigma^2_{b0}) \\end{align*}\\] Modelo 2 \\[\\begin{align*} Distance_{ij} &amp;\\sim N(\\mu_{ij}, \\sigma^2_{distance}) \\\\ \\mu_{ij} &amp;= \\beta_0 + \\beta_1 age_{ij} + \\beta_2 SexFemale_i + b_{0i} \\\\ b_{0} &amp;\\sim N(0, \\sigma^2_{b0}) \\end{align*}\\] SoluciÃ³n El problema de este ejercicio se puede resumir con \\(H_0:\\) la variable Sexo no aporta al modelo, versus, \\(H_A:\\) la variable Sexo si aporta al modelo. Para ajustar ambos modelos se usa el siguiente cÃ³digo. library(lme4) mod1 &lt;- lmer(distance ~ age + (1|Subject), data=Orthodont, REML=FALSE) mod2 &lt;- lmer(distance ~ age + Sex + (1|Subject), data=Orthodont, REML=FALSE) Para calcular la prueba razÃ³n de verosimilitud se usa el siguiente cÃ³digo. lrt &lt;- -2 * (logLik(mod1) - logLik(mod2)) lrt ## &#39;log Lik.&#39; 8.533057 (df=4) pchisq(q=lrt, df=5-4, lower.tail=FALSE) ## &#39;log Lik.&#39; 0.003487534 (df=4) De la salida anterior se tiene que el valor-P = 0.003487534 y menor que cualquier \\(\\alpha\\). Sin embargo, como este valor-P puede ser â€œanticonservativoâ€ (mÃ¡s pequeÃ±o de lo que deberÃ­a ser), es mejor no sacar conclusiones apresuradas y rechazar \\(H_0\\). La prueba de verosimilitud se puede obtener tambiÃ©n asÃ­: anova(mod1, mod2) ## Data: Orthodont ## Models: ## mod1: distance ~ age + (1 | Subject) ## mod2: distance ~ age + Sex + (1 | Subject) ## Df AIC BIC logLik deviance Chisq Chi Df Pr(&gt;Chisq) ## mod1 4 451.39 462.12 -221.69 443.39 ## mod2 5 444.86 458.27 -217.43 434.86 8.5331 1 0.003488 ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Para obtener un valor-P mÃ¡s acorde al problema podemos usar simulaciÃ³n. La funciÃ³n simulate.lme simula respuestas \\(y_{ij}\\) del modelo dado. A continuaciÃ³n el cÃ³digo para obtener el valor-P con simulaciÃ³n (Â¡tarda varios minutos!). nrep &lt;- 5000 lrts_lme4 &lt;- numeric(nrep) for (i in 1:nrep) { new_y_h0 &lt;- simulate(mod1) # Asumiendo H0 verdadera Orthodont$new_y_h0 &lt;- new_y_h0$sim_1 aux0 &lt;- lmer(new_y_h0 ~ age + (1|Subject), data=Orthodont, REML=FALSE) aux1 &lt;- lmer(new_y_h0 ~ age + Sex + (1|Subject), data=Orthodont, REML=FALSE) lrts_lme4[i] &lt;- -2 * (logLik(aux0) - logLik(aux1)) } acumulada2 &lt;- ecdf(x=lrts_lme4) # F(x) para los valores LRT 1 - acumulada1(8.533057) ## [1] 0.005 De la salida anterior se tiene que el valor-P = 0.005 y ya no es tan pequeÃ±o como el valor-P anterior. Por esta razÃ³n hay evidencias rechazar \\(H_0\\) y por lo tanto la variable Sexo si aporta al modelo. 5.4 Prueba de hipÃ³tesis sobre componentes de varianza Las componentes de varianza corresponden a las varianzas y covarianzas del vector de efectos aleatorios. La prueba razÃ³n de verosimilitud puede ser usada para comparar modelos ajustados por el mÃ©todo REML y que difieran en sus componentes de varianza, pero que tenga igual estructura de efectos fijos. Para hacer pruebas de hipÃ³tesis sobre las componentes de varianza se tienen dos casos que se explican en las siguientes subsecciones. 5.4.1 Componentes de varianza lejos del borde Luego un ejemplo. 5.4.2 Componentes de varianza en el borde Este caso se presenta cuando la hipÃ³tesis nula considera que uno o varios parÃ¡metros estÃ¡n justo en el borde del dominio del parÃ¡metro en cuestion. Por ejemplo, si queremos estudiar la inclusiÃ³n del intercepto aleatorio \\(b_0\\) en un modelo de regresiÃ³n clÃ¡sico, tendrÃ­amos las siguientes hipÃ³tesis: \\(H_0: \\sigma^2_{b0} = 0\\) versus \\(H_A: \\sigma^2_{b0} &gt; 0\\). Debido a la condiciÃ³n de \\(\\sigma^2_{b0}\\) en \\(H_0\\), se dice que esa componente de varianza estÃ¡ en el borde de su dominio, ya que \\(\\sigma^2_{b0}\\) no puede ser negativa. En este ejemplo particular, rechazar \\(H_0\\) implicarÃ­a que es apropiado incluir \\(b_0\\) en el modelo. En el caso de componentes de varianza cerca de la frontera la distribuciÃ³n del estadÃ­stico razÃ³n de verosimilitud no es exactamente una \\(\\chi^2\\) (Galecki and Burzykowski 2012). En la secciÃ³n 6.3.4 de (Verbeke and Molenberghs 2000) se listan cuatro casos en los cuales se usan mezclas de distribuciones corregir la distribuciÃ³n del estadÃ­stico y asÃ­ calcular el valor-P corregido en la prueba razÃ³n de verosimilitud. Los cuatro casos son los siguientes: Sin efecto aleatorio versus 1 efecto aleatorio: en este caso lo que interesa es \\(H_0: \\sigma^2_{b} = 0\\) versus \\(H_A: \\sigma^2_{b} &gt; 0\\), la distribuciÃ³n asintÃ³tica del estadÃ­stico de razon de verosimilitud es una mezcla de \\(\\chi^2_1\\) y \\(\\chi^2_0\\) con pesos iguales a 0.5. 1 efecto aleatorio versus 2 efectos aleatorios: en este caso lo que interesa es \\(H_0: \\boldsymbol{D} = \\begin{pmatrix} d_{11} &amp; 0 \\\\ 0 &amp; 0 \\end{pmatrix}\\) versus \\(H_A: \\boldsymbol{D} \\neq \\boldsymbol{0}\\) para un \\(d_{11}&gt;0\\), en este caso la distribuciÃ³n asintÃ³tica del estadÃ­stico razÃ³n de verosimilitud es una mezcla de \\(\\chi^2_2\\) y \\(\\chi^2_1\\) con pesos iguales a 0.5. \\(q\\) efectos aleatorios versus \\(q+1\\) efectos aleatorios: en este caso lo que interesa es \\(H_0: \\boldsymbol{D} = \\begin{pmatrix} \\boldsymbol{D_{11}} &amp; \\boldsymbol{0}\\\\ \\boldsymbol{0}^\\top &amp; 0 \\end{pmatrix}\\) donde \\(\\boldsymbol{D_{11}}\\) es una matriz de covarianzas (positiva definida) de dimensiÃ³n \\(q \\times q\\) versus que \\(\\boldsymbol{D}\\) es una matriz general de dimensiÃ³n \\(q+1 \\times q+1\\). En este caso la distribuciÃ³n asintÃ³tica del estadÃ­stica razÃ³n de verosimilitud es una mezcla de \\(\\chi^2_{q+1}\\) y \\(\\chi^2_q\\) con pesos iguales a 0.5. \\(q\\) efectos aleatorios versus \\(q+k\\) efectos aleatorios: en este caso lo que interesa es \\(H_0: \\boldsymbol{D} = \\begin{pmatrix} \\boldsymbol{D_{11}} &amp; \\boldsymbol{0}\\\\ \\boldsymbol{0}^\\top &amp; \\boldsymbol{0} \\end{pmatrix}\\) donde \\(\\boldsymbol{D}\\) es una matriz de covarianzas (positiva definida) de dimensiÃ³n \\(q+k \\times q+k\\) versus que \\(H_A: \\boldsymbol{D} = \\begin{pmatrix} \\boldsymbol{D_{11}} &amp; \\boldsymbol{D_{12}}\\\\ \\boldsymbol{D_{12}}^\\top &amp; \\boldsymbol{D_{22}} \\end{pmatrix}\\) es una matriz general de dimensiÃ³n \\(q+k \\times q+k\\). En este caso la distribuciÃ³n asintÃ³tica del estadÃ­stica razÃ³n de verosimilitud es una mezcla de \\(\\chi^2_{q+k}\\) y \\(\\chi^2_q\\) con pesos iguales a 0.5. Si la distribuciÃ³n nula del estadÃ­stico razÃ³n de verosimilitud no puede ser obtenida analÃ­ticamente, una posible soluciÃ³n es usar la distribuciÃ³n empÃ­rica del estadÃ­stico obtenida al ajustar mÃºltiples modelos nulos y alternativos (Galecki and Burzykowski 2012). Ejemplo Simule 10 observaciones para cada uno de los 10 grupos siguiendo el siguiente modelo y luego aplique la prueba de razÃ³n de verosimilitud para estudiar \\(H_0: \\sigma^2_{b0} = 0\\) versus \\(H_A: \\sigma^2_{b0} &gt; 0\\). \\[\\begin{align*} y_{ij} &amp;\\sim N(\\mu_{ij}, \\sigma^2_y) \\\\ \\mu_{ij} &amp;= 4 - 6 x_{ij} + b_{0i} \\\\ \\sigma^2_y &amp;= 4 \\\\ b_{0} &amp;\\sim N(0, \\sigma^2_{b0}=4) \\\\ x_{ij} &amp;\\sim U(0, 10) \\end{align*}\\] SoluciÃ³n La funciÃ³n gen_dat_b0 de abajo permite simular m observaciones de n grupos con intercepto aleatorio \\(b_0 \\sim N(0, \\sigma^2_{b0})\\). Adicionalmente, es posible elegir los efectos fijos beta0, beta_1 y la varianza sigma de la variable respuesta. gen_dat_b0 &lt;- function(n, m, beta0, beta1, sigmay, sigmab0, seed=NULL) { if(is.null(seed)) seed &lt;- as.integer(runif(1)*2e9) group &lt;- rep(1:n, each=m) set.seed(seed) b0 &lt;- rep(rnorm(n=n, mean=0, sd=sigmab0), each=m) set.seed(seed) x &lt;- runif(n=n*m, min=0, max=10) set.seed(seed) y &lt;- rnorm(n=n*m, mean=beta0 + beta1 * x + b0, sd=sigmay) data.frame(group=group, x=x, y=y) } Vamos ahora a generar 10 observaciones para 10 grupos con intercepto aleatorio con una varianza \\(\\sigma^2_{b0}=2^2=4\\). La semilla se va a fijar en un valor de 1220872376 por cuestiones didÃ¡cticas. datos &lt;- gen_dat_b0(n=10, m=10, beta0=4, beta1=-6, sigmay=2, sigmab0=2, seed=1220872376) head(datos) ## group x y ## 1 1 3.817132 -20.106729 ## 2 1 8.951117 -49.950457 ## 3 1 5.710726 -33.154170 ## 4 1 7.451320 -39.583303 ## 5 1 1.263282 -1.070788 ## 6 1 6.114367 -33.423587 Vamos a ajustar dos modelos, el primero sin incluir \\(b_0\\) y el segundo incluyendo \\(b_0\\). library(nlme) fit1 &lt;- gls(y ~ x, data=datos, method=&quot;REML&quot;) # Igual resultado con lm fit2 &lt;- lme(y ~ x, random = ~ 1| group, data=datos, method=&quot;REML&quot;) Resultados del primer modelo. summary(fit1) ## Generalized least squares fit by REML ## Model: y ~ x ## Data: datos ## AIC BIC logLik ## 475.8248 483.5797 -234.9124 ## ## Coefficients: ## Value Std.Error t-value p-value ## (Intercept) 4.64931 0.5180190 8.97517 0 ## x -6.00175 0.0814173 -73.71588 0 ## ## Correlation: ## (Intr) ## x -0.875 ## ## Standardized residuals: ## Min Q1 Med Q3 Max ## -2.14346496 -0.64999607 -0.06461389 0.60660976 3.48238119 ## ## Residual standard error: 2.50842 ## Degrees of freedom: 100 total; 98 residual Resultados del segundo modelo. summary(fit2) ## Linear mixed-effects model fit by REML ## Data: datos ## AIC BIC logLik ## 474.7777 485.1175 -233.3888 ## ## Random effects: ## Formula: ~1 | group ## (Intercept) Residual ## StdDev: 0.8166724 2.383898 ## ## Fixed effects: y ~ x ## Value Std.Error DF t-value p-value ## (Intercept) 4.640053 0.5652943 89 8.20821 0 ## x -6.000087 0.0795348 89 -75.43973 0 ## Correlation: ## (Intr) ## x -0.783 ## ## Standardized Within-Group Residuals: ## Min Q1 Med Q3 Max ## -2.19536246 -0.56396957 0.05433633 0.61634184 3.29594400 ## ## Number of Observations: 100 ## Number of Groups: 10 Ahora vamos a calcular el estadÃ­stico y su valor-P. lrt &lt;- -2 * (logLik(fit1) - logLik(fit2)) lrt ## &#39;log Lik.&#39; 3.04712 (df=3) my_p.value &lt;- pchisq(q=3.04712, df=1, lower.tail=FALSE) my_p.value ## [1] 0.08088045 De la salida anterior se tiene que \\(valor-P = 0.0809\\) y como \\(\\alpha=0.05\\), por lo tanto NO hay evidencias para rechazar \\(H_0: \\sigma^2_{b0} = 0\\). Â¿No es extraÃ±a esta conclusiÃ³n ðŸ¤”? Los resultados anteriores se pueden obtener por medio de la funciÃ³n anova asÃ­. anova(fit1, fit2) ## Model df AIC BIC logLik Test L.Ratio p-value ## fit1 1 3 475.8248 483.5797 -234.9124 ## fit2 2 4 474.7777 485.1175 -233.3888 1 vs 2 3.04712 0.0809 Ahora vamos a simular 50 conjuntos de datos suponiendo \\(H_0\\) verdadera y luego calcularemos los lrt para asÃ­ tener la distribuciÃ³n empÃ­rica de los lrt bajo la hipÃ³tesis nula \\(H_0: \\sigma^2_{b0} = 0\\) verdadera. En un aplicaciÃ³n se deberÃ­an generar mÃ¡s conjuntos de pero aquÃ­ vamos a usar sÃ³lo 50 por comodidad. pseudo_gen_dat &lt;- function(nobs, beta0, beta1, sigmay) { group &lt;- datos$group # Aqui la diferencia x &lt;- datos$x # Aqui la diferencia y &lt;- rnorm(n=nobs, mean=beta0 + beta1 * x, sd=sigmay) data.frame(group=group, x=x, y=y) } nrep &lt;- 50 lrts &lt;- numeric(nrep) for (i in 1:nrep) { pseudo_datos &lt;- pseudo_gen_dat(nobs=100, beta0=4.64931, beta1=-6.00175, sigma=2.50842) m1 &lt;- gls(y ~ x, data=pseudo_datos, method=&quot;REML&quot;) m2 &lt;- lme(y ~ x, random = ~ 1| group, data=pseudo_datos, method=&quot;REML&quot;) lrts[i] &lt;- -2 * (logLik(m1) - logLik(m2)) } Dibujando la densidad de los lrt. plot(density(lrts), main=&#39;Densidad empÃ­rica de los lrts&#39;) Calculando el valor-P. acumulada &lt;- ecdf(x=lrts) # F(x) para los valores LRT 1 - acumulada(3.04712) # Valor-P ## [1] 0.04 De la salida anterior se tiene que \\(valor-P &lt; \\alpha\\) por lo tanto SI hay evidencias para rechazar \\(H_0: \\sigma^2_{b0} = 0\\). Â¿Es esto coherente ahora ðŸ™‚? Los resultados anteriores se obtuvieron usando nrep &lt;- 50, en la prÃ¡ctica ese nÃºmero de repeticiones deberÃ­a subir al menos a 1000. Repita el procedimiento anterior con nrep &lt;- 5000 y observe lo que sucede. El paquete RLRsim (Scheipl and Bolker 2016) tiene la funciÃ³n exactRLRT que permite extraer el valor-P mediante simulaciÃ³n. Abajo un ejemplo de como usarla en el presente ejemplo. library(RLRsim) exactRLRT(m=fit2, nsim=1000) ## Warning in model.matrix.default(~m$groups[[n.levels - i + 1]] - 1, ## contrasts.arg = c(&quot;contr.treatment&quot;, : non-list contrasts argument ignored ## ## simulated finite sample distribution of RLRT. ## ## (p-value based on 1000 simulated values) ## ## data: ## RLRT = 3.0471, p-value = 0.039 Consulte la ayuda de la funciÃ³n exactRLRT para que conozca sus posibilidades y limitaciones. Ejercicios Â¿QuÃ© son modelos anidados? Â¿Son modelos que usan datos relacionados con aves? Considere la base de datos sleepstudy del paquete lme4. El objetivo es comparar los siguientes dos modelos. Modelo 1 \\[\\begin{align*} Reaction_{ij} &amp;\\sim N(\\mu_{ij}, \\sigma^2_{reaction}) \\\\ \\mu_{ij} &amp;= \\beta_0 + \\beta_1 days_{ij} + b_{0i} + b_{1i} days_{ij} \\\\ (b_0, b_1)^\\top &amp;\\sim N(\\boldsymbol{0}, \\boldsymbol{D}) \\end{align*}\\] Modelo 2 \\[\\begin{align*} Reaction_{ij} &amp;\\sim N(\\mu_{ij}, \\sigma^2_{reaction}) \\\\ \\mu_{ij} &amp;= \\beta_0 + \\beta_1 days_{ij} + \\beta_2 days_{ij}^2 + b_{0i} + b_{1i} days_{ij} \\\\ (b_0, b_1)^\\top &amp;\\sim N(\\boldsymbol{0}, \\boldsymbol{D}) \\end{align*}\\] Escriba las hipÃ³tesis del problema en forma simbÃ³lica y en lenguaje sencillo. Aplique la prueba razÃ³n de verosimilitud usando simulaciÃ³n y concluya. Rta: el valor-P \\(\\approx\\) 0.136. Considere el ejemplo del capÃ­tulo 7 sobre el estudio de crecimiento de un grupo de jÃ³venes. Aplique la prueba razÃ³n de verosimilitud para estudiar \\(H_0: \\sigma^2_{b0} = 0\\) versus \\(H_A: \\sigma^2_{b0} &gt; 0\\), es decir, ajuste un modelo lineal simple para explicar la estatura en funciÃ³n de la edad y luego un modelo mixto con intercepto aleatorio. Â¿CuÃ¡l de los dos modelos parece explicar mejor los datos? Use \\(\\alpha=0.06\\). En este enlace estÃ¡ la pregunta de un usuario de StackExange sobre prueba de hipÃ³tesis (PH). Â¿Fue la pregunta sobre PH sobre efectos fijos o PH sobre componentes de varianza? Â¿QuerÃ­a el usuario un PH asintÃ³tica o una PH basada en bootstrap (relacionado con simulaciÃ³n)? Mire el ejemplo que diÃ³ YaronZ, Â¿por quÃ© no definiÃ³ el mÃ©todo REML dentro de las funciones lmer y lm? En este enlace estÃ¡ la extensa pregunta del usuario Patrick. En el primer cajÃ³n de cÃ³digo Patrick escribiÃ³ un cÃ³digo para simular observaciones de un modelo mixto. Â¿CÃ³mo le parece esa forma de simular? Â¿CuÃ¡ntos elementos tiene el vector de parÃ¡metros del modelo de Patrick? Â¿CuÃ¡les son los valores de los parÃ¡metros? En este enlace estÃ¡ la pregunta del usuario biostat_newbie. Â¿QuÃ© nombre recibe el modelo que le interesa a biostat_newbie? Â¿QuÃ© es lo que necesita 0.7494974? Â¿CuÃ¡l es el mensaje de primer pÃ¡rrafo de que respondiÃ³ Fabians? En la respuesta que Fabians diÃ³ hay un cÃ³digo de R. Â¿Para quÃ© sirve ese cÃ³digo tan extraÃ±o? Â¿QuiÃ©n es Ben Bolker? Â¿En cuÃ¡les paquetes de R ha participado Ben Bolker? En este enlace estÃ¡ la pregunta del usuario user9171. Â¿CuÃ¡l es el error que comete user9171 al usar el siguiente cÃ³digo? &gt; anova(fit.fe, fit.me) Error: $ operator not defined for this S4 class Â¿QuÃ© le respondiÃ³ Karl Ove Hufthammer? Karl le agrega en su respuesta â€œAnd really the choice of whether to include the random effects should be based on theory (e.g., the sampling plan), not on a statistical testâ€. Â¿QuÃ© quiere decir eso? Ben Bolker escribiÃ³ unas notas sobre pruebas de hipÃ³tesis, revise este enlace para consultarlas. En el ejemplo de Ben Bolker hay tres modelos: m2, m1 y m0. Â¿CuÃ¡l es el â€œfull modelâ€ y cuÃ¡l es el â€œreduced modelâ€? Â¿Para quÃ© sirve la funciÃ³n update? Â¿Usted la ha usado alguna vez? Â¿No? Pues Ãºsela de aquÃ­ en adelante. Ben escribe â€œwhich has a fast implementation of simulation-based tests of null hypotheses about zero variances, for simple tests.â€ Â¿A quÃ© paquete se refiere con esa frase? References "],
["reg-diagnos.html", "6 DiagnÃ³stico del modelo de regresiÃ³n de efectos mixtos 6.1 Los residuos 6.2 Iniciando con el diagnÃ³stico: prueba de hipÃ³tesis e inferencia visual", " 6 DiagnÃ³stico del modelo de regresiÃ³n de efectos mixtos El diagnÃ³stico del modelo de regresiÃ³n es un mÃ©todo que permite determinar si un modelo de regresiÃ³n ajustado representa adecuadamente los datos. El objetivo de este capitulo consiste en introducir al lector los distintos mÃ©todos de diagnostico del modelo, los cuales permitiran identificar aquel modelo que represente sus datos con una mayor precisiÃ³n. 6.1 Los residuos Los residuos son la base de la mayorÃ­a de los mÃ©todos de diagnÃ³stico. Estos pueden ser de distinto tipo. Los residuos mÃ¡s bÃ¡sicos son los denominados residuos ordinarios, \\(\\hat{\\epsilon}_{i}\\), el cual se define como la diferencia entre el valor observado, \\(y_{i}\\), y su correspondiente valor estimado por el modelo, \\(\\hat{\\mu}_{i}\\), asÃ­: \\[\\begin{align*} \\hat{\\epsilon}_{i} = y_{i} - \\hat{\\mu}_{i}, i = 1, 2, ..., n \\end{align*}\\] donde \\(\\hat{\\mu}_{i}\\) es igual a \\(x^{&#39;}_{i}\\hat{\\beta}\\). A continuaciÃ³n, se presenta una representaciÃ³n grÃ¡fica de \\(\\hat{\\epsilon}_{i}\\): Luego los residuos ordinarios se escalan con el fin de que su interpretaciÃ³n no dependa de las unidades de medida de la variable dependiente. El proceso de estandarizaciÃ³n consiste en dividir el residuo ordinario, \\(\\hat{\\epsilon}_{i}\\), por la expresiÃ³n \\(\\sigma\\sqrt{(1-h_{i})}\\), donde \\({\\sigma}\\) corresponde a la desviaciÃ³n estandar verdadera y \\(h_{i}\\) al apalancamiento o valor de sombrero. Los residuos obtenidos de esta manera se denominan como residuos estandarizados. Sin embargo la verdadera desviaciÃ³n estÃ¡ndar rara vez se conoce. Por lo tanto, el escalado se puede realizar utilizando un estimador del mismo, es decir \\(\\hat{\\sigma}\\). Los residuos obtenidos de esta manera se denominan como residuos estudentizados, los cuales a su vez se dividen en dos: los residuos internamente estudentizados y los residuos externamente estudentizados. La tabla a continuaciÃ³n, resume las formas bÃ¡sicas de los residuos escalados: Formula matemÃ¡tica Estandarizado \\(\\frac{\\hat\\epsilon_i}{\\sigma\\sqrt{(1-h_i)}}\\) Internamente estudentizado \\(\\frac{\\hat\\epsilon_i}{\\hat\\sigma\\sqrt{(1-h_i)}}\\) Externamente estudentizado \\(\\frac{\\hat\\epsilon_i}{\\hat\\sigma_{(-i)}\\sqrt{(1-h_i)}}\\) * En el residuo internamente estudentizado, \\(\\hat\\sigma\\) denota una estimaciÃ³n de \\(\\sigma\\) basada en todas las observaciones; â€  En el residuo externamente estudentizado, \\(\\hat\\sigma_{(-i)}\\) es una estimaciÃ³n obtenida luego de excluir la i-Ã©sima observaciÃ³n de los cÃ¡lculos. Se usara la base de datos hsb del paquete merTools para entender mejor de que tratan los residuos, asÃ­ como tambiÃ©n los mÃ©todos de diagnosticos que explicaremos mÃ¡s adelante en este capitulo. A continuaciÃ³n podra ver la base de datos a usar: Se puede entender bien la lÃ³gica de los que son los residuos ajustando un modelo de regresiÃ³n simple. El diagnÃ³stico del modelo de regresiÃ³n aborda la adecuaciÃ³n de un modelo estadÃ­stico una vez se han ajustado los datos. De hecho, el ajuste de un modelo debe verse como un proceso iterativo en el que se ajusta el modelo, se evalÃºan sus residuos y se mejora. AsÃ­ hasta llegar a un modelo Ã³ptimo. Suponga que se quiere poner en relaciÃ³n dos variables: la variable \\(x_{1}\\) que representa el nivel socio-econÃ³mico de los alumnos (ses), y la variable \\(y\\), que es el rendimiento de los mismos alumnos en una prueba de matemÃ¡ticas (mathach). Para facilitar este anÃ¡lisis (y los posteriores) se asumira que \\(x_{1}\\) es una variable continua que toma valores entre -4 y +4, donde cero indica nivel socio-econÃ³mico medio, +4 indica nivel socio-econÃ³mico alto y -4 indica nivel socio-econÃ³mico bajo. El modelo de regresiÃ³n simple aplicado a este ejemplo se puede representar asÃ­: \\[\\begin{align} \\label{mod2} y_i &amp;\\sim N(\\mu_i, \\sigma^2), \\\\ \\mu_i &amp;= \\beta_0 + \\beta_1 x_{1i}, \\\\ \\sigma^2 &amp;= \\text{constante} \\end{align}\\] El codigÃ³ en R para ajustar el anterior modelo se presenta a continuaciÃ³n: Modelo_simple &lt;- lm(mathach ~ ses, data = hsb) Luego, los residuos (en este caso los residuos ordinarios) se pueden obtener con las siguientes funciones genericas: muestra_aleatoria$val_predicho &lt;- predict(Modelo_simple) muestra_aleatoria$res_ordinario &lt;- residuals(Modelo_simple) Tenga en cuenta que se bien el modelo se ajusto con las 7185 valores observados, la grÃ¡fica a continuaciÃ³n solo presenta 150 valores. Esto debido a que al no restringir por este valor, la grÃ¡fica se presentaba muy saturada de valores observados y estimados. 6.2 Iniciando con el diagnÃ³stico: prueba de hipÃ³tesis e inferencia visual Como es sabido, la inferencia estadÃ­stica clÃ¡sica consiste en formular inicialmente un juego de hipÃ³tesis (hipÃ³tesis nula y alternativa), y calcular posteriormente un estadÃ­stico de prueba del cual se deriva un valor p que permitira concluir en relaciÃ³n a las hipÃ³tesis planteadas. Este proceso tiene su anÃ¡logo en inferencia visual. Suponga que el interÃ©s consiste en verificar alguna suposiciÃ³n sobre el modelo ajustado: por ejemplo, la homogeneidad de la varianza residual. Para ello se plantea como hipÃ³tesis nula el cumplimiento de dicha homogeneidad, mientras que la hipÃ³tesis alternativa abarca cualquier violaciÃ³n de este supuesto. Para la inferencia visual, el estadÃ­stico de prueba corresponde a una grÃ¡fica que muestra un aspecto del supuesto que se desea verifcar, y permite al observador distinguir entre escenarios bajo la hipÃ³tesis nula y la alternativa. No obstante los mÃ©todos grÃ¡ficos permiten al analista descubrir no solo cuÃ¡ndo el modelo ajustado no cumple con el supuesto planteado, sino que tambiÃ©n permite detectar cuÃ¡l puede ser la causa del mismo, lo cual serÃ­a casi imposible a travÃ©s de unicamente pruebas de hipÃ³tesis. Existe una gran variedad de grÃ¡ficos (como los presentados a continuaciÃ³n) lo que refleja el hecho de que ningÃºn grÃ¡fico de diagnÃ³stico es apropiado para todos los propÃ³sitos. "],
["apli-nlme.html", "7 AplicaciÃ³n con nlme Ejercicios", " 7 AplicaciÃ³n con nlme En este capÃ­tulo se mostrarÃ¡ como usar el paquete nlme para la aplicaciÃ³n de modelos mixtos con la base de datos Oxboys del mismo paquete. A continuaciÃ³n la base de datos a utilizar. library(nlme) head(Oxboys) ## Grouped Data: height ~ age | Subject ## Subject age height Occasion ## 1 1 -1.0000 140.5 1 ## 2 1 -0.7479 143.4 2 ## 3 1 -0.4630 144.8 3 ## 4 1 -0.1643 147.1 4 ## 5 1 -0.0027 147.7 5 ## 6 1 0.2466 150.2 6 Esta base de datos sobre crecimiento contiene la informaciÃ³n sobre altura (heigth), edad estandarizada (age) de un grupo de 26 jÃ³venes. Como la base de datos Oxboys es de la clase groupedData, es posible aplicar un plot directamente y el resultado se muestra continuaciÃ³n. plot(Oxboys) Es posible convertir un data.frame para que tenga la clase groupedData, consulte la ayuda de la funciÃ³n groupedData del paquete nlme para mÃ¡s detalles. De la figura anterior vemos que las curvas de crecimiento inician a diferente altura (intercepto) y que la pendiente del crecimiento no son todas iguales, por ejemplo, el individuo 21 creciÃ³ mÃ¡s rÃ¡pido que el individuo 3. Esto nos hace pensar que un modelo con intercepto y pendiente aleatoria podrÃ­an ser adecuados para modelar el crecimiento. En las siguientes ecuaciones se resume el modelo matemÃ¡tico que interesa en esta situaciÃ³n. \\[\\begin{align*} Height_{ij} &amp;\\sim N(\\mu_{ij}, \\sigma^2_{Heigth}) \\\\ \\mu_{ij} &amp;= \\beta_0 + \\beta_1 Age_{ij} + b_{0i} + b_{1i} Age_{ij} \\\\ \\left ( \\begin{matrix} b_{0} \\\\ b_{1} \\end{matrix} \\right ) &amp;\\sim N\\left ( \\left ( \\begin{matrix} 0 \\\\ 0 \\end{matrix} \\right ), \\left ( \\begin{matrix} \\sigma^2_{b0} &amp; \\sigma_{b01} \\\\ \\sigma_{b01} &amp; \\sigma^2_{b1} \\end{matrix} \\right ) \\right ) \\end{align*}\\] El vector de parÃ¡metros para este modelo serÃ­a \\(\\boldsymbol{\\Theta}=(\\beta_0, \\beta_1, \\sigma_{height}, \\sigma_{b0}, \\sigma_{b1}, \\sigma_{b0b1})^\\top\\). Para ajustar este modelo a los datos con el paquete nlme podemos usar el siguiente cÃ³digo. fit &lt;- lme(height ~ age, random= ~ 1 + age | Subject, data=Oxboys, method=&quot;REML&quot;) Para obtener la tabla de resumen usamos: summary(fit) ## Linear mixed-effects model fit by REML ## Data: Oxboys ## AIC BIC logLik ## 736.091 756.7714 -362.0455 ## ## Random effects: ## Formula: ~1 + age | Subject ## Structure: General positive-definite, Log-Cholesky parametrization ## StdDev Corr ## (Intercept) 8.081077 (Intr) ## age 1.680717 0.641 ## Residual 0.659889 ## ## Fixed effects: height ~ age ## Value Std.Error DF t-value p-value ## (Intercept) 149.37175 1.5854173 207 94.21605 0 ## age 6.52547 0.3363003 207 19.40370 0 ## Correlation: ## (Intr) ## age 0.628 ## ## Standardized Within-Group Residuals: ## Min Q1 Med Q3 Max ## -2.65092109 -0.57493341 -0.02842894 0.59604254 2.60496077 ## ## Number of Observations: 234 ## Number of Groups: 26 De la salida anterior se obtiene que \\(\\hat{\\boldsymbol{\\Theta}}=(\\hat{\\beta}_0=149.37, \\hat{\\beta}_1=6.53, \\hat{\\sigma}_{height}=0.66, \\hat{\\sigma}_{b0}=8.08, \\hat{\\sigma}_{b1}=1.68, \\hat{\\sigma}_{b0b1}=8.71)^\\top\\). La estimaciÃ³n \\(\\hat{\\sigma}_{b0b1}\\) no aparece directamente en el summary pero se obtiene utilizando la ecuaciÃ³n \\(Cor=Cov/(\\sigma_1 \\sigma_2)\\) que relaciona correlaciÃ³n, covarianza y desviaciones de los efectos aleatorios. Usando la informaciÃ³n anterior se puede escribir el modelo ajustado de la siguiente manera. \\[\\begin{align*} Height_{ij} &amp;\\sim N(\\hat{\\mu}_{ij}, 0.66^2) \\\\ \\hat{\\mu}_{ij} &amp;= 149.37 + 6.53 Age_{ij} + b_{0i} + b_{1i} Age_{ij} \\\\ \\left ( \\begin{matrix} b_{0} \\\\ b_{1} \\end{matrix} \\right ) &amp;\\sim N\\left ( \\left ( \\begin{matrix} 0 \\\\ 0 \\end{matrix} \\right ), \\left ( \\begin{matrix} 8.08^2 &amp; 8.71 \\\\ 8.71 &amp; 1.68^2 \\end{matrix} \\right ) \\right ). \\end{align*}\\] Los elementos \\(b_{0i}\\) y \\(b_{1i}\\) se deben substituir por sus respectivas predicciones \\(\\tilde{b}_{0i}\\) y \\(\\tilde{b}_{1i}\\) y se pueden obtener del modelo ajustado asÃ­: ranef(fit) ## (Intercept) age ## 10 -19.0972476 -2.78657472 ## 26 -11.3675996 -0.97474075 ## 25 -10.1595528 -2.42702035 ## 9 -11.2213331 -0.58069044 ## 2 -6.5096277 -1.07136271 ## 6 -2.5902388 -2.41771656 ## 7 -3.2473132 -1.46379286 ## 17 -6.3744842 1.89443713 ## 16 -1.8344703 -1.86707015 ## 15 -5.0856366 0.51526141 ## 8 -1.0776201 -0.06615528 ## 20 2.0850836 -1.99239802 ## 1 -1.2464285 0.59919226 ## 18 1.8031920 -0.51486646 ## 5 2.0531168 -0.24308081 ## 23 1.6937341 0.63140824 ## 11 0.6839704 1.85733185 ## 21 1.1525543 0.91894343 ## 3 6.2613001 -1.58181075 ## 24 3.7645669 0.25652772 ## 22 5.1957592 1.50551719 ## 12 7.4308033 0.52297645 ## 13 6.7004368 1.89758007 ## 14 10.0986013 2.09367207 ## 19 15.1957040 2.50720025 ## 4 15.6927297 2.78723179 Los valores de los efectos fijos estimados se pueden obtener asÃ­: fixef(fit) ## (Intercept) age ## 149.371753 6.525469 Usando la informaciÃ³n de los efectos fijo y aleatorios obtenidos antes, es posible escribir la ecuaciÃ³n del modelo para cada individuo. Los efectos fijos estimados fueron \\(\\hat{\\beta}_0 \\approx 149.37\\) y \\(\\hat{\\beta}_1\\approx 6.53\\). Para el sujeto # 10 se obtuvo \\(\\tilde{b}_{0, i=10} \\approx -19.10\\) y \\(\\tilde{b}_{1, i=10} \\approx -2.79\\), asÃ­ la media del individuo # 10 se calcula asÃ­: \\[\\begin{align*} \\hat{\\mu}_{i=10, j} &amp;= \\hat{\\beta}_0 + \\hat{\\beta}_0 \\, Age_{i=10, j} + \\tilde{b}_{0, i=10} + \\tilde{b}_{1, i=10} \\, Age_{i=10, j} \\\\ \\hat{\\mu}_{i=10, j} &amp;= 149.37 + 6.53 \\, Age_{i=10, j} - 19.10 - 2.79 \\, Age_{i=10, j} \\\\ \\hat{\\mu}_{i=10, j} &amp;= 130.27 + 3.74 \\, Age_{i=10, j} \\end{align*}\\] Lo anterior se puede resumir en el siguiente modelo. \\[\\begin{align*} Height_{i=10, j} &amp;\\sim N(\\hat{\\mu}_{i=10, j}, \\hat{\\sigma}^2_{Height}) \\\\ \\hat{\\mu}_{i=10, j} &amp;= 130.27 + 3.74 \\, Age_{i=10, j} \\\\ \\hat{\\sigma}_{Height} &amp;= 0.66 \\end{align*}\\] La expresiÃ³n anterior para cada individuo con los efectos finales (fijos y aleatorios) se puede obtener con R asÃ­: coef(fit) ## (Intercept) age ## 10 130.2745 3.738894 ## 26 138.0042 5.550728 ## 25 139.2122 4.098448 ## 9 138.1504 5.944778 ## 2 142.8621 5.454106 ## 6 146.7815 4.107752 ## 7 146.1244 5.061676 ## 17 142.9973 8.419906 ## 16 147.5373 4.658399 ## 15 144.2861 7.040730 ## 8 148.2941 6.459313 ## 20 151.4568 4.533071 ## 1 148.1253 7.124661 ## 18 151.1749 6.010602 ## 5 151.4249 6.282388 ## 23 151.0655 7.156877 ## 11 150.0557 8.382801 ## 21 150.5243 7.444412 ## 3 155.6331 4.943658 ## 24 153.1363 6.781996 ## 22 154.5675 8.030986 ## 12 156.8026 7.048445 ## 13 156.0722 8.423049 ## 14 159.4704 8.619141 ## 19 164.5675 9.032669 ## 4 165.0645 9.312700 En la presente aplicaciÃ³n es posible incluir la recta de regresiÃ³n para cada individuo al diagrama de dispersiÃ³n original. El cÃ³digo de R para obtener esto es el siguiente. library(lattice) xyplot(height ~ age | Subject, data=Oxboys, fit=fit, strip=strip.custom(bg=&quot;white&quot;), pch=16, cex=0.7, col=&#39;indianred1&#39;, panel = function(x, y, ..., fit, subscripts) { panel.xyplot(x, y, ...) ypred &lt;- fitted(fit)[subscripts] panel.lines(x, ypred, col=&quot;deepskyblue3&quot;, lwd=1) }, ylab=&quot;Height (cm)&quot;, xlab=&quot;Centered age&quot;) En la figura anterior se tienen las observaciones (crecimiento) representado por los puntos rojos, adicionalmente, aparece una recta de color azul que representa la recta de regresiÃ³n para cada individuo. De la figura se observa que la linea logra explicar la evoluciÃ³n del crecimiento para cada individuo. Ejercicios Repita el ejercicio anterior considerando un modelo sÃ³lo con intercepto aleatorio. Dibuje las rectas de regresiÃ³n para cada individuo. Â¿QuÃ© opina de este modelo? Repita el ejercicio anterior considerando un modelo sÃ³lo con pendiente aleatoria. Dibuje las rectas de regresiÃ³n para cada individuo. Â¿QuÃ© opina de este modelo? Estime la estatura para el individuo # 3 cuando su edad centrada sea de 1.1. Replique los ejemplo de este documento. "],
["apli-lme4.html", "8 AplicaciÃ³n con lme4 Ejercicios", " 8 AplicaciÃ³n con lme4 En este capÃ­tulo se mostrarÃ¡ como usar el paquete lme4 para la aplicaciÃ³n de modelos mixtos con la base de datos sleepstudy del mismo paquete. A continuaciÃ³n la base de datos a utilizar. library(lme4) head(sleepstudy) ## Reaction Days Subject ## 1 249.5600 0 308 ## 2 258.7047 1 308 ## 3 250.8006 2 308 ## 4 321.4398 3 308 ## 5 356.8519 4 308 ## 6 414.6901 5 308 Esta base de datos sobre el tiempo de reacciÃ³n promedio por dÃ­a para un conjunto de individuos, en un estudio de privaciÃ³n del sueÃ±o, contiene la informaciÃ³n sobre el tiempo de reacciÃ³n promedio (Reaction), el nÃºmero de dÃ­as de privaciÃ³n del sueÃ±o (Days), donde el dÃ­a 0 corresponde al dÃ­a en el que los indiviuos tenÃ­an su cantidad normal de sueÃ±o, y el nÃºmero del individuo (en total 18) sobre el que se realizÃ³ la observaciÃ³n (Subject). A partir del dÃ­a 0, hubo una restricciÃ³n en cada individuo a 3 horas de sueÃ±o por noche. library(ggplot2) ggplot(data = sleepstudy, aes(x = Days, y = Reaction, color = Subject)) + geom_point() + theme_bw() + facet_wrap(~ Subject) + theme(legend.position = &quot;none&quot;) De la figura anterior vemos que el tiempo de reacciÃ³n promedio, tanto en el dÃ­a 0 como en los siguientes dÃ­as de prueba (del dÃ­a 1 al dÃ­a 9), son distintos en cada uno de los individuos. Esta situaciÃ³n conlleva a probar la hipÃ³tesis de que el tiempo de reacciÃ³n promedio en una serie de pruebas varÃ­a segÃºn los individuos. Esto es, ajustar un modelo donde el intercepto y la pendiente se consideran como efectos aleatorios. Un modelo lineal mixto que describe la anterior situaciÃ³n se puede escribir como: \\[\\begin{align*} Reaction_{ij} &amp;\\sim N(\\mu_{ij}, \\sigma^2_{Reaction}) \\\\ \\mu_{ij} &amp;= \\beta_0 + \\beta_1 Days_{ij} + b_{0i} + b_{1i} Days_{ij} \\\\ \\left ( \\begin{matrix} b_{0} \\\\ b_{1} \\end{matrix} \\right ) &amp;\\sim N\\left ( \\left [ \\begin{matrix} 0 \\\\ 0 \\end{matrix} \\right ], \\left [ \\begin{matrix} \\sigma^2_{b0} &amp; \\sigma_{b01} \\\\ \\sigma_{b01} &amp; \\sigma^2_{b1} \\end{matrix} \\right ] \\right ) \\end{align*}\\] AquÃ­, los individuos (\\(i\\)) varÃ­an en el tiempo de reacciÃ³n promedio tanto en su intercepto (\\(b_{0i}\\)) como en su pendiente (\\(b_{1i}\\)), que en conjunto componen la varianza total en dicho tiempo atribuible a la variaciÃ³n entre individuos. Esta contribuciÃ³n individual se cuantifica usando un modelo de intercepto y pendiente aleatoria con distribuciÃ³n normal (\\(N\\)). La variaciÃ³n entre individuos en intercepto y pendiente es \\(\\sigma^2_{b0}\\) y \\(\\sigma^2_{b1}\\), respectivamente. La covarianza entre el intercepto y la pendiente esta dada por \\(\\sigma_{b01}\\). El vector de parÃ¡metros para este modelo serÃ­a \\(\\boldsymbol{\\Theta}=(\\beta_0, \\beta_1, \\sigma_{reaction}, \\sigma_{b0}, \\sigma_{b1}, \\sigma_{b0b1})^\\top\\). Para ajustar el modelo de intercepto y pendiente aleatoria planteado usando el paquete lme4 podemos usar el siguiente cÃ³digo: fit &lt;- lmer(Reaction ~ Days + (Days | Subject), REML = TRUE, data = sleepstudy) Para obtener la tabla de resumen usamos: summary(fit) ## Linear mixed model fit by REML [&#39;lmerMod&#39;] ## Formula: Reaction ~ Days + (Days | Subject) ## Data: sleepstudy ## ## REML criterion at convergence: 1743.6 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -3.9536 -0.4634 0.0231 0.4633 5.1793 ## ## Random effects: ## Groups Name Variance Std.Dev. Corr ## Subject (Intercept) 611.90 24.737 ## Days 35.08 5.923 0.07 ## Residual 654.94 25.592 ## Number of obs: 180, groups: Subject, 18 ## ## Fixed effects: ## Estimate Std. Error t value ## (Intercept) 251.405 6.824 36.843 ## Days 10.467 1.546 6.771 ## ## Correlation of Fixed Effects: ## (Intr) ## Days -0.138 De la salida anterior se obtienen los siguientes parÃ¡metros (\\(\\Theta\\)): \\(\\Theta\\) \\(\\beta_{0}\\) 251.40 \\(\\beta_{1}\\) 10.47 \\(\\sigma_{reaction}\\) 25.59 \\(\\sigma_{b0}\\) 24.74 \\(\\sigma_{b1}\\) 5.92 \\(\\sigma_{b0b1}\\) 10.25 * El Ãºtimo parÃ¡metro estimado se obtiene utilizando la ecuaciÃ³n de correlaciÃ³n (\\(\\rho\\)) que relaciona la covarianza y desviaciones de los efectos aleatorios: \\(\\rho_{b0b1} = \\sigma_{b0b1}/(\\sigma_{b0} * \\sigma_{b1})\\). Usando la informaciÃ³n anterior se puede escribir el modelo ajustado de la siguiente manera: \\[\\begin{align*} Reaction_{ij} &amp;\\sim N(\\hat{\\mu}_{ij}, 25.59^2) \\\\ \\hat{\\mu}_{ij} &amp;= 251.40 + 10.47 Days_{ij} + b_{0i} + b_{1i} Days_{ij} \\\\ \\left ( \\begin{matrix} b_{0} \\\\ b_{1} \\end{matrix} \\right ) &amp;\\sim N\\left ( \\left [ \\begin{matrix} 0 \\\\ 0 \\end{matrix} \\right ], \\left [ \\begin{matrix} 24.74^2 &amp; 10.25 \\\\ 10.25 &amp; 5.92^2 \\end{matrix} \\right ] \\right ) \\end{align*}\\] Los elementos \\(b_{0i}\\) y \\(b_{1i}\\) se deben substituir por sus respectivas predicciones \\(\\tilde{b}_{0i}\\) y \\(\\tilde{b}_{1i}\\) y se pueden obtener del modelo ajustado de esta forma: ranef(fit) ## $Subject ## (Intercept) Days ## 308 2.2575329 9.1992737 ## 309 -40.3942719 -8.6205161 ## 310 -38.9563542 -5.4495796 ## 330 23.6888704 -4.8141448 ## 331 22.2585409 -3.0696766 ## 332 9.0387625 -0.2720535 ## 333 16.8389833 -0.2233978 ## 334 -7.2320462 1.0745075 ## 335 -0.3326901 -10.7524799 ## 337 34.8865253 8.6290208 ## 349 -25.2080191 1.1730997 ## 350 -13.0694180 6.6142185 ## 351 4.5777099 -3.0152825 ## 352 20.8614523 3.5364062 ## 369 3.2750882 0.8722876 ## 370 -25.6110745 4.8222518 ## 371 0.8070591 -0.9881730 ## 372 12.3133491 1.2842380 ## ## with conditional variances for &quot;Subject&quot; Y los valores de los efectos fijos estimados se pueden obtener asÃ­: fixef(fit) ## (Intercept) Days ## 251.40510 10.46729 Con base en la informaciÃ³n anterior de efectos aleatorios y fijos, es posible escribir la ecuaciÃ³n del modelo para cada individuo. Para esto, se debe considerar los efectos fijos estimados (\\(\\hat{\\beta}_0 \\approx 251.40\\) y \\(\\hat{\\beta}_1\\approx 10.47\\)) y los efectos aleatorios de cada uno de los individuos (por ejemplo para el individuo 308, \\(\\tilde{b}_{0, i=308} \\approx 2.26\\) y \\(\\tilde{b}_{1, i=308} \\approx 9.20\\)). AsÃ­, el valor medio del individuo 308 se calcula como: \\[\\begin{align*} \\hat{\\mu}_{i=308, j} &amp;= \\hat{\\beta}_0 + \\hat{\\beta}_0 \\, Days_{i=308, j} + \\tilde{b}_{0, i=308} + \\tilde{b}_{1, i=308} \\, Days_{i=308, j} \\\\ \\hat{\\mu}_{i=308, j} &amp;= 251.40 + 10.47 \\, Days_{i=308, j} 2.26 + 9.20 \\, Days_{i=308, j} \\\\ \\hat{\\mu}_{i=308, j} &amp;= 253.66 + 19.67 \\, Days_{i=308, j} \\end{align*}\\] Lo anterior se puede resumir en el siguiente modelo. \\[\\begin{align*} Reaction_{i=308, j} &amp;\\sim N(\\hat{\\mu}_{i=308, j}, \\hat{\\sigma}^2_{Reaction}) \\\\ \\hat{\\mu}_{i=308, j} &amp;= 253.66 + 19.67 \\, Days_{i=308, j} \\\\ \\hat{\\sigma}_{Reaction} &amp;= 25.59 \\end{align*}\\] Los efectos fijos y aleatorios de la expresiÃ³n anterior para cada uno de los individuos se pueden obtener con R de la siguiente forma: coef(fit) ## $Subject ## (Intercept) Days ## 308 253.6626 19.6665597 ## 309 211.0108 1.8467699 ## 310 212.4488 5.0177063 ## 330 275.0940 5.6531411 ## 331 273.6636 7.3976093 ## 332 260.4439 10.1952325 ## 333 268.2441 10.2438881 ## 334 244.1731 11.5417935 ## 335 251.0724 -0.2851939 ## 337 286.2916 19.0963068 ## 349 226.1971 11.6403856 ## 350 238.3357 17.0815045 ## 351 255.9828 7.4520035 ## 352 272.2666 14.0036922 ## 369 254.6802 11.3395736 ## 370 225.7940 15.2895377 ## 371 252.2122 9.4791130 ## 372 263.7185 11.7515240 ## ## attr(,&quot;class&quot;) ## [1] &quot;coef.mer&quot; A continuaciÃ³n podras observar el diagrama de dispersiÃ³n mostrado al inicio de este capitulo, agregandole a la misma la recta de regresiÃ³n para cada individuo. El cÃ³digo de R para obtener esto se presenta a continuaciÃ³n: fit &lt;- lmer(Reaction ~ Days + (Days | Subject), REML = TRUE, data = sleepstudy) sleepstudy$pred_inter_pend_aleatorio &lt;- predict(fit) ggplot(data = sleepstudy, aes(x = Days, y = pred_inter_pend_aleatorio, color = Subject)) + geom_line() + geom_point(aes(x = Days, y = Reaction, color = Subject)) + geom_abline(intercept = 251.40, slope = 10.47, color = &quot;black&quot;, linetype = &quot;dashed&quot;, size = 0.5) + theme_bw() + facet_wrap(~ Subject) + theme(legend.position = &quot;none&quot;) La figura anterior corresponde a un modelo de intercepto y pendiente aleatoria, en el que se permite que tanto los interceptos como las pendientes varÃ­en segÃºn los individuos. Las lÃ­neas continuas corresponde a la recta de regresiÃ³n ajustada a los datos. Los puntos representan las observaciones (tiempo de reacciÃ³n promedio por dÃ­a) medidas en cada uno de los individuos. La lÃ­nea negra discontinua representa el valor medio global de la distribuciÃ³n de los efectos aleatorios. A continuaciÃ³n podra observar distintas figuras donde se ajustaron cuatro modelos distintos, entre ellos el modelo mixto con intercepto y pendiente aleatoria ya evaluado aquÃ­ (Figura 4). Con base en estas figuras, se plantean los ejercicios posteriores a las mismas figuras: Ejercicios Ajuste el modelo con intercepto aleatorio mostrado en la anterior Figura 2. Â¿QuÃ© opina de este modelo? Ajuste el modelo con pendiente aleatoria presentada en la anterior Figura 3. Â¿QuÃ© opina de este modelo? Ajustar solo un intercepto aleatorio permite que los individuos varÃ­en asumiendo que los mismos tienen una pendiente comÃºn (Figura 2). Al ajustar solo una pendiente aleatoria (Figura 3) permite que la pendiente de un predictor varÃ­e en funciÃ³n de los individuos (la variable de agrupaciÃ³n). Con base esto y teniendo en cuenta el modelo de intercepto y pendiente aleatoria (Figura 4), evalÃºe cual de estos estos modelos permite un mejor ajuste de los datos presentados en la base de datos sleepstudy del paquete lme4. "],
["references.html", "References", " References "]
>>>>>>> 71ed290cc913ba5284c4fcc2053a58a1c8c3bf93
]
