[["index.html", "Modelos Mixtos con R Bienvenido Estructura del libro Software y convenciones Bloques informativos", " Modelos Mixtos con R Freddy Hernández Barajas Jorge Leonardo López Martínez 2022-10-20 Bienvenido Este libro está destinado para usuarios de R interesados en aplicar modelos mixtos. Freddy Hernández Barajas Jorge Leonardo López Martínez Estructura del libro En el capítulo 2 se hace un repaso básico del modelo de regresión lineal clásico. En el capítulo 3 se presentan los modelos mixtos y en el capítulo 14 se presentan los modelos lineales generalizados mixtos. En el capítulo 5 se presenta el paquete lme4 y sus principales funciones para modelación, mientras que en el capítulo 7 se presenta el paquete nlme y sus principales funciones para modelación. Software y convenciones Para realizar este libro usamos los paquetes knitr (Xie 2015) y bookdown (Xie 2022) que permiten unir la ventajas de LaTeX y R en un mismo archivo. En todo el libro se presentarán códigos que el lector puede copiar y pegar en su consola de R para obtener los mismos resultados aquí del libro. Los códigos se destacan en una caja de color similar a la mostrada a continuación. 4 + 6 a &lt;- c(1, 5, 6) 5 * a 1:10 Los resultados o salidas obtenidos de cualquier código se destacan con dos símbolos de númeral (##) al inicio de cada línea o renglón, esto quiere decir que todo lo que inicie con ## son resultados obtenidos y NO los debe copiar. Abajo se muestran los resultados obtenidos luego de correr el código anterior. ## [1] 10 ## [1] 5 25 30 ## [1] 1 2 3 4 5 6 7 8 9 10 Bloques informativos En varias partes del libro usaremos bloques informativos para resaltar algún aspecto importante. Abajo se encuentra un ejemplo de los bloques y su significado. Nota aclaratoria. Sugerencia. Advertencia. Solución a ejemplos. References "],["intro.html", "1 Introducción 1.1 La complejidad estructural tenida en cuenta por los modelos mixtos", " 1 Introducción Los métodos estadísticos empleados en las distintas áreas de la ciencia, tienen como objetivo fundamental adentrar al investigador en la complejidad del fenómeno a investigar. A menudo, muchos de estos fenomenos quedan fuera del alcance de los métodos estadísticos clásicos (comúnmente enseñados en las clases introductorias de estadística), dado que los mismos suelen ser sencillos o muy restrictivos. Como es sabido, lo fundamental en el uso de la estadística es que los modelos a utilizar logren representar la complejidad del fenomeno que se intenta comprender. En el intento de construir modelos acordes al fenomeno que se intentaba comprender, la estadística, y su posibilidad cuasi infinita de desarrollo y aplicación metodológica, propusieron los denominados modelos mixtos. Estos modelos no se desarrollaron exclusivamente como un conjunto de procedimientos novedosos, sino como la consecuencia del intento de emplear un modelo que permitiera acercar al investigador al fenomeno a estudiar. La disponibilidad en el uso de esta metodología, significa que el investigador esta mejor equipado que nunca para el análisis de sus datos. La perspectiva en su uso en las distintas áreas de la ciencia es brillante, puesto que estos modelos cada vez van cogiendo más popularidad, aun cuando hoy en día sigue siendo un desafió saber de que forma aplicarlos. 1.1 La complejidad estructural tenida en cuenta por los modelos mixtos Los primeros modelos de regresión lineal (denominados también modelos de regresión clásicos), fueron creados bajo supuestos muy rigidos los cuales, a pesar de simplificar su uso, acabaron por tomarse inadecuados para diversas situaciones de datos. Un ejemplo común de esta situación corresponde a conjuntos de datos con estructuras jerárquicas. Es decir, un conjunto de datos con un nivel básico de observaciones anidadas dentro de un nivel de agrupamiento de orden superior. Estas estructuras jerárquicas pueden ser de distinto tipo. Una de ellas es la estructura de dos niveles, siendo un ejemplo de este tipo de estructura, un determinado número de estudiantes asistiendo a un curso de estadística con dos profesores distintos. Aquí, los estudiantes se podrían clasificar dentro del nivel básico de la estructura (denominada también micro-nivel o de primer nivel) y los dos profesores dentro del nivel de orden superior (conocido también como macro-nivel o, de modo más general, el contexto). Otro tipo de estructura corresponde a la estructura de tres o más niveles, como por ejemplo un conjunto de estudiantes asistiendo al curso de estadística con dos profesores distintos en dos universidades. "],["reg-lin.html", "2 Regresión lineal 2.1 Modelo estadístico 2.2 Verosimilitud del modelo", " 2 Regresión lineal En este capítulo se presenta el modelo de regresión lineal clásico. 2.1 Modelo estadístico El modelo estadístico en regresión lineal clásico permite modelar la media de una variable \\(Y\\) en función de \\(k\\) covariables. El modelo se puede expresar como sigue. \\[\\begin{align} \\label{mod2} y_i &amp;\\sim N(\\mu_i, \\sigma^2), \\\\ \\mu_i &amp;= \\beta_0 + \\beta_1 x_{1i} + \\beta_2 x_{2i} + \\cdots + \\beta_k x_{ki}, \\\\ \\sigma^2 &amp;= \\text{constante} \\end{align}\\] donde \\(i=1, 2, \\ldots, n\\) es el índice que identifica las \\(n\\) observaciones del conjunto de entrenamiento. El vector de parámetros del modelo es \\(\\boldsymbol{\\theta}=(\\beta_0, \\beta_1, \\cdots, \\beta_k, \\sigma)^\\top\\). 2.2 Verosimilitud del modelo La función de verosimilitud \\(L\\) para el modelo es la siguiente: \\[ L(\\boldsymbol{\\theta}) = \\prod_i^n f(y_i \\vert \\beta_0, \\beta_1, \\cdots, \\beta_k, \\sigma), \\] donde \\(f\\) corresponde a la función de densidad de la normal. Para estimar el vector de parámetros \\(\\boldsymbol{\\theta}\\) del modelo se usa el método de Máxima Verosimilitud sobre la función \\(L\\) o sobre la función de log-verosimilitud siguiente: \\[ l(\\boldsymbol{\\theta}) = \\sum_i^n \\log(f(y_i \\vert \\beta_0, \\beta_1, \\cdots, \\beta_k, \\sigma)), \\] Ejemplo Como ilustración vamos a usar los datos del ejemplo 3.1 del libro de Montgomery, Peck and Vining (2003). En el ejemplo 3.1 los autores ajustaron un modelo de regresión lineal múltiple para explicar el Tiempo necesario para que un trabajador haga el mantenimiento y surta una máquina dispensadora de refrescos en función de las variables Número de Cajas y Distancia. Los datos del ejemplo están disponibles en el paquete MPV (por los apellidos de los autores). A continuación el código para cargar los datos y una muestra de las 6 primeras observaciones de la base de datos, en total se disponen de 20 observaciones. require(MPV) colnames(softdrink) &lt;- c(&#39;tiempo&#39;, &#39;cantidad&#39;, &#39;distancia&#39;) head(softdrink) ## tiempo cantidad distancia ## 1 16.68 7 560 ## 2 11.50 3 220 ## 3 12.03 3 340 ## 4 14.88 4 80 ## 5 13.75 6 150 ## 6 18.11 7 330 Un gráfico en 3d es obligratorio para explorar la relación entre las variables, este diagrama de puede obtener usando el paquete scatterplot3d. A continuación el código para construirlo. library(scatterplot3d) attach(softdrink) scatterplot3d(x=cantidad, y=distancia, z=tiempo, pch=16, cex.lab=1, highlight.3d=TRUE, type=&quot;h&quot;, xlab=&#39;Cantidad de cajas&#39;, ylab=&#39;Distancia (pies)&#39;, zlab=&#39;Tiempo (min)&#39;) De la figura anterior se ve claramente que a medida que aumenta el número de cajas y la distancia los tiempos tienden a ser mayores. A continuación se define la función de menos log-verosimilitud para el modelo anterior. A pesar de que nos interesa maximizar la función de log-verosimilitud hemos creado su negativo, esto porque la mayoría de las funciones de optimización minimizan y no maximizan; maximizar \\(f(x)\\) es equivalente a minimizar \\(-f(x)\\). minusll &lt;- function(theta, y, x1, x2) { media &lt;- theta[1] + theta[2] * x1 + theta[3] * x2 # Se define la media desvi &lt;- theta[4] # Se define la desviación. - sum(dnorm(x=y, mean=media, sd=desvi, log=TRUE)) } Ahora vamos a usar la función optim para encontrar los valores que maximizan la función de log-verosimilitud, el código para hacer eso se muestra a continuación. En el parámetro par se coloca un vector de posibles valores de \\(\\boldsymbol{\\Theta}\\) para iniciar la búsqueda, en fn se coloca la función de interés, en lower y upper se colocan vectores que indican los límites de búsqueda de cada parámetro, los \\(\\beta_k\\) pueden variar entre \\(-\\infty\\) y \\(\\infty\\) mientras que el parámetro \\(\\sigma\\) toma valores en el intervalo \\((0, \\infty)\\). Como la función minusll tiene argumentos adicionales y, x1 y x2, estos pasan a la función optim al final como se muestra en el código. mod1 &lt;- optim(par=c(0, 0, 0, 1), fn=minusll, method=&#39;L-BFGS-B&#39;, lower=c(-Inf, -Inf, -Inf, 0), upper=c(Inf, Inf, Inf, Inf), y=softdrink$tiempo, x1=softdrink$cantidad, x2=softdrink$distancia) En el objeto res1 está el resultado de la optimización, para explorar los resultados usamos mod1 ## $par ## [1] 2.34103296 1.61590757 0.01438512 3.05769678 ## ## $value ## [1] 63.41469 ## ## $counts ## function gradient ## 58 58 ## ## $convergence ## [1] 0 ## ## $message ## [1] &quot;CONVERGENCE: REL_REDUCTION_OF_F &lt;= FACTR*EPSMCH&quot; De esta forma el vector de parámetros estimados del modelo es \\(\\hat{\\boldsymbol{\\theta}}=(2.34, 1.62, 0.01, 3.06)^\\top\\). Usualmente en la práctica se usa la función lm para estimar el vector de parámetros, a continuación el código necesario para usar la funcion lm. mod2 &lt;- lm(tiempo ~ cantidad + distancia, data=softdrink) summary(mod2) ## ## Call: ## lm(formula = tiempo ~ cantidad + distancia, data = softdrink) ## ## Residuals: ## Min 1Q Median 3Q Max ## -5.7880 -0.6629 0.4364 1.1566 7.4197 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 2.341231 1.096730 2.135 0.044170 * ## cantidad 1.615907 0.170735 9.464 3.25e-09 *** ## distancia 0.014385 0.003613 3.981 0.000631 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 3.259 on 22 degrees of freedom ## Multiple R-squared: 0.9596, Adjusted R-squared: 0.9559 ## F-statistic: 261.2 on 2 and 22 DF, p-value: 4.687e-16 De la salida anterior vemos que el vector de parámetros estimados del modelo es \\(\\hat{\\boldsymbol{\\theta}}=(2.34, 1.62, 0.01, 3.26)^\\top\\). Para profundizar en el modelo de regresion lineal se recomienda consultar libro Modelos de Regresión con R "],["lmm.html", "3 Modelos Lineales Mixtos 3.1 Entrevista con Jim Ware y Nan Laird", " 3 Modelos Lineales Mixtos Los modelos lineales mixtos fueron propuestos por (Laird and Ware 1982) y en ellos se asume que existe una relación entre el vector de observaciones \\(\\boldsymbol{Y}_i\\) del sujeto o grupo \\(i\\) y las covariables por medio de la siguiente expresión \\[\\begin{equation} \\begin{aligned} \\boldsymbol{Y}_i \\mid \\boldsymbol{b}_i &amp;\\sim \\mathcal{N}(\\boldsymbol{X}_i \\boldsymbol{\\beta} + \\boldsymbol{Z}_i \\boldsymbol{b}_i, \\boldsymbol{\\Sigma}_i), \\\\ \\boldsymbol{b}_i &amp;\\sim \\mathcal{N}(\\boldsymbol{0}, \\boldsymbol{D}), \\end{aligned} \\tag{3.1} \\end{equation}\\] donde \\(\\boldsymbol{X}_i\\) y \\(\\boldsymbol{Z}_i\\) son matrices de diseño conocidas con la información de las covariables, siendo \\(\\boldsymbol{X}_i\\) de dimensión \\(n_i \\times p\\) y \\(\\boldsymbol{Z}_i\\) de dimensión \\(n_i \\times q\\). El elemento \\(\\boldsymbol{\\beta}\\) representa el vector de efectos fijos general, \\(\\boldsymbol{b}_i\\) el vector de efectos aleatorios exclusivo para el grupo \\(i\\). El vector \\(\\boldsymbol{b}_i\\) en la expresión (3.1) es llamado efecto aleatorio porque éste cambia la media de sujeto a sujeto y su función es la de mejorar el ajuste general dado por el elemento \\(\\boldsymbol{X}_i \\boldsymbol{\\beta}\\) al agregar la cantidad \\(\\boldsymbol{Z}_i \\boldsymbol{b}_i\\). El modelo dado en la expresión (3.1) es llamado también modelo mixto porque involucra tanto efectos fijos (\\(\\boldsymbol{\\beta}\\)) como efectos aleatorios (\\(\\boldsymbol{b}_i\\)). La distribución marginal de \\(\\boldsymbol{Y}_i\\) está dada por \\[\\begin{equation} f_i(\\boldsymbol{Y}_i) = \\int f(\\boldsymbol{Y}_i | \\boldsymbol{b}_i) f(\\boldsymbol{b}_i) \\, d \\boldsymbol{b}_i \\end{equation}\\] donde \\(f(\\boldsymbol{Y}_i | \\boldsymbol{b}_i)\\) y \\(f(\\boldsymbol{b}_i)\\) corresponden a las densidades normales mostradas en la expresión (3.1). Esta distribución marginal tiene forma cerrada y se puede mostrar fácilmente que la distribución de \\(\\boldsymbol{Y}_i\\) es una normal multivariada con vector de medias y matriz de covarianzas como se muestra a continuación. \\[\\begin{equation} \\boldsymbol{Y}_i \\sim \\mathcal{N}(\\boldsymbol{X}_i \\boldsymbol{\\beta}, \\boldsymbol{V}_i), \\end{equation}\\] donde \\(\\boldsymbol{V}_i=\\boldsymbol{Z}_i \\boldsymbol{D} \\boldsymbol{Z}_i^\\top + \\boldsymbol{\\Sigma}_i\\). El vector de parámetros en este caso es \\(\\boldsymbol{\\theta}=(\\boldsymbol{\\beta}, \\boldsymbol{\\alpha})^\\top\\) donde \\(\\boldsymbol{\\alpha}\\) consiste de los \\(q(q+1)/2\\) elementos diferentes de la matriz \\(\\boldsymbol{D}\\) y todos los elementos de la matriz \\(\\boldsymbol{\\Sigma}_i\\). 3.1 Entrevista con Jim Ware y Nan Laird References "],["shiny.html", "4 Aplicaciones shiny", " 4 Aplicaciones shiny En este capítulo se presentan aplicaciones shiny para ilustrar modelos con efectos aleatorios. Aplicación lmm con intercepto aleatorio. Aplicación lmm con intercepto y pendiente aleatorias. "],["pac-lme4.html", "5 Paquete lme4 5.1 Función lmer Ejemplo: modelo normal con intercepto aleatorio Ejemplo: recuperando los interceptos aleatorios 5.2 Función glmer Ejemplo: modelo gamma con intercepto aleatorio Ejemplo: modelo inversa gaussiana con intercepto y pendiente aleatoria", " 5 Paquete lme4 El paquete lme4 de Bates et al. (2022) es uno de los paquetes más completos para modelos mixtos. Al visitar este enlace se encontrará la página de apoyo del paquete, allí se puede consultar el manual de referencia y las viñetas. 5.1 Función lmer La función lmer es la principal función del paquete lme4. Esta función sirve para ajustar un modelo mixto y su estructura es la siguiente: lmer(formula, data = NULL, REML = TRUE, control = lmerControl(), start = NULL, verbose = 0L, subset, weights, na.action, offset, contrasts = NULL, devFunOnly = FALSE, ...) Los principales argumentos de la función son: formula: es una fórmula similar a la usada en el modelo lineal clásico. Un ejemplo de fórmula sería y ~ 1 + x1 + x2 + (1 + x2 | grupo) con la cual se indican los efectos fijos y los efectos aleatorios del modelo. Más abajo hay una tabla con más detalles sobre la fórmula. data: marco de datos donde están las variables. REML: valor lógico que sirve para indicar si queremos estimaciones maximizando la verosimilitud restringida o la verosimilitud usual. La siguiente imagen corresponde a la tabla 2 de la viñeta Fitting Linear Mixed-Effects Models using lme4. En la tabla las dos primeras columnas muestran formas equivalentes de incluir las estructuras de modelos mixtos más comunes. Ejemplo: modelo normal con intercepto aleatorio En este ejemplo vamos a simular observaciones \\(n_i=50\\) observaciones para \\(G=10\\) grupos (en total 500 obs) que tengan la estructura mostrada abajo. El objetivo del ejemplo es ilustrar el uso de la función lmer para estimar los parámetros del modelo. \\[\\begin{align*} y_{ij} | b_0 &amp;\\sim N(\\mu_{ij}, \\sigma^2_y) \\\\ \\mu_{ij} &amp;= 4 - 6 x_{ij} + b_{0i} \\\\ \\sigma^2_y &amp;= 16 \\\\ b_{0} &amp;\\sim N(0, \\sigma^2_{b0}=625) \\\\ x_{ij} &amp;\\sim U(-5, 6) \\end{align*}\\] El vector de parámetros de este modelo es \\(\\boldsymbol{\\Theta}=(\\beta_0=4, \\beta_1=-6, \\sigma_y=4, \\sigma_{b0}=25)^\\top\\). Solución. El código para simular las 500 observaciones se muestra a continuación. Observe que se fijó la semilla en dos ocasiones para que el lector pueda replicar el ejemplo y obtener los mismos resultados. ni &lt;- 50 G &lt;- 10 nobs &lt;- ni * G grupo &lt;- factor(rep(x=1:G, each=ni)) obs &lt;- rep(x=1:ni, times=G) set.seed(1234567) x &lt;- runif(n=nobs, min=-5, max=6) set.seed(1234567) b0 &lt;- rnorm(n=G, mean=0, sd=sqrt(625)) # Intercepto aleatorio b0 &lt;- rep(x=b0, each=ni) # El mismo intercepto aleatorio pero repetido media &lt;- 4 - 6 * x + b0 set.seed(1234567) y &lt;- rnorm(n=nobs, mean=media, sd=sqrt(16)) datos &lt;- data.frame(obs, grupo, b0, x, media, y) Vamos a explorar los datos simulados. library(rmarkdown) paged_table(datos, options = list(rows.print = 6)) El siguiente paso es dibujar los datos para explorar si sería apropiado usar un modelo con intercepto aleatorio (obvio porque así se simularon los datos). El código para dibujar los datos se muestra abajo. library(ggplot2) ggplot(datos, aes(x, y, color=grupo) ) + geom_point() + labs(colour=&quot;Grupo/Cluster&quot;) En la figura anterior se observa un patrón claro, todas las 10 nubes de puntos tienen la misma pendiente pero diferente intercepto con el eje vertical, eso se debe a que en la simulación se incluyó un \\(b_0\\). Para estimar los parámetros del modelos se usa la función mler de la siguiente forma. library(lme4) fit1 &lt;- lmer(y ~ x + (1 | grupo), data = datos) La función summary se puede usar sobre el objeto fit1 para obtener una tabla de resumen, a continuación se ilustra el uso y la salida de summary. summary(fit1) Según el resultado anterior \\(\\hat{\\boldsymbol{\\Theta}}=(\\hat{\\beta}_0=2.2378, \\hat{\\beta}_1=-6.0264, \\hat{\\sigma}_y=3.9352, \\hat{\\sigma}_{b0}=25.369)^\\top\\) mientras que el vector real de parámetros es \\(\\boldsymbol{\\Theta}=(\\beta_0=4, \\beta_1=-6, \\sigma_y=4, \\sigma_{b0}=25)^\\top\\). Compare los resultados de la tabla anterior obtenida con la función lmer anterior con los resultados obtenidos con la función lme de capítulo 7. ¿Hay alguna similitud? Ejemplo: recuperando los interceptos aleatorios ¿Cómo se pueden obtener los interceptos aleatorios a partir del modelo ajustado en la sección anterior? Solución. Para obtener los interceptos aleatorios se usa la función ranef del paquete lme4 de Bates et al. (2022). A continuación vamos a obtener los interceptos aleatorios y los vamos a comparar con los \\(b_0\\) simulados. interceptos_aleatorios &lt;- ranef(fit1) cbind(interceptos_aleatorios$grupo, b0=unique(b0)) ## (Intercept) b0 ## 1 5.388795 3.917594 ## 2 35.790443 34.345280 ## 3 19.885504 18.266756 ## 4 -31.893039 -33.770023 ## 5 1.074942 -0.212874 ## 6 10.680482 8.024547 ## 7 -43.320003 -44.453710 ## 8 25.363102 22.737596 ## 9 -20.648195 -22.985108 ## 10 -2.322031 -3.942871 De la salida anterior vemos que los \\(\\tilde{b}_0\\) son cercanos a los valores reales de \\(b_0\\). La comparación anterior solo es posible cuando usamos datos simulados. Cuando se usan datos de un fenómeno real no se tienen los valores de \\(b_0\\). 5.2 Función glmer La función glmer es la función del paquete lme4 para ajustar modelo lineales generalizados mixtos y su estructura es la siguiente: glmer(formula, data = NULL, family = gaussian, control = glmerControl(), start = NULL, verbose = 0L, nAGQ = 1L, subset, weights, na.action, offset, contrasts = NULL, mustart, etastart, devFunOnly = FALSE) Los principales argumentos de la función son: formula: es una fórmula similar a la usada en el modelo lineal clásico. Un ejemplo de fórmula sería y ~ 1 + x1 + x2 + (1 + x2) con la cual se indican los efectos fijos y los efectos aleatorios del modelo. Más abajo hay una tabla con más detalles sobre la fórmula. data: marco de datos donde están las variables. family: argumento para seleccionar la distribución de la variable respuesta. Para más detalles de las distribuciones y funciones de enlace se recomienda ver la ayuda de la función family escribiendo esto en la consola ?family. Ejemplo: modelo gamma con intercepto aleatorio En este ejemplo vamos a simular observaciones \\(n_i=20\\) observaciones para \\(G=10\\) grupos (en total 200 obs) que tengan la estructura mostrada abajo. El objetivo del ejemplo es ilustrar el uso de la función glmer para estimar los parámetros del modelo. \\[\\begin{align*} y_{ij} | b_0 &amp;\\sim Gamma(\\mu_{ij}, \\phi) \\\\ \\log(\\mu_{ij}) &amp;= 2 - 8 x_{ij} + b_{0i} \\\\ \\phi &amp;= 0.5 \\\\ b_{0} &amp;\\sim N(0, \\sigma^2_{b0}=9) \\\\ x_{ij} &amp;\\sim U(0, 1) \\end{align*}\\] El vector de parámetros de este modelo es \\(\\boldsymbol{\\Theta}=(\\beta_0=2, \\beta_1=-8, \\phi=0.5, \\sigma_{b0}=3)^\\top\\). Solución. La función rgamma_glm que se muestra a continuación es una modificación de la función rgamma para tener la parametrización usada en los glm. rgamma_glm &lt;- function(n, mu, phi) { x &lt;- rgamma(n=n, shape=1/phi, scale=mu*phi) return(x) } A continuación el código para simular datos del modelo de interés. ni &lt;- 20 G &lt;- 10 nobs &lt;- ni * G grupo &lt;- factor(rep(x=1:G, each=ni)) obs &lt;- rep(x=1:ni, times=G) set.seed(123456) x &lt;- runif(n=nobs, min=0, max=1) set.seed(123456) b0 &lt;- rnorm(n=G, mean=0, sd=sqrt(9)) # Intercepto aleatorio b0 &lt;- rep(x=b0, each=ni) # El mismo intercepto aleatorio pero repetido media &lt;- exp(2 - 8 * x + b0) set.seed(123456) y &lt;- rgamma_glm(n=nobs, mu=media, phi=0.5) datos &lt;- data.frame(obs, grupo, b0, x, media, y) Vamos a explorar los datos simulados. library(rmarkdown) paged_table(datos, options = list(rows.print = 6, cols.print=6)) El siguiente paso es explorar los datos simulados. El código para dibujar los datos se muestra abajo. library(ggplot2) ggplot(datos, aes(x, y, color=grupo) ) + geom_point() + labs(colour=&quot;Grupo/Cluster&quot;) Para estimar los parámetros del modelos se usa la función glmer de la siguiente forma. library(lme4) fit2 &lt;- glmer(y ~ x + (1 | grupo), family=Gamma(link=&quot;log&quot;), data = datos) La función summary se puede usar sobre el objeto fit2 para obtener una tabla de resumen, a continuación se muestra la salida de summary. summary(fit2) ## Generalized linear mixed model fit by maximum likelihood (Laplace ## Approximation) [glmerMod] ## Family: Gamma ( log ) ## Formula: y ~ x + (1 | grupo) ## Data: datos ## ## AIC BIC logLik deviance df.resid ## 591.6 604.8 -291.8 583.6 196 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -1.4164 -0.7151 -0.2155 0.5631 3.0609 ## ## Random effects: ## Groups Name Variance Std.Dev. ## grupo (Intercept) 4.3265 2.0800 ## Residual 0.4728 0.6876 ## Number of obs: 200, groups: grupo, 10 ## ## Fixed effects: ## Estimate Std. Error t value Pr(&gt;|z|) ## (Intercept) 4.3965 0.9566 4.596 4.31e-06 *** ## x -8.0784 0.0411 -196.549 &lt; 2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Correlation of Fixed Effects: ## (Intr) ## x -0.021 Según el resultado anterior \\(\\hat{\\boldsymbol{\\Theta}}=(\\hat{\\beta}_0=4.3965, \\hat{\\beta}_1=-8.0784, \\hat{\\phi}=0.4728, \\hat{\\sigma}_{bo}=4.3265)^\\top\\) mientras que el vector real de parámetros es \\(\\boldsymbol{\\Theta}=(\\beta_0=2, \\beta_1=-8, \\phi=0.50, \\sigma_{b0}=3)^\\top\\). El valor de \\(\\hat{\\phi}\\) se encuentra en la línea Residual y columna Variance del bloque Random effects que está en el summary. Ejemplo: modelo inversa gaussiana con intercepto y pendiente aleatoria En este ejemplo vamos a simular observaciones \\(n_i=20\\) observaciones para \\(G=10\\) grupos (en total 200 obs) que tengan la estructura mostrada abajo. El objetivo del ejemplo es ilustrar el uso de la función glmer para estimar los parámetros del modelo. \\[\\begin{align*} y_{ij} | b_0, b_1 &amp;\\sim InvGauss(\\mu_{ij}, \\phi) \\\\ \\log(\\mu_{ij}) &amp;= 2 - 8 x_{ij} + b_{0i} + b_{1i} x_{ij} \\\\ \\phi &amp;= 0.5 \\\\ \\left ( \\begin{matrix} b_{0} \\\\ b_{1} \\end{matrix} \\right ) &amp;\\sim N\\left ( \\left [ \\begin{matrix} 0 \\\\ 0 \\end{matrix} \\right ], \\left [ \\begin{matrix} \\sigma^2_{b0}=1 &amp; \\sigma_{b01}=0.5 \\\\ \\sigma_{b01} &amp; \\sigma^2_{b1}=1 \\end{matrix} \\right ] \\right ) \\\\ x_{ij} &amp;\\sim U(0, 1) \\end{align*}\\] El vector de parámetros de este modelo es \\(\\boldsymbol{\\Theta}=(\\beta_0=2, \\beta_1=-8, \\phi=0.5, \\sigma_{b0}^2=1, \\sigma_{b1}^2=1, \\sigma_{b01}=0.5)^\\top\\). Solución. Para simular valores de una distribución inversa gaussiana vamos a usar la función rinvgauss del paquete statmod de Smyth et al. (2022). A continuación el código para simular datos del modelo de interés. ni &lt;- 20 G &lt;- 10 nobs &lt;- ni * G grupo &lt;- factor(rep(x=1:G, each=ni)) obs &lt;- rep(x=1:ni, times=G) set.seed(12345) x &lt;- runif(n=nobs, min=0, max=1) set.seed(12345) Sigma &lt;- matrix(c(1, 0.5, # Matriz de var-cov 0.5, 1), ncol=2, nrow=2) b &lt;- MASS::mvrnorm(n=G, mu=rep(0, 2), Sigma=Sigma) # Simulando b0 y b1 b &lt;- apply(b, MARGIN=2, function(c) rep(c, each=ni)) # Replicando b0 &lt;- as.vector(b[, 1]) # Separando los b0 b1 &lt;- as.vector(b[, 2]) # Separando los b1 media &lt;- exp(2 - 8 * x + b0 + b1 * x) phi &lt;- 0.5 set.seed(12345) y &lt;- statmod::rinvgauss(n=nobs, mean=media, dispersion=phi) datos &lt;- data.frame(obs, grupo, b0, x, media, y) Vamos a explorar los datos simulados. library(rmarkdown) paged_table(datos, options = list(rows.print = 6, cols.print=6)) El siguiente paso es explorar los datos simulados. El código para dibujar los datos se muestra abajo. library(ggplot2) ggplot(datos, aes(x, y, color=grupo) ) + geom_point() + labs(colour=&quot;Grupo/Cluster&quot;) Para estimar los parámetros del modelos se usa la función glmer de la siguiente forma. library(lme4) fit3 &lt;- glmer(y ~ x + (1 + x | grupo), family=inverse.gaussian(link=&quot;log&quot;), data = datos) La función summary se puede usar sobre el objeto fit3 para obtener una tabla de resumen, a continuación se muestra la salida de summary. summary(fit3) ## Generalized linear mixed model fit by maximum likelihood (Laplace ## Approximation) [glmerMod] ## Family: inverse.gaussian ( log ) ## Formula: y ~ x + (1 + x | grupo) ## Data: datos ## ## AIC BIC logLik deviance df.resid ## -1060.0 -1040.2 536.0 -1072.0 194 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -1.7657 -0.5806 -0.1294 0.4044 6.5944 ## ## Random effects: ## Groups Name Variance Std.Dev. Corr ## grupo (Intercept) 0.6118 0.7822 ## x 0.3740 0.6116 0.33 ## Residual 0.7266 0.8524 ## Number of obs: 200, groups: grupo, 10 ## ## Fixed effects: ## Estimate Std. Error t value Pr(&gt;|z|) ## (Intercept) 1.7907 0.2947 6.077 1.22e-09 *** ## x -8.0237 0.2345 -34.218 &lt; 2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Correlation of Fixed Effects: ## (Intr) ## x 0.268 Según el resultado anterior \\(\\hat{\\boldsymbol{\\Theta}}=(\\hat{\\beta}_0=1.7907, \\hat{\\beta}_1=-8.0237, \\hat{\\phi}=0.7266, \\hat{\\sigma}_{b0}^2=0.6118, \\hat{\\sigma}_{b1}^2=0.3740, \\hat{\\sigma}_{b01}=0.1579)^\\top\\) mientras que el vector real de parámetros es \\(\\boldsymbol{\\Theta}=(\\beta_0=2, \\beta_1=-8, \\phi=0.5, \\sigma_{b0}^2=1, \\sigma_{b1}^2=1, \\sigma_{b01}=0.5)^\\top\\). El parámetro estimado \\(\\hat{\\sigma}_{b01}\\) se obtiene utilizando la ecuación de correlación (\\(\\rho\\)) que relaciona la covarianza y desviaciones de los efectos aleatorios: \\(\\rho_{b0b1} = \\sigma_{b0b1}/(\\sigma_{b0} \\times \\sigma_{b1})\\). El valor de \\(\\hat{\\phi}\\) se encuentra en la línea Residual y columna Variance del bloque Random effects que está en el summary. References "],["apli-lme4.html", "6 Aplicación con lme4 Ejercicios", " 6 Aplicación con lme4 En este capítulo se mostrará como usar el paquete lme4 para la aplicación de modelos mixtos con la base de datos sleepstudy del mismo paquete. A continuación la base de datos a utilizar. library(lme4) head(sleepstudy) ## Reaction Days Subject ## 1 249.5600 0 308 ## 2 258.7047 1 308 ## 3 250.8006 2 308 ## 4 321.4398 3 308 ## 5 356.8519 4 308 ## 6 414.6901 5 308 Esta base de datos sobre el tiempo de reacción promedio por día para un conjunto de individuos, en un estudio de privación del sueño, contiene la información sobre el tiempo de reacción promedio (Reaction), el número de días de privación del sueño (Days), donde el día 0 corresponde al día en el que los indiviuos tenían su cantidad normal de sueño, y el número del individuo (en total 18) sobre el que se realizó la observación (Subject). A partir del día 0, hubo una restricción en cada individuo a 3 horas de sueño por noche. library(ggplot2) ggplot(data = sleepstudy, aes(x = Days, y = Reaction, color = Subject)) + geom_point() + theme_bw() + facet_wrap(~ Subject) + labs(y = &quot;Reaction time&quot;) + theme(legend.position = &quot;none&quot;) De la figura anterior vemos que el tiempo de reacción promedio, tanto en el día 0 como en los siguientes días de prueba (del día 1 al día 9), son distintos en cada uno de los individuos. Esta situación conlleva a probar la hipótesis de que el tiempo de reacción promedio en una serie de pruebas varía según los individuos. Esto es, ajustar un modelo donde el intercepto y la pendiente se consideran como efectos aleatorios. Un modelo lineal mixto que describe la anterior situación se puede escribir como: \\[\\begin{align*} Reaction_{ij} | b_0, b_1 &amp;\\sim N(\\mu_{ij}, \\sigma^2_{Reaction}) \\\\ \\mu_{ij} &amp;= \\beta_0 + \\beta_1 Days_{ij} + b_{0i} + b_{1i} Days_{ij} \\\\ \\left ( \\begin{matrix} b_{0} \\\\ b_{1} \\end{matrix} \\right ) &amp;\\sim N\\left ( \\left [ \\begin{matrix} 0 \\\\ 0 \\end{matrix} \\right ], \\left [ \\begin{matrix} \\sigma^2_{b0} &amp; \\sigma_{b01} \\\\ \\sigma_{b01} &amp; \\sigma^2_{b1} \\end{matrix} \\right ] \\right ) \\end{align*}\\] Aquí, los individuos (\\(i\\)) varían en el tiempo de reacción promedio tanto en su intercepto (\\(b_{0i}\\)) como en su pendiente (\\(b_{1i}\\)), que en conjunto componen la varianza total en dicho tiempo atribuible a la variación entre individuos. Esta contribución individual se cuantifica usando un modelo de intercepto y pendiente aleatoria con distribución normal (\\(N\\)). La variación entre individuos en intercepto y pendiente es \\(\\sigma^2_{b0}\\) y \\(\\sigma^2_{b1}\\), respectivamente. La covarianza entre el intercepto y la pendiente esta dada por \\(\\sigma_{b01}\\). El vector de parámetros para este modelo sería \\(\\boldsymbol{\\Theta}=(\\beta_0, \\beta_1, \\sigma_{reaction}, \\sigma_{b0}, \\sigma_{b1}, \\sigma_{b0b1})^\\top\\). Para ajustar el modelo de intercepto y pendiente aleatoria planteado usando el paquete lme4 podemos usar el siguiente código: fit &lt;- lmer(Reaction ~ Days + (Days | Subject), REML = TRUE, data = sleepstudy) Para obtener la tabla de resumen usamos: summary(fit) ## Linear mixed model fit by REML [&#39;lmerMod&#39;] ## Formula: Reaction ~ Days + (Days | Subject) ## Data: sleepstudy ## ## REML criterion at convergence: 1743.6 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -3.9536 -0.4634 0.0231 0.4634 5.1793 ## ## Random effects: ## Groups Name Variance Std.Dev. Corr ## Subject (Intercept) 612.10 24.741 ## Days 35.07 5.922 0.07 ## Residual 654.94 25.592 ## Number of obs: 180, groups: Subject, 18 ## ## Fixed effects: ## Estimate Std. Error t value ## (Intercept) 251.405 6.825 36.838 ## Days 10.467 1.546 6.771 ## ## Correlation of Fixed Effects: ## (Intr) ## Days -0.138 De la salida anterior se obtienen los siguientes parámetros estimados \\[ \\hat{\\boldsymbol{\\Theta}} = (\\hat{\\beta_0}=251.40, \\hat{\\beta_1}=10.47, \\hat{\\sigma}_{reaction}=25.59, \\hat{\\sigma}_{b0}=24.74, \\hat{\\sigma}_{b1}=5.92, \\hat{\\sigma}_{b0b1}=10.25)^\\top \\] El último parámetro estimado se obtiene utilizando la ecuación de correlación que relaciona la correlación, la covarianza y las desviaciones de los efectos aleatorios: \\(\\rho_{b0b1} = \\sigma_{b0b1}/(\\sigma_{b0} \\times \\sigma_{b1})\\) Usando la información anterior se puede escribir el modelo ajustado de la siguiente manera: \\[\\begin{align*} Reaction_{ij} &amp;\\sim N(\\hat{\\mu}_{ij}, 25.59^2) \\\\ \\hat{\\mu}_{ij} &amp;= 251.40 + 10.47 Days_{ij} + \\tilde{b}_{0i} + \\tilde{b}_{1i} Days_{ij} \\\\ \\left ( \\begin{matrix} b_{0} \\\\ b_{1} \\end{matrix} \\right ) &amp;\\sim N\\left ( \\left [ \\begin{matrix} 0 \\\\ 0 \\end{matrix} \\right ], \\left [ \\begin{matrix} 24.74^2 &amp; 10.25 \\\\ 10.25 &amp; 5.92^2 \\end{matrix} \\right ] \\right ) \\end{align*}\\] Los elementos \\(b_{0i}\\) y \\(b_{1i}\\) se deben substituir por sus respectivas predicciones \\(\\tilde{b}_{0i}\\) y \\(\\tilde{b}_{1i}\\) y se pueden obtener del modelo ajustado de esta forma: ranef(fit) ## $Subject ## (Intercept) Days ## 308 2.2585509 9.1989758 ## 309 -40.3987381 -8.6196806 ## 310 -38.9604090 -5.4488565 ## 330 23.6906196 -4.8143503 ## 331 22.2603126 -3.0699116 ## 332 9.0395679 -0.2721770 ## 333 16.8405086 -0.2236361 ## 334 -7.2326151 1.0745816 ## 335 -0.3336684 -10.7521652 ## 337 34.8904868 8.6282652 ## 349 -25.2102286 1.1734322 ## 350 -13.0700342 6.6142178 ## 351 4.5778642 -3.0152621 ## 352 20.8636782 3.5360011 ## 369 3.2754656 0.8722149 ## 370 -25.6129993 4.8224850 ## 371 0.8070461 -0.9881562 ## 372 12.3145921 1.2840221 ## ## with conditional variances for &quot;Subject&quot; Y los valores de los efectos fijos estimados se pueden obtener así: fixef(fit) ## (Intercept) Days ## 251.40510 10.46729 Con base en la información anterior de efectos aleatorios y fijos, es posible escribir la ecuación del modelo para cada individuo. Para esto, se debe considerar los efectos fijos estimados (\\(\\hat{\\beta}_0 \\approx 251.40\\) y \\(\\hat{\\beta}_1\\approx 10.47\\)) y los efectos aleatorios de cada uno de los individuos (por ejemplo para el individuo 308, \\(\\tilde{b}_{0, i=308} \\approx 2.26\\) y \\(\\tilde{b}_{1, i=308} \\approx 9.20\\)). Así, el valor medio del individuo 308 se calcula como: \\[\\begin{align*} \\hat{\\mu}_{i=308, j} &amp;= \\hat{\\beta}_0 + \\hat{\\beta}_0 \\, Days_{i=308, j} + \\tilde{b}_{0, i=308} + \\tilde{b}_{1, i=308} \\, Days_{i=308, j} \\\\ \\hat{\\mu}_{i=308, j} &amp;= 251.40 + 10.47 \\, Days_{i=308, j} 2.26 + 9.20 \\, Days_{i=308, j} \\\\ \\hat{\\mu}_{i=308, j} &amp;= 253.66 + 19.67 \\, Days_{i=308, j} \\end{align*}\\] Lo anterior se puede resumir en el siguiente modelo. \\[\\begin{align*} Reaction_{i=308, j} &amp;\\sim N(\\hat{\\mu}_{i=308, j}, \\hat{\\sigma}^2_{Reaction}) \\\\ \\hat{\\mu}_{i=308, j} &amp;= 253.66 + 19.67 \\, Days_{i=308, j} \\\\ \\hat{\\sigma}_{Reaction} &amp;= 25.59 \\end{align*}\\] Los efectos fijos y aleatorios de la expresión anterior para cada uno de los individuos se pueden obtener con R de la siguiente forma: coef(fit) ## $Subject ## (Intercept) Days ## 308 253.6637 19.6662617 ## 309 211.0064 1.8476053 ## 310 212.4447 5.0184295 ## 330 275.0957 5.6529356 ## 331 273.6654 7.3973743 ## 332 260.4447 10.1951090 ## 333 268.2456 10.2436499 ## 334 244.1725 11.5418676 ## 335 251.0714 -0.2848792 ## 337 286.2956 19.0955511 ## 349 226.1949 11.6407181 ## 350 238.3351 17.0815038 ## 351 255.9830 7.4520239 ## 352 272.2688 14.0032871 ## 369 254.6806 11.3395008 ## 370 225.7921 15.2897709 ## 371 252.2122 9.4791297 ## 372 263.7197 11.7513080 ## ## attr(,&quot;class&quot;) ## [1] &quot;coef.mer&quot; A continuación usted podrá observar el diagrama de dispersión mostrado al inicio de este capitulo con la recta de regresión para cada individuo. El código de R para obtener esto se presenta a continuación: fit &lt;- lmer(Reaction ~ Days + (Days | Subject), REML = TRUE, data = sleepstudy) sleepstudy$pred_inter_pend_aleatorio &lt;- predict(fit) ggplot(data = sleepstudy, aes(x = Days, y = pred_inter_pend_aleatorio, color = Subject)) + geom_line() + geom_point(aes(x = Days, y = Reaction, color = Subject)) + geom_abline(intercept = 251.40, slope = 10.47, color = &quot;black&quot;, linetype = &quot;dashed&quot;, size = 0.5) + theme_bw() + facet_wrap(~ Subject) + theme(legend.position = &quot;none&quot;) + labs(y = &quot;Reaction time&quot;) La figura anterior corresponde a un modelo de intercepto y pendiente aleatoria, en el que se permite que tanto los interceptos como las pendientes varíen según los individuos. Las líneas continuas corresponde a la recta de regresión ajustada a los datos. Los puntos representan las observaciones (tiempo de reacción promedio por día) medidas en cada uno de los individuos. La línea negra discontinua representa el valor medio global de la distribución de los efectos aleatorios. A continuación usted encontrará una figura con cuatro páneles donde se muestran los resultados de cuatro modelos distintos, entre ellos el modelo mixto con intercepto y pendiente aleatoria del ejemplo anterior. Con base en estas figuras, responda las preguntas siguientes. Ejercicios Ajuste el modelo con intercepto aleatorio mostrado en el panel 2. ¿Qué opina de este modelo? Ajuste el modelo con pendiente aleatoria presentado en el panel 3. ¿Qué opina de este modelo? Ajustar solo un intercepto aleatorio permite que los individuos varíen asumiendo que los mismos tienen una pendiente común (panel 2). Al ajustar solo una pendiente aleatoria (panel 3) permite que la pendiente de un predictor varíe en función de los individuos (la variable de agrupación). Con base esto y teniendo en cuenta el modelo de intercepto y pendiente aleatoria (panel 4), evalúe cual de estos estos modelos permite un mejor ajuste de los datos presentados en la base de datos sleepstudy del paquete lme4. "],["pac-nlme.html", "7 Paquete nlme 7.1 Función lme Ejemplo: modelo normal con intercepto aleatorio", " 7 Paquete nlme El paquete nlme de José Pinheiro, Bates, and R Core Team (2022) es otro de los paquetes para modelos mixtos. Al visitar este enlace se encontrará la página de apoyo del paquete, allí se puede consultar el manual de referencia. 7.1 Función lme La función lme es la principal función del paquete nlme. Esta función sirve para ajustar un modelo mixto y su estructura es la siguiente: lme(fixed, data, random, correlation, weights, subset, method, na.action, control, contrasts = NULL, keep.data = TRUE) Los principales argumentos de la función son: formula: es una fórmula similar a la usada en el modelo lineal clásico. Un ejemplo de fórmula sería y ~ 1 + x1 + x2 con la cual se indican los efectos fijos del modelo. - data: marco de datos donde están las variables. random: es una fórmula solo con lado derecho. Si queremos indicar intercepto aleatorio se escribe ~ 1 | group y si se desea intercepto y pendiente aleatoria se escribe ~ 1 + x2 | group. correlation: es un parámetro opcional para indicar la estructura de correlación entre las observaciones de cada grupo. Para más detalles consulte la ayuda de la función corClasses. method: valor lógico que sirve para indicar si queremos estimaciones maximizando la verosimilitud restringida o la verosimilitud usual, las dos opciones son ML o REML. Ejemplo: modelo normal con intercepto aleatorio En este ejemplo vamos a simular observaciones \\(n_i=50\\) observaciones para \\(G=10\\) grupos (en total 500 obs) que tengan la estructura mostrada abajo. El objetivo del ejemplo es ilustrar el uso de la función lmer para estimar los parámetros del modelo. \\[\\begin{align*} y_{ij} | b_0 &amp;\\sim N(\\mu_{ij}, \\sigma^2_y) \\\\ \\mu_{ij} &amp;= 4 - 6 x_{ij} + b_{0i} \\\\ \\sigma^2_y &amp;= 16 \\\\ b_{0} &amp;\\sim N(0, \\sigma^2_{b0}=625) \\\\ x_{ij} &amp;\\sim U(-5, 6) \\end{align*}\\] El vector de parámetros de este modelo es \\(\\boldsymbol{\\Theta}=(\\beta_0=4, \\beta_1=-6, \\sigma_y=4, \\sigma_{b0}=25)^\\top\\). Solución. El código para simular las 500 observaciones se muestra a continuación. Observe que se fijó la semilla para que el lector pueda replicar el ejemplo y obtener los mismos resultados. ni &lt;- 50 G &lt;- 10 nobs &lt;- ni * G grupo &lt;- factor(rep(x=1:G, each=ni)) obs &lt;- rep(x=1:ni, times=G) set.seed(1234567) x &lt;- runif(n=nobs, min=-5, max=6) set.seed(1234567) b0 &lt;- rnorm(n=G, mean=0, sd=sqrt(625)) # Intercepto aleatorio b0 &lt;- rep(x=b0, each=ni) # El mismo intercepto aleatorio pero repetido media &lt;- 4 - 6 * x + b0 set.seed(1234567) y &lt;- rnorm(n=nobs, mean=media, sd=sqrt(16)) datos &lt;- data.frame(obs, grupo, b0, x, media, y) Vamos a explorar los datos simulados. library(rmarkdown) paged_table(datos, options = list(rows.print = 6)) El siguiente paso es dibujar los datos para explorar si sería apropiado usar un modelo con intercepto aleatorio (obvio porque así se simularon los datos). El código para dibujar los datos se muestra abajo. library(ggplot2) ggplot(datos, aes(x, y, color=grupo) ) + geom_point() + labs(colour=&quot;Grupo/Cluster&quot;) En la figura anterior se observa un patrón claro, todas las 10 nubes de puntos tienen la misma pendiente pero diferente intercepto con el eje vertical, eso se debe a que en la simulación se incluyó un \\(b_0\\). Para estimar los parámetros del modelos se usa la función mler de la siguiente forma. library(nlme) fit1 &lt;- lme(y ~ x, random = ~ 1 | grupo, data=datos) La función summary se puede usar sobre el objeto fit para obtener una tabla de resumen, a continuación se ilustra el uso y la salida de summary. summary(fit1) Según el resultado anterior \\(\\hat{\\boldsymbol{\\Theta}}=(\\hat{\\beta}_0=2.2378, \\hat{\\beta}_1=-6.0264, \\hat{\\sigma}_y=3.9354, \\hat{\\sigma}_{b0}=25.3690)^\\top\\) mientras que el vector real de parámetros es \\(\\boldsymbol{\\Theta}=(\\beta_0=4, \\beta_1=-6, \\sigma_y=4, \\sigma_{b0}=25)^\\top\\). Compare los resultados de la tabla anterior obtenida con la función lme anterior con los resultados obtenidos con la función lmer de capítulo 5. ¿Hay alguna similitud? References "],["apli-nlme.html", "8 Aplicación con nlme Ejercicios", " 8 Aplicación con nlme En este capítulo se mostrará como usar el paquete nlme para la aplicación de modelos mixtos con la base de datos Oxboys del mismo paquete. A continuación la base de datos a utilizar. library(nlme) head(Oxboys) ## Grouped Data: height ~ age | Subject ## Subject age height Occasion ## 1 1 -1.0000 140.5 1 ## 2 1 -0.7479 143.4 2 ## 3 1 -0.4630 144.8 3 ## 4 1 -0.1643 147.1 4 ## 5 1 -0.0027 147.7 5 ## 6 1 0.2466 150.2 6 Esta base de datos sobre crecimiento contiene la información sobre altura (heigth), edad estandarizada (age) de un grupo de 26 jóvenes. Como la base de datos Oxboys es de la clase groupedData, es posible aplicar un plot directamente y el resultado se muestra continuación. plot(Oxboys) Es posible convertir un data.frame para que tenga la clase groupedData, consulte la ayuda de la función groupedData del paquete nlme para más detalles. De la figura anterior vemos que las curvas de crecimiento inician a diferente altura (intercepto) y que la pendiente del crecimiento no son todas iguales, por ejemplo, el individuo 21 creció más rápido que el individuo 3. Esto nos hace pensar que un modelo con intercepto y pendiente aleatoria podrían ser adecuados para modelar el crecimiento. En las siguientes ecuaciones se resume el modelo matemático que interesa en esta situación. \\[\\begin{align*} Height_{ij} | b_0, b_1 &amp;\\sim N(\\mu_{ij}, \\sigma^2_{Heigth}) \\\\ \\mu_{ij} &amp;= \\beta_0 + \\beta_1 Age_{ij} + b_{0i} + b_{1i} Age_{ij} \\\\ \\left ( \\begin{matrix} b_{0} \\\\ b_{1} \\end{matrix} \\right ) &amp;\\sim N\\left ( \\left ( \\begin{matrix} 0 \\\\ 0 \\end{matrix} \\right ), \\left ( \\begin{matrix} \\sigma^2_{b0} &amp; \\sigma_{b01} \\\\ \\sigma_{b01} &amp; \\sigma^2_{b1} \\end{matrix} \\right ) \\right ) \\end{align*}\\] El vector de parámetros para este modelo sería \\(\\boldsymbol{\\Theta}=(\\beta_0, \\beta_1, \\sigma_{height}, \\sigma_{b0}, \\sigma_{b1}, \\sigma_{b0b1})^\\top\\). Para ajustar este modelo a los datos con el paquete nlme podemos usar el siguiente código. fit &lt;- lme(height ~ age, random= ~ 1 + age | Subject, data=Oxboys, method=&quot;REML&quot;) Para obtener la tabla de resumen usamos: summary(fit) ## Linear mixed-effects model fit by REML ## Data: Oxboys ## AIC BIC logLik ## 736.091 756.7714 -362.0455 ## ## Random effects: ## Formula: ~1 + age | Subject ## Structure: General positive-definite, Log-Cholesky parametrization ## StdDev Corr ## (Intercept) 8.081077 (Intr) ## age 1.680717 0.641 ## Residual 0.659889 ## ## Fixed effects: height ~ age ## Value Std.Error DF t-value p-value ## (Intercept) 149.37175 1.5854173 207 94.21605 0 ## age 6.52547 0.3363003 207 19.40370 0 ## Correlation: ## (Intr) ## age 0.628 ## ## Standardized Within-Group Residuals: ## Min Q1 Med Q3 Max ## -2.65092109 -0.57493341 -0.02842894 0.59604254 2.60496077 ## ## Number of Observations: 234 ## Number of Groups: 26 De la salida anterior se obtiene que \\(\\hat{\\boldsymbol{\\Theta}}=(\\hat{\\beta}_0=149.37, \\hat{\\beta}_1=6.53, \\hat{\\sigma}_{height}=0.66, \\hat{\\sigma}_{b0}=8.08, \\hat{\\sigma}_{b1}=1.68, \\hat{\\sigma}_{b0b1}=8.71)^\\top\\). La estimación \\(\\hat{\\sigma}_{b0b1}\\) no aparece directamente en el summary pero se obtiene utilizando la ecuación \\(Cor=Cov/(\\sigma_1 \\sigma_2)\\) que relaciona correlación, covarianza y desviaciones de los efectos aleatorios. Usando la información anterior se puede escribir el modelo ajustado de la siguiente manera. \\[\\begin{align*} Height_{ij} &amp;\\sim N(\\hat{\\mu}_{ij}, 0.66^2) \\\\ \\hat{\\mu}_{ij} &amp;= 149.37 + 6.53 Age_{ij} + b_{0i} + b_{1i} Age_{ij} \\\\ \\left ( \\begin{matrix} b_{0} \\\\ b_{1} \\end{matrix} \\right ) &amp;\\sim N\\left ( \\left ( \\begin{matrix} 0 \\\\ 0 \\end{matrix} \\right ), \\left ( \\begin{matrix} 8.08^2 &amp; 8.71 \\\\ 8.71 &amp; 1.68^2 \\end{matrix} \\right ) \\right ). \\end{align*}\\] Los elementos \\(b_{0i}\\) y \\(b_{1i}\\) se deben substituir por sus respectivas predicciones \\(\\tilde{b}_{0i}\\) y \\(\\tilde{b}_{1i}\\) y se pueden obtener del modelo ajustado así: ranef(fit) ## (Intercept) age ## 10 -19.0972476 -2.78657472 ## 26 -11.3675996 -0.97474075 ## 25 -10.1595528 -2.42702035 ## 9 -11.2213331 -0.58069044 ## 2 -6.5096277 -1.07136271 ## 6 -2.5902388 -2.41771656 ## 7 -3.2473132 -1.46379286 ## 17 -6.3744842 1.89443713 ## 16 -1.8344703 -1.86707015 ## 15 -5.0856366 0.51526141 ## 8 -1.0776201 -0.06615528 ## 20 2.0850836 -1.99239802 ## 1 -1.2464285 0.59919226 ## 18 1.8031920 -0.51486646 ## 5 2.0531168 -0.24308081 ## 23 1.6937341 0.63140824 ## 11 0.6839704 1.85733185 ## 21 1.1525543 0.91894343 ## 3 6.2613001 -1.58181075 ## 24 3.7645669 0.25652772 ## 22 5.1957592 1.50551719 ## 12 7.4308033 0.52297645 ## 13 6.7004368 1.89758007 ## 14 10.0986013 2.09367207 ## 19 15.1957040 2.50720025 ## 4 15.6927297 2.78723179 Los valores de los efectos fijos estimados se pueden obtener así: fixef(fit) ## (Intercept) age ## 149.371753 6.525469 Usando la información de los efectos fijo y aleatorios obtenidos antes, es posible escribir la ecuación del modelo para cada individuo. Los efectos fijos estimados fueron \\(\\hat{\\beta}_0 \\approx 149.37\\) y \\(\\hat{\\beta}_1\\approx 6.53\\). Para el sujeto # 10 se obtuvo \\(\\tilde{b}_{0, i=10} \\approx -19.10\\) y \\(\\tilde{b}_{1, i=10} \\approx -2.79\\), así la media del individuo # 10 se calcula así: \\[\\begin{align*} \\hat{\\mu}_{i=10, j} &amp;= \\hat{\\beta}_0 + \\hat{\\beta}_0 \\, Age_{i=10, j} + \\tilde{b}_{0, i=10} + \\tilde{b}_{1, i=10} \\, Age_{i=10, j} \\\\ \\hat{\\mu}_{i=10, j} &amp;= 149.37 + 6.53 \\, Age_{i=10, j} - 19.10 - 2.79 \\, Age_{i=10, j} \\\\ \\hat{\\mu}_{i=10, j} &amp;= 130.27 + 3.74 \\, Age_{i=10, j} \\end{align*}\\] Lo anterior se puede resumir en el siguiente modelo. \\[\\begin{align*} Height_{i=10, j} &amp;\\sim N(\\hat{\\mu}_{i=10, j}, \\hat{\\sigma}^2_{Height}) \\\\ \\hat{\\mu}_{i=10, j} &amp;= 130.27 + 3.74 \\, Age_{i=10, j} \\\\ \\hat{\\sigma}_{Height} &amp;= 0.66 \\end{align*}\\] La expresión anterior para cada individuo con los efectos finales (fijos y aleatorios) se puede obtener con R así: coef(fit) ## (Intercept) age ## 10 130.2745 3.738894 ## 26 138.0042 5.550728 ## 25 139.2122 4.098448 ## 9 138.1504 5.944778 ## 2 142.8621 5.454106 ## 6 146.7815 4.107752 ## 7 146.1244 5.061676 ## 17 142.9973 8.419906 ## 16 147.5373 4.658399 ## 15 144.2861 7.040730 ## 8 148.2941 6.459313 ## 20 151.4568 4.533071 ## 1 148.1253 7.124661 ## 18 151.1749 6.010602 ## 5 151.4249 6.282388 ## 23 151.0655 7.156877 ## 11 150.0557 8.382801 ## 21 150.5243 7.444412 ## 3 155.6331 4.943658 ## 24 153.1363 6.781996 ## 22 154.5675 8.030986 ## 12 156.8026 7.048445 ## 13 156.0722 8.423049 ## 14 159.4704 8.619141 ## 19 164.5675 9.032669 ## 4 165.0645 9.312700 En la presente aplicación es posible incluir la recta de regresión para cada individuo al diagrama de dispersión original. El código de R para obtener esto es el siguiente. library(lattice) xyplot(height ~ age | Subject, data=Oxboys, fit=fit, strip=strip.custom(bg=&quot;white&quot;), pch=16, cex=0.7, col=&#39;indianred1&#39;, panel = function(x, y, ..., fit, subscripts) { panel.xyplot(x, y, ...) ypred &lt;- fitted(fit)[subscripts] panel.lines(x, ypred, col=&quot;deepskyblue3&quot;, lwd=1) }, ylab=&quot;Height (cm)&quot;, xlab=&quot;Centered age&quot;) En la figura anterior se tienen las observaciones (crecimiento) representado por los puntos rojos, adicionalmente, aparece una recta de color azul que representa la recta de regresión para cada individuo. De la figura se observa que la linea logra explicar la evolución del crecimiento para cada individuo. Ejercicios Repita el ejercicio anterior considerando un modelo sólo con intercepto aleatorio. Dibuje las rectas de regresión para cada individuo. ¿Qué opina de este modelo? Repita el ejercicio anterior considerando un modelo sólo con pendiente aleatoria. Dibuje las rectas de regresión para cada individuo. ¿Qué opina de este modelo? Estime la estatura para el individuo # 3 cuando su edad centrada sea de 1.1. Replique los ejemplo de este documento. "],["apli-rat-pup.html", "9 Aplicación rat pup", " 9 Aplicación rat pup En este capítulo se mostrará un ejemplo de un modelo mixto con dos niveles usando la base de datos RatPupWeight del paquete nlme. Este ejemplo corresponde al ejemplo de la sección 3.2 de West (2014). Figure 9.1: Camada de ratones, tomada de https://www.howcast.com/videos/509444-how-to-care-for-a-pregnant-rat-pet-rats A continuación la base de datos a utilizar. library(nlme) head(RatPupWeight) ## Grouped Data: weight ~ 1 | Litter ## weight sex Litter Lsize Treatment ## 1 6.60 Male 1 12 Control ## 2 7.40 Male 1 12 Control ## 3 7.15 Male 1 12 Control ## 4 7.24 Male 1 12 Control ## 5 7.10 Male 1 12 Control ## 6 6.04 Male 1 12 Control Esta base de datos sobre crecimiento contiene la información sobre altura (weigth), sexo (sex), camada (litter), tamaño de la camada (Lsize) y tratamiento (Treatment) al que se sometió un rata antes de tener ratones. La estrategia es crear el modelo de forma incremental. Vamos a comenzar la construcción a partir del modelo mod31 que usa como efectos fijos el tratamiento, el sexo, la interacción entre tratamiento y sexo, el tamaño de la camada. Adicionalmente, este modelo incluye intercepto aleatorio debido a la camada. mod31 &lt;- lme(weight ~ Treatment * sex + Lsize, random= ~ 1 | Litter, data=RatPupWeight, method = &quot;REML&quot;) Vamos a usar la función anova.lme para estudiar la importancia de cada efecto fijo en el modelo. anova(mod31) ## numDF denDF F-value p-value ## (Intercept) 1 292 9093.772 &lt;.0001 ## Treatment 2 23 5.082 0.0149 ## sex 1 292 52.602 &lt;.0001 ## Lsize 1 23 47.374 &lt;.0001 ## Treatment:sex 2 292 0.466 0.6282 El otro modelo inicial mod31a es un modelo lineal sin intercepto aleatorio y se ajusta con la función gls y no con lm, esto se hace para poder comparar los modelos mod31 y mod31a. mod31a &lt;- gls(weight ~ Treatment * sex + Lsize, data=RatPupWeight, method = &quot;REML&quot;) Para comparar los modelos mod31 y mod31a se puede usar nuevamente la función anova.lme. En este caso la hipótesis nula es \\(H_0: \\sigma_{b0}=0\\) frente a \\(H_1: \\sigma_{b0} &gt; 0\\). anova(mod31, mod31a) ## Model df AIC BIC logLik Test L.Ratio p-value ## mod31 1 9 421.3015 455.0747 -201.6508 ## mod31a 2 8 508.7072 538.7277 -246.3536 1 vs 2 89.40562 &lt;.0001 De la salida anterior se tiene que el estadístico de la prueba LRT (likelihood ratio test) es 89.40562 con un valor-P inferior a 0.0001, es quiere decir que hay evidencias en contra de \\(H_0\\), lo que significa que incluir \\(b_0\\) mejora el modelo. mod32a &lt;- lme(weight ~ Treatment * sex + Lsize, random= ~ 1 | Litter, data=RatPupWeight, method = &quot;REML&quot;, weights = varIdent(form = ~1 | Treatment)) summary(mod32a) ## Linear mixed-effects model fit by REML ## Data: RatPupWeight ## AIC BIC logLik ## 384.0819 425.3602 -181.041 ## ## Random effects: ## Formula: ~1 | Litter ## (Intercept) Residual ## StdDev: 0.3134846 0.5147948 ## ## Variance function: ## Structure: Different standard deviations per stratum ## Formula: ~1 | Treatment ## Parameter estimates: ## Control High Low ## 1.0000000 0.6394383 0.5649830 ## Fixed effects: weight ~ Treatment * sex + Lsize ## Value Std.Error DF t-value p-value ## (Intercept) 7.888771 0.23223913 292 33.96831 0.0000 ## Treatment.L -0.638713 0.13587695 23 -4.70067 0.0001 ## Treatment.Q 0.011965 0.11635236 23 0.10283 0.9190 ## sexFemale -0.351238 0.04682791 292 -7.50062 0.0000 ## Lsize -0.130007 0.01848708 23 -7.03233 0.0000 ## Treatment.L:sexFemale 0.066939 0.09135485 292 0.73274 0.4643 ## Treatment.Q:sexFemale -0.023417 0.06929365 292 -0.33794 0.7357 ## Correlation: ## (Intr) Trtm.L Trtm.Q sexFml Lsize Tr.L:F ## Treatment.L -0.325 ## Treatment.Q -0.139 0.154 ## sexFemale -0.126 -0.008 -0.103 ## Lsize -0.954 0.376 0.190 0.031 ## Treatment.L:sexFemale -0.020 -0.304 -0.012 -0.034 0.015 ## Treatment.Q:sexFemale -0.021 -0.023 -0.300 0.445 -0.017 -0.029 ## ## Standardized Within-Group Residuals: ## Min Q1 Med Q3 Max ## -5.88670114 -0.52493419 0.02123518 0.57307286 2.56409983 ## ## Number of Observations: 322 ## Number of Groups: 27 References "],["estim.html", "10 Métodos de estimación 10.1 ML y REML Ejemplo: comparando REML y ML usando lme4 Ejemplo: comparando REML y ML usando nlme Ejercicios", " 10 Métodos de estimación En este capítulo se muestran los métodos ML (maximum likelihood) y REML (restricted maximum likelihood) para estimar los parámetros de un modelo mixto. 10.1 ML y REML El método de máxima verosimilitud restringida (o residual o reducida) (REML) es una alternativa de estimación de máxima verosimilitud que no basa las estimaciones en un ajuste de máxima verosimilitud de toda la información, sino que utiliza una función de verosimilitud calculada a partir de una conjunto de datos transformado, de modo que los parámetros molestos no tengan ningún efecto. En el caso de la estimación del componente de varianza, el conjunto de datos original se reemplaza por un conjunto de contrastes calculados a partir de los datos, y la función de verosimilitud se calcula a partir de la distribución de probabilidad de estos contrastes, de acuerdo con el modelo para el conjunto de datos completo. En particular, REML se utiliza como método para ajustar modelos lineales mixtos. En contraste con la estimación de máxima verosimilitud anterior, REML puede producir estimaciones insesgadas de parámetros de varianza y covarianza. Ejemplo: comparando REML y ML usando lme4 En este ejemplo vamos a simular datos de un modelo lineal mixto con intercepto y pendiente aleatoria, luego vamos a comparar las estimaciones de los parámetros del modelo usando REML y ML. Solución. Los datos los vamos a simular del siguiente modelo. \\[\\begin{align*} y_{ij} | b_0, b_1 &amp;\\sim N(\\mu_{ij}, \\sigma^2_y) \\\\ \\mu_{ij} &amp;= 4 - 5 x_{ij} + b_{0i} + b_{1i} x_{ij} \\\\ \\sigma^2_y &amp;= 4 \\\\ \\left ( \\begin{matrix} b_{0} \\\\ b_{1} \\end{matrix} \\right ) &amp;\\sim N\\left ( \\left ( \\begin{matrix} 0 \\\\ 0 \\end{matrix} \\right ), \\left ( \\begin{matrix} \\sigma^2_{b0}=40 &amp; \\sigma_{b01}=3 \\\\ \\sigma_{b01}=3 &amp; \\sigma^2_{b1}=50 \\end{matrix} \\right ) \\right ) \\\\ x_{ij} &amp;\\sim U(0, 5) \\end{align*}\\] Vamos a simular datos balanceados del anterior modelo considerando cinco grupos y diez observaciones por grupo. Para hacer esto vamos a usar la siguiente función. gen_data &lt;- function() { ni &lt;- 10 G &lt;- 5 nobs &lt;- ni * G # Numero total de observaciones grupo &lt;- factor(rep(x=1:G, each=ni)) # Para crear la variable grupal obs &lt;- rep(x=1:ni, each=G) # Para identificar las obs por grupo x &lt;- runif(n=nobs, min=0, max=5) # La covariable library(MASS) # Libreria para simular obs de Normal bivariada Sigma &lt;- matrix(c(40, 3, # Matriz de var-cov 3, 50), ncol=2, nrow=2) b &lt;- mvrnorm(n=G, mu=rep(0, 2), Sigma=Sigma) # Simulando b0 y b1 b &lt;- apply(b, MARGIN=2, function(c) rep(c, each=ni)) # Replicando b0 &lt;- as.vector(b[, 1]) # Separando los b0 b1 &lt;- as.vector(b[, 2]) # Separando los b1 media &lt;- 4 - 5 * x + b0 + b1 * x # La media y &lt;- rnorm(n=nobs, mean=media, sd=2) # La variable respuesta datos &lt;- data.frame(grupo, obs, x, y) # El dataframe } set.seed(123456) # Fijando la semilla para replicar el ejemplo datos &lt;- gen_data() # Creando los datos Ahora vamos a ajustar dos modelos, uno con estimación REML y otro con estimación ML. library(lme4) fit_reml &lt;- lmer(y ~ 1 + x + (1 + x| grupo), data = datos, REML = TRUE) fit_ml &lt;- lmer(y ~ 1 + x + (1 + x| grupo), data = datos, REML = FALSE) Para extraer sólo los efectos fijos de los dos modelos ajustados hacemos lo siguiente: fixef(fit_reml) ## (Intercept) x ## 11.449474 -6.236896 fixef(fit_ml) ## (Intercept) x ## 11.449454 -6.235161 Los efectos fijos verdaderos son \\(\\beta_0=4\\) y \\(\\beta_1=-5\\). Al comparar las estimaciones REML y ML vemos que son cercanas entre sí y próximas de los parámetros. Para extraer sólo las componentes de varianza de los dos modelos hacemos lo siguiente: (vc_reml &lt;- VarCorr(fit_reml)) ## Groups Name Std.Dev. Corr ## grupo (Intercept) 6.5259 ## x 4.0121 0.466 ## Residual 2.0379 (vc_ml &lt;- VarCorr(fit_ml)) ## Groups Name Std.Dev. Corr ## grupo (Intercept) 5.8025 ## x 3.5803 0.475 ## Residual 2.0377 Las componentes de varianza son \\(\\sigma_{b0}=6.32\\) (obtenida como \\(\\sqrt{40}\\)), \\(\\sigma_{b1}=7.07\\) (obtenida como \\(\\sqrt{50}\\)), \\(\\sigma_{b01}=3\\) y \\(\\sigma_y=2\\). Vamos a calcular el MSE (mean squared error) para las dos estimaciones REML y ML. a &lt;- vc_reml[[1]] b &lt;- vc_ml[[1]] mean((a[upper.tri(a, diag = TRUE)] - c(40, 3, 50))^2) ## [1] 413.6231 mean((b[upper.tri(b, diag = TRUE)] - c(40, 3, 50))^2) ## [1] 489.9286 De los anteriores resultados vemos que MSE es menor cuando se usa REML. Ejemplo: comparando REML y ML usando nlme Vamos a ajustar nuevamente los modelos pero usando el paquete nlme. library(nlme) fit_reml &lt;- lme(y ~ 1 + x, random = ~ 1 + x | grupo, data = datos, method = &quot;REML&quot;) fit_ml &lt;- lme(y ~ 1 + x, random = ~ 1 + x | grupo, data = datos, method = &quot;ML&quot;) Para extraer sólo los efectos fijos de los dos modelos ajustados hacemos lo siguiente: fixef(fit_reml) ## (Intercept) x ## 11.449474 -6.236896 fixef(fit_ml) ## (Intercept) x ## 11.449459 -6.235162 Los efectos fijos verdaderos son \\(\\beta_0=4\\) y \\(\\beta_1=-5\\). Al comparar las estimaciones REML y ML vemos que son cercanas entre sí, y próximas de los parámetros. Para extraer sólo las componentes de varianza de los dos modelos hacemos lo siguiente: (vc_reml &lt;- VarCorr(fit_reml)) ## grupo = pdLogChol(1 + x) ## Variance StdDev Corr ## (Intercept) 42.588627 6.525996 (Intr) ## x 16.097479 4.012166 0.466 ## Residual 4.153191 2.037938 (vc_ml &lt;- VarCorr(fit_ml)) ## grupo = pdLogChol(1 + x) ## Variance StdDev Corr ## (Intercept) 33.668543 5.802460 (Intr) ## x 12.819501 3.580433 0.475 ## Residual 4.152341 2.037729 Las componentes de varianza son \\(\\sigma_{b0}=6.32\\) (obtenida como \\(\\sqrt{40}\\)), \\(\\sigma_{b1}=7.07\\) (obtenida como \\(\\sqrt{50}\\)), \\(\\sigma_{b01}=3\\) y \\(\\sigma_y=2\\). Cuando se tienen muchos grupos y muchas repeticiones por grupo las estimaciones con REML y ML son muy cercanas. Ejercicios Repita el primer ejemplo de este capítulo para diez grupos y veinte observaciones por grupo. ¿Cuál es el valor de MSE para REML y ML? Repita el primer ejemplo de este capítulo para treinta grupos y cincuenta observaciones por grupo. ¿Cuál es el valor de MSE para REML y ML? Repita el primer ejemplo sin fijar la semilla y haga 100 réplicas con las siguientes combinaciones. Calcule el promedio de los MSE obtenidos. \\(G\\) \\(n_i\\) \\(\\overline{MSE}_{REML}\\) \\(\\overline{MSE}_{ML}\\) 5 10 10 15 20 20 30 25 "],["ph.html", "11 Pruebas de hipótesis 11.1 Prueba razón de verosimilitud 11.2 Prueba de Wald 11.3 Prueba de hipótesis sobre los efectos fijos 11.4 Prueba de hipótesis sobre componentes de varianza Ejercicios", " 11 Pruebas de hipótesis En este capítulo se muestran las pruebas de hipótesis para comparar modelos mixtos. 11.1 Prueba razón de verosimilitud Supongamos que queremos estudiar \\(H_0: \\boldsymbol{\\theta} \\in \\boldsymbol{\\Theta}_0\\) versus \\(H_A: \\boldsymbol{\\theta} \\in \\boldsymbol{\\Theta}\\). La prueba razón de verosimilitud (\\(LR\\)) para \\(H_0\\) está dada por: \\[ LR = -2 \\log \\left( \\frac{ sup_{\\theta \\in \\boldsymbol{\\Theta}_0} L(\\theta)}{ sup_{\\theta \\in \\boldsymbol{\\Theta}} L(\\theta)} \\right). \\] Usualmente la prueba de razón de verosimilitud se expresa en función de los valores de log-verosimilitud del modelo así: \\[ LR = -2 ( l(\\boldsymbol{\\theta}_0) - l(\\hat{\\boldsymbol{\\theta}}) ), \\] y el estadístico \\(LR \\sim \\chi^2_{k-k_0}\\), donde \\(k\\) es el número de parámetros del modelo estimado y \\(k_0\\) el número de parámetros del modelo asumiendo \\(H_0\\) verdadera. El vector \\(\\boldsymbol{\\theta}_0\\) es el vector de parámetros asumiendo que \\(H_0\\) es verdadera mientras que \\(\\hat{\\boldsymbol{\\theta}}\\) es el vector de parámetros del modelo más general. 11.2 Prueba de Wald Si el interés es estudiar \\(H_0: \\beta_k = \\beta_{k0}\\) contra \\(H_A: \\beta_k \\neq \\beta_{k0}\\) se puede usar la prueba de Wald que tiene el siguiente estadístico: \\[ t = \\frac{\\hat{\\beta}_k - \\beta_{k0}}{se(\\hat{\\beta}_k)}, \\] donde \\(se(\\hat{\\beta}_k)\\) corresponde al error estándar de la estimación \\(\\hat{\\beta}_k\\), todo esto disponible en el summary del modelo ajustado. Si \\(H_0\\) es verdadera, \\(t \\sim t_{n-p}\\), siendo \\(n\\) el número de observaciones y \\(p\\) el número de efectos fijos estimados (no el número de variables) en el modelo. 11.3 Prueba de hipótesis sobre los efectos fijos La prueba razón de verosimilitud puede ser usada para comparar modelos ajustados por el método ML y que difieran en su estructura de efectos fijos, pero con la mismas componentes de varianza. Los valores-P de la prueba pueden ser anticonservativos, es decir, más pequeños de lo normal y por lo tanto se podría rechazar \\(H_0\\) más fácilmente (J. Pinheiro and Bates 2000). En lugar de usar la distribución \\(\\chi^2\\) para el estadístico de la prueba razón de verosimilitud, se recomienda usar la distribución empírica del estadístico, obtenida al ajustar los modelos nulo y alternativo con múltiples conjuntos de datos simulados (Galecki and Burzykowski 2012). Ejemplo La base de datos ChickWeight contiene información sobre el peso de un grupo de pollos versus el tiempo bajo diferentes dietas. Abajo una ilustración de los datos. library(ggplot2) ggplot(data = ChickWeight, aes(x = Time, y = weight, color = Diet)) + geom_point() + theme_bw() + facet_wrap(~ Chick) El objetivo es comparar los siguientes dos modelos. Modelo 1 \\[\\begin{align*} Weight_{ij} &amp;\\sim N(\\mu_{ij}, \\sigma^2_{weight}) \\\\ \\mu_{ij} &amp;= \\beta_0 + \\beta_1 tiempo_{ij} + b_{0i} \\\\ b_{0} &amp;\\sim N(0, \\sigma^2_{b0}) \\end{align*}\\] Modelo 2 \\[\\begin{align*} Weight_{ij} &amp;\\sim N(\\mu_{ij}, \\sigma^2_{weight}) \\\\ \\mu_{ij} &amp;= \\beta_0 + \\beta_1 tiempo_{ij} + \\beta_2 dieta2_{i} + \\beta_3 dieta3_{i} + \\beta_4 dieta4_{i} + b_{0i} \\\\ b_{0} &amp;\\sim N(0, \\sigma^2_{b0}) \\end{align*}\\] Solución. El problema de este ejercicio se puede resumir con \\(H_0:\\) la variable Dieta no aporta al modelo, versus, \\(H_A:\\) la variable Dieta si aporta al modelo. Para ajustar ambos modelos se usa el siguiente código. library(nlme) mod1 &lt;- lme(weight ~ Time, data = ChickWeight, random = ~ 1 | Chick, method=&#39;ML&#39;) mod2 &lt;- lme(weight ~ Time + Diet, data = ChickWeight, random = ~ 1 | Chick, method=&#39;ML&#39;) Para calcular la prueba razón de verosimilitud se usa el siguiente código. lrt &lt;- -2 * (logLik(mod1) - logLik(mod2)) lrt ## &#39;log Lik.&#39; 17.14349 (df=4) pchisq(q=lrt, df=7-4, lower.tail=FALSE) ## &#39;log Lik.&#39; 0.000660304 (df=4) De la salida anterior se tiene que el valor-P = 0.000660304 y menor que cualquier \\(\\alpha\\). Sin embargo, como este valor-P puede ser “anticonservativo” (más pequeño de lo que debería ser), es mejor no sacar conclusiones apresuradas y rechazar \\(H_0\\). La prueba de verosimilitud se puede obtener también así: anova(mod1, mod2) ## Model df AIC BIC logLik Test L.Ratio p-value ## mod1 1 4 5630.344 5647.782 -2811.172 ## mod2 2 7 5619.201 5649.718 -2802.600 1 vs 2 17.14349 7e-04 Para obtener un valor-P más acorde al problema podemos usar simulación. La función simulate.lme simula datos de modelos especificados por medio de los argumentos object y m2, ajusta los modelos, y entrega los valores de log-verosimilitud, con los se puede obtener el estadístico de la prueba de razón de verosimilitud. A continuación el código para obtener el valor-P con simulación. simul &lt;- simulate.lme(object=mod1, m2=mod2, method = &#39;ML&#39;, nsim=1000) lrts_nlme &lt;- -2 * (simul$null$ML[, 2] - simul$alt$ML[, 2]) acumulada1 &lt;- ecdf(x=lrts_nlme) # F(x) para los valores LRT 1 - acumulada1(17.14349) ## [1] 0.001 De la salida anterior se tiene que el valor-P = 0.001 y ya no es tan pequeño como el valor-P anterior. Por esta razón hay evidencias rechazar \\(H_0\\) y por lo tanto la variable Dieta si aporta al modelo. Ejemplo La base de datos Orthodont contiene información sobre una medida de distancia intrafacial para jóvenes sometidos a ortodoncia. data(Orthodont, package=&quot;nlme&quot;) library(ggplot2) ggplot(data = Orthodont, aes(x = age, y = distance, color = Sex)) + geom_point() + theme_bw() + facet_wrap(~ Subject) El objetivo es comparar los siguientes dos modelos. Modelo 1 \\[\\begin{align*} Distance_{ij} &amp;\\sim N(\\mu_{ij}, \\sigma^2_{distance}) \\\\ \\mu_{ij} &amp;= \\beta_0 + \\beta_1 age_{ij} + b_{0i} \\\\ b_{0} &amp;\\sim N(0, \\sigma^2_{b0}) \\end{align*}\\] Modelo 2 \\[\\begin{align*} Distance_{ij} &amp;\\sim N(\\mu_{ij}, \\sigma^2_{distance}) \\\\ \\mu_{ij} &amp;= \\beta_0 + \\beta_1 age_{ij} + \\beta_2 SexFemale_i + b_{0i} \\\\ b_{0} &amp;\\sim N(0, \\sigma^2_{b0}) \\end{align*}\\] Solución. El problema de este ejercicio se puede resumir con \\(H_0:\\) la variable Sexo no aporta al modelo, versus, \\(H_A:\\) la variable Sexo si aporta al modelo. Para ajustar ambos modelos se usa el siguiente código. library(lme4) mod1 &lt;- lmer(distance ~ age + (1|Subject), data=Orthodont, REML=FALSE) mod2 &lt;- lmer(distance ~ age + Sex + (1|Subject), data=Orthodont, REML=FALSE) Para calcular la prueba razón de verosimilitud se usa el siguiente código. lrt &lt;- -2 * (logLik(mod1) - logLik(mod2)) lrt ## &#39;log Lik.&#39; 8.533057 (df=4) pchisq(q=lrt, df=5-4, lower.tail=FALSE) ## &#39;log Lik.&#39; 0.003487534 (df=4) De la salida anterior se tiene que el valor-P = 0.003487534 y menor que cualquier \\(\\alpha\\). Sin embargo, como este valor-P puede ser “anticonservativo” (más pequeño de lo que debería ser), es mejor no sacar conclusiones apresuradas y rechazar \\(H_0\\). La prueba de verosimilitud se puede obtener también así: anova(mod1, mod2) ## Data: Orthodont ## Models: ## mod1: distance ~ age + (1 | Subject) ## mod2: distance ~ age + Sex + (1 | Subject) ## npar AIC BIC logLik deviance Chisq Df Pr(&gt;Chisq) ## mod1 4 451.39 462.12 -221.69 443.39 ## mod2 5 444.86 458.27 -217.43 434.86 8.5331 1 0.003488 ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Para obtener un valor-P más acorde al problema podemos usar simulación. La función simulate.lme simula respuestas \\(y_{ij}\\) del modelo dado. A continuación el código para obtener el valor-P con simulación (¡tarda varios minutos!). nrep &lt;- 5000 lrts_lme4 &lt;- numeric(nrep) for (i in 1:nrep) { new_y_h0 &lt;- simulate(mod1) # Asumiendo H0 verdadera Orthodont$new_y_h0 &lt;- new_y_h0$sim_1 aux0 &lt;- lmer(new_y_h0 ~ age + (1|Subject), data=Orthodont, REML=FALSE) aux1 &lt;- lmer(new_y_h0 ~ age + Sex + (1|Subject), data=Orthodont, REML=FALSE) lrts_lme4[i] &lt;- -2 * (logLik(aux0) - logLik(aux1)) } acumulada2 &lt;- ecdf(x=lrts_lme4) # F(x) para los valores LRT 1 - acumulada1(8.533057) ## [1] 0.005 De la salida anterior se tiene que el valor-P = 0.005 y ya no es tan pequeño como el valor-P anterior. Por esta razón hay evidencias rechazar \\(H_0\\) y por lo tanto la variable Sexo si aporta al modelo. 11.4 Prueba de hipótesis sobre componentes de varianza Las componentes de varianza corresponden a las varianzas y covarianzas del vector de efectos aleatorios. La prueba razón de verosimilitud puede ser usada para comparar modelos ajustados por el método REML y que difieran en sus componentes de varianza, pero que tenga igual estructura de efectos fijos. Para hacer pruebas de hipótesis sobre las componentes de varianza se tienen dos casos que se explican en las siguientes subsecciones. 11.4.1 Componentes de varianza lejos del borde Luego un ejemplo. 11.4.2 Componentes de varianza en el borde Este caso se presenta cuando la hipótesis nula considera que uno o varios parámetros están justo en el borde del dominio del parámetro en cuestion. Por ejemplo, si queremos estudiar la inclusión del intercepto aleatorio \\(b_0\\) en un modelo de regresión clásico, tendríamos las siguientes hipótesis: \\(H_0: \\sigma^2_{b0} = 0\\) versus \\(H_A: \\sigma^2_{b0} &gt; 0\\). Debido a la condición de \\(\\sigma^2_{b0}\\) en \\(H_0\\), se dice que esa componente de varianza está en el borde de su dominio, ya que \\(\\sigma^2_{b0}\\) no puede ser negativa. En este ejemplo particular, rechazar \\(H_0\\) implicaría que es apropiado incluir \\(b_0\\) en el modelo. En el caso de componentes de varianza cerca de la frontera la distribución del estadístico razón de verosimilitud no es exactamente una \\(\\chi^2\\) (Galecki and Burzykowski 2012). En la sección 6.3.4 de (Verbeke and Molenberghs 2000) se listan cuatro casos en los cuales se usan mezclas de distribuciones corregir la distribución del estadístico y así calcular el valor-P corregido en la prueba razón de verosimilitud. Los cuatro casos son los siguientes: Sin efecto aleatorio versus 1 efecto aleatorio: en este caso lo que interesa es \\(H_0: \\sigma^2_{b} = 0\\) versus \\(H_A: \\sigma^2_{b} &gt; 0\\), la distribución asintótica del estadístico de razon de verosimilitud es una mezcla de \\(\\chi^2_1\\) y \\(\\chi^2_0\\) con pesos iguales a 0.5. 1 efecto aleatorio versus 2 efectos aleatorios: en este caso lo que interesa es \\(H_0: \\boldsymbol{D} = \\begin{pmatrix} d_{11} &amp; 0 \\\\ 0 &amp; 0 \\end{pmatrix}\\) versus \\(H_A: \\boldsymbol{D} \\neq \\boldsymbol{0}\\) para un \\(d_{11}&gt;0\\), en este caso la distribución asintótica del estadístico razón de verosimilitud es una mezcla de \\(\\chi^2_2\\) y \\(\\chi^2_1\\) con pesos iguales a 0.5. \\(q\\) efectos aleatorios versus \\(q+1\\) efectos aleatorios: en este caso lo que interesa es \\(H_0: \\boldsymbol{D} = \\begin{pmatrix} \\boldsymbol{D_{11}} &amp; \\boldsymbol{0}\\\\ \\boldsymbol{0}^\\top &amp; 0 \\end{pmatrix}\\) donde \\(\\boldsymbol{D_{11}}\\) es una matriz de covarianzas (positiva definida) de dimensión \\(q \\times q\\) versus que \\(\\boldsymbol{D}\\) es una matriz general de dimensión \\(q+1 \\times q+1\\). En este caso la distribución asintótica del estadística razón de verosimilitud es una mezcla de \\(\\chi^2_{q+1}\\) y \\(\\chi^2_q\\) con pesos iguales a 0.5. \\(q\\) efectos aleatorios versus \\(q+k\\) efectos aleatorios: en este caso lo que interesa es \\(H_0: \\boldsymbol{D} = \\begin{pmatrix} \\boldsymbol{D_{11}} &amp; \\boldsymbol{0}\\\\ \\boldsymbol{0}^\\top &amp; \\boldsymbol{0} \\end{pmatrix}\\) donde \\(\\boldsymbol{D}\\) es una matriz de covarianzas (positiva definida) de dimensión \\(q+k \\times q+k\\) versus que \\(H_A: \\boldsymbol{D} = \\begin{pmatrix} \\boldsymbol{D_{11}} &amp; \\boldsymbol{D_{12}}\\\\ \\boldsymbol{D_{12}}^\\top &amp; \\boldsymbol{D_{22}} \\end{pmatrix}\\) es una matriz general de dimensión \\(q+k \\times q+k\\). En este caso la distribución asintótica del estadística razón de verosimilitud es una mezcla de \\(\\chi^2_{q+k}\\) y \\(\\chi^2_q\\) con pesos iguales a 0.5. Si la distribución nula del estadístico razón de verosimilitud no puede ser obtenida analíticamente, una posible solución es usar la distribución empírica del estadístico obtenida al ajustar múltiples modelos nulos y alternativos (Galecki and Burzykowski 2012). Ejemplo Simule 10 observaciones para cada uno de los 10 grupos siguiendo el siguiente modelo y luego aplique la prueba de razón de verosimilitud para estudiar \\(H_0: \\sigma^2_{b0} = 0\\) versus \\(H_A: \\sigma^2_{b0} &gt; 0\\). \\[\\begin{align*} y_{ij} &amp;\\sim N(\\mu_{ij}, \\sigma^2_y) \\\\ \\mu_{ij} &amp;= 4 - 6 x_{ij} + b_{0i} \\\\ \\sigma^2_y &amp;= 4 \\\\ b_{0} &amp;\\sim N(0, \\sigma^2_{b0}=4) \\\\ x_{ij} &amp;\\sim U(0, 10) \\end{align*}\\] Solución. La función gen_dat_b0 de abajo permite simular m observaciones de n grupos con intercepto aleatorio \\(b_0 \\sim N(0, \\sigma^2_{b0})\\). Adicionalmente, es posible elegir los efectos fijos beta0, beta_1 y la varianza sigma de la variable respuesta. gen_dat_b0 &lt;- function(n, m, beta0, beta1, sigmay, sigmab0, seed=NULL) { if(is.null(seed)) seed &lt;- as.integer(runif(1)*2e9) group &lt;- rep(1:n, each=m) set.seed(seed) b0 &lt;- rep(rnorm(n=n, mean=0, sd=sigmab0), each=m) set.seed(seed) x &lt;- runif(n=n*m, min=0, max=10) set.seed(seed) y &lt;- rnorm(n=n*m, mean=beta0 + beta1 * x + b0, sd=sigmay) data.frame(group=group, x=x, y=y) } Vamos ahora a generar 10 observaciones para 10 grupos con intercepto aleatorio con una varianza \\(\\sigma^2_{b0}=2^2=4\\). La semilla se va a fijar en un valor de 1220872376 por cuestiones didácticas. datos &lt;- gen_dat_b0(n=10, m=10, beta0=4, beta1=-6, sigmay=2, sigmab0=2, seed=1220872376) head(datos) ## group x y ## 1 1 3.817132 -20.106729 ## 2 1 8.951117 -49.950457 ## 3 1 5.710726 -33.154170 ## 4 1 7.451320 -39.583303 ## 5 1 1.263282 -1.070788 ## 6 1 6.114367 -33.423587 Vamos a ajustar dos modelos, el primero sin incluir \\(b_0\\) y el segundo incluyendo \\(b_0\\). library(nlme) fit1 &lt;- gls(y ~ x, data=datos, method=&quot;REML&quot;) # Igual resultado con lm fit2 &lt;- lme(y ~ x, random = ~ 1| group, data=datos, method=&quot;REML&quot;) Resultados del primer modelo. summary(fit1) ## Generalized least squares fit by REML ## Model: y ~ x ## Data: datos ## AIC BIC logLik ## 475.8248 483.5797 -234.9124 ## ## Coefficients: ## Value Std.Error t-value p-value ## (Intercept) 4.64931 0.5180190 8.97517 0 ## x -6.00175 0.0814173 -73.71588 0 ## ## Correlation: ## (Intr) ## x -0.875 ## ## Standardized residuals: ## Min Q1 Med Q3 Max ## -2.14346496 -0.64999607 -0.06461389 0.60660976 3.48238119 ## ## Residual standard error: 2.50842 ## Degrees of freedom: 100 total; 98 residual Resultados del segundo modelo. summary(fit2) ## Linear mixed-effects model fit by REML ## Data: datos ## AIC BIC logLik ## 474.7777 485.1175 -233.3888 ## ## Random effects: ## Formula: ~1 | group ## (Intercept) Residual ## StdDev: 0.8166724 2.383898 ## ## Fixed effects: y ~ x ## Value Std.Error DF t-value p-value ## (Intercept) 4.640053 0.5652943 89 8.20821 0 ## x -6.000087 0.0795348 89 -75.43973 0 ## Correlation: ## (Intr) ## x -0.783 ## ## Standardized Within-Group Residuals: ## Min Q1 Med Q3 Max ## -2.19536246 -0.56396957 0.05433633 0.61634184 3.29594400 ## ## Number of Observations: 100 ## Number of Groups: 10 Ahora vamos a calcular el estadístico y su valor-P. lrt &lt;- -2 * (logLik(fit1) - logLik(fit2)) lrt ## &#39;log Lik.&#39; 3.04712 (df=3) p_value &lt;- pchisq(q=3.04712, df=1, lower.tail=FALSE) p_value ## [1] 0.08088045 De la salida anterior se tiene que \\(valor-P = 0.0809\\) y como \\(\\alpha=0.05\\), por lo tanto NO hay evidencias para rechazar \\(H_0: \\sigma^2_{b0} = 0\\). ¿No es extraña esta conclusión ? Lo anterior ocurre porque la distribución del estadístico \\(LR\\) no es un \\(\\chi^2\\) sino una mezcla de distribuciones \\(\\chi^2_1\\) y \\(\\chi^2_0\\) con pesos iguales a 0.5. A continuación vamos a mostrar la distribución de \\(LR\\) en este ejemplo. library(emdbook) # Para usar la función dchibarsq library(ggplot2) ggplot(data = data.frame(x = 0), mapping = aes(x = x)) + stat_function(fun = dchibarsq, args = list(df = 1)) + xlim(0, 5) Para calcular el valor-P de la prueba hacemos pchibarsq(p=3.04712, df = 1, mix = 0.5, lower.tail=FALSE) ## [1] 0.04044023 También es posible obtener el valor-P usando simulación. Vamos a simular 50 conjuntos de datos suponiendo \\(H_0\\) verdadera y luego calcularemos los lrt para así tener la distribución empírica de los lrt bajo la hipótesis nula \\(H_0: \\sigma^2_{b0} = 0\\) verdadera. En un aplicación se deberían generar más conjuntos de pero aquí vamos a usar sólo 50 por comodidad. pseudo_gen_dat &lt;- function(nobs, beta0, beta1, sigmay) { group &lt;- datos$group # Aqui la diferencia x &lt;- datos$x # Aqui la diferencia y &lt;- rnorm(n=nobs, mean=beta0 + beta1 * x, sd=sigmay) data.frame(group=group, x=x, y=y) } nrep &lt;- 50 lrts &lt;- numeric(nrep) for (i in 1:nrep) { pseudo_datos &lt;- pseudo_gen_dat(nobs=100, beta0=4.64931, beta1=-6.00175, sigma=2.50842) m1 &lt;- gls(y ~ x, data=pseudo_datos, method=&quot;REML&quot;) m2 &lt;- lme(y ~ x, random = ~ 1| group, data=pseudo_datos, method=&quot;REML&quot;) lrts[i] &lt;- -2 * (logLik(m1) - logLik(m2)) } Dibujando la densidad de los lrt. plot(density(lrts), main=&#39;Densidad empírica de los lrts&#39;) Calculando el valor-P. acumulada &lt;- ecdf(x=lrts) # F(x) para los valores LRT 1 - acumulada(3.04712) # Valor-P ## [1] 0.04 De la salida anterior se tiene que \\(valor-P &lt; \\alpha\\) por lo tanto SI hay evidencias para rechazar \\(H_0: \\sigma^2_{b0} = 0\\). ¿Es esto coherente ahora ? Los resultados anteriores se obtuvieron usando nrep &lt;- 50, en la práctica ese número de repeticiones debería subir al menos a 1000. Repita el procedimiento anterior con nrep &lt;- 5000 y observe lo que sucede. El paquete RLRsim de Scheipl (2022) tiene la función exactRLRT que permite extraer el valor-P mediante simulación. Abajo un ejemplo de como usarla en el presente ejemplo. library(RLRsim) exactRLRT(m=fit2, nsim=1000) ## ## simulated finite sample distribution of RLRT. ## ## (p-value based on 1000 simulated values) ## ## data: ## RLRT = 3.0471, p-value = 0.039 Consulte la ayuda de la función exactRLRT para que conozca sus posibilidades y limitaciones. Ejemplo Simule 10 observaciones para cada uno de los 10 grupos siguiendo el siguiente modelo y luego aplique la prueba de razón de verosimilitud para estudiar \\(H_0:\\) el modelo con intercepto aleatorio está bien versus \\(H_A:\\) se necesita intercepto y pendiente aleatoria. \\[\\begin{align*} y_{ij} &amp;\\sim N(\\mu_{ij}, \\sigma^2_y) \\\\ \\mu_{ij} &amp;= 4 - 6 x_{ij} + b_{0i} + b_{1i} x_{ij} \\\\ \\sigma^2_y &amp;= 4 \\\\ \\left ( \\begin{matrix} b_{0} \\\\ b_{1} \\end{matrix} \\right ) &amp;\\sim N\\left ( \\left ( \\begin{matrix} 0 \\\\ 0 \\end{matrix} \\right ), \\left ( \\begin{matrix} \\sigma^2_{b0}=10 &amp; \\sigma_{b01}=3 \\\\ \\sigma_{b01}=3 &amp; \\sigma^2_{b1}=2 \\end{matrix} \\right ) \\right ) \\\\ x_{ij} &amp;\\sim U(0, 10) \\end{align*}\\] Solución. La función gen_dat_b0_b1 de abajo permite simular m observaciones de n grupos con intercepto y pendiente aleatoria según el modelo exigido. gen_dat_b0_b1 &lt;- function(n, m, beta0, beta1, sigma2y, sigma2b0, sigma2b1, sigmab0b1, seed=NULL) { if(is.null(seed)) seed &lt;- as.integer(runif(1)*2e9) group &lt;- rep(1:n, each=m) Sigma &lt;- matrix(c(sigma2b0, sigmab0b1, sigmab0b1, sigma2b1), ncol=2, nrow=2) set.seed(seed) b &lt;- MASS::mvrnorm(n=n, mu=c(0, 0), Sigma=Sigma, empirical=TRUE) b &lt;- apply(X=b, MARGIN=2, rep, each=m) b0 &lt;- b[, 1] # Extrayendo los b0 b1 &lt;- b[, 2] # Extrayendo los b1 set.seed(seed) x &lt;- runif(n=n*m, min=0, max=10) mu &lt;- beta0 + beta1 * x + b0 + b1 * x set.seed(seed) y &lt;- rnorm(n=n*m, mean=mu, sd=sqrt(sigma2y)) data.frame(group=group, x=x, y=y) } Vamos ahora a generar 10 observaciones para 10 grupos con intercepto y pendiente aleatoria. La semilla se va a fijar en un valor de 1234 por cuestiones didácticas. datos &lt;- gen_dat_b0_b1(n=10, m=10, beta0=4, beta1=-6, sigma2y=4, sigma2b0=10, sigma2b1=2, sigmab0b1=3, seed=1234) head(datos) ## group x y ## 1 1 1.137034 -6.60088 ## 2 1 6.222994 -39.51716 ## 3 1 6.092747 -36.98415 ## 4 1 6.233794 -44.83962 ## 5 1 8.609154 -56.04992 ## 6 1 6.403106 -40.33074 Vamos a ajustar dos modelos, el primero sólo con \\(b_0\\) y el segundo incluyendo \\(b_0\\) y \\(b_1\\). library(lme4) fit0 &lt;- lmer(y ~ x + (1 | group), data=datos, REML=TRUE) fit1 &lt;- lmer(y ~ x + (1 + x | group), data=datos, REML=TRUE) Vamos a calcular ahora el valor del estadístico de la prueba razón de verosimilitudes así: lrt &lt;- -2 * (logLik(fit0) - logLik(fit1)) lrt ## &#39;log Lik.&#39; 122.1118 (df=4) Como la distribución del estadístico es una mezcla de distribuciones vamos a calcular el valor P de la siguiente manera. p_value &lt;- 0.5 * (1-pchisq(lrt, 1)) + 0.5 * (1-pchisq(lrt, 2)) p_value &lt;- as.numeric(p_value) p_value # p-value from equal mixture chi_1^2:chi_2^2 ## [1] 0 De la salida anterior vemos que el valor-P es muy pequeño, eso significa que rechazamos \\(H_0\\) y concluimos que el modelo con \\(b_0\\) y \\(b_1\\) es más apropiado que el modelo que tiene sólo intercepto aleatorio. La conclusión a la que llegamos es correcta porque así fue que generamos los datos. Es posible obtener el valor-P anterior usando boostrap por medio de la función PBmodcomp del paquete pbkrtest de Halekoh and Højsgaard (2021). library(pbkrtest) PBmodcomp(largeModel=fit1, smallModel=fit0, nsim=1000, seed=123) Bootstrap test; time: 21.86 sec; samples: 1000; extremes: 0; Requested samples: 1000 Used samples: 999 Extremes: 0 large : y ~ x + (1 + x | group) y ~ x + (1 | group) stat df p.value LRT 122.82 2 &lt;2e-16 *** PBtest 122.82 0.001 *** --- Signif. codes: 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 En el código anterior se usó la semilla seed = 123 para simular los nuevos conjuntos de datos. De la salida anterior se observa que el valor-P es 0.001 con lo que se concluye que hay evidencias para rechazar \\(H_0\\). Para usar la función PBmodcomp es necesario que los modelos sean de la clase lme4. Consulte la ayuda de la función para más detalles. Ejercicios ¿Qué son modelos anidados? ¿Son modelos que usan datos relacionados con aves? Considere la base de datos sleepstudy del paquete lme4. El objetivo es comparar los siguientes dos modelos. Modelo 1 \\[\\begin{align*} Reaction_{ij} &amp;\\sim N(\\mu_{ij}, \\sigma^2_{reaction}) \\\\ \\mu_{ij} &amp;= \\beta_0 + \\beta_1 days_{ij} + b_{0i} + b_{1i} days_{ij} \\\\ (b_0, b_1)^\\top &amp;\\sim N(\\boldsymbol{0}, \\boldsymbol{D}) \\end{align*}\\] Modelo 2 \\[\\begin{align*} Reaction_{ij} &amp;\\sim N(\\mu_{ij}, \\sigma^2_{reaction}) \\\\ \\mu_{ij} &amp;= \\beta_0 + \\beta_1 days_{ij} + \\beta_2 days_{ij}^2 + b_{0i} + b_{1i} days_{ij} \\\\ (b_0, b_1)^\\top &amp;\\sim N(\\boldsymbol{0}, \\boldsymbol{D}) \\end{align*}\\] Escriba las hipótesis del problema en forma simbólica y en lenguaje sencillo. Aplique la prueba razón de verosimilitud usando simulación y concluya. Rta: el valor-P \\(\\approx\\) 0.136. Considere el ejemplo del capítulo 8 sobre el estudio de crecimiento de un grupo de jóvenes. Aplique la prueba razón de verosimilitud para estudiar \\(H_0: \\sigma^2_{b0} = 0\\) versus \\(H_A: \\sigma^2_{b0} &gt; 0\\), es decir, ajuste un modelo lineal simple para explicar la estatura en función de la edad y luego un modelo mixto con intercepto aleatorio. ¿Cuál de los dos modelos parece explicar mejor los datos? Use \\(\\alpha=0.06\\). En este enlace está la pregunta de un usuario de StackExange sobre prueba de hipótesis (PH). ¿Fue la pregunta sobre PH sobre efectos fijos o PH sobre componentes de varianza? ¿Quería el usuario un PH asintótica o una PH basada en bootstrap (relacionado con simulación)? Mire el ejemplo que dió YaronZ, ¿por qué no definió el método REML dentro de las funciones lmer y lm? En este enlace está la extensa pregunta del usuario Patrick. En el primer cajón de código Patrick escribió un código para simular observaciones de un modelo mixto. ¿Cómo le parece esa forma de simular? ¿Cuántos elementos tiene el vector de parámetros del modelo de Patrick? ¿Cuáles son los valores de los parámetros? En este enlace está la pregunta del usuario biostat_newbie. ¿Qué nombre recibe el modelo que le interesa a biostat_newbie? ¿Qué es lo que necesita 0.7494974? ¿Cuál es el mensaje de primer párrafo de que respondió Fabians? En la respuesta que Fabians dió hay un código de R. ¿Para qué sirve ese código tan extraño? ¿Quién es Ben Bolker? ¿En cuáles paquetes de R ha participado Ben Bolker? En este enlace está la pregunta del usuario user9171. ¿Cuál es el error que comete user9171 al usar el siguiente código? &gt; anova(fit.fe, fit.me) Error: $ operator not defined for this S4 class ¿Qué le respondió Karl Ove Hufthammer? Karl le agrega en su respuesta “And really the choice of whether to include the random effects should be based on theory (e.g., the sampling plan), not on a statistical test”. ¿Qué quiere decir eso? Ben Bolker escribió unas notas sobre pruebas de hipótesis, revise este enlace para consultarlas. En el ejemplo de Ben Bolker hay tres modelos: m2, m1 y m0. ¿Cuál es el “full model” y cuál es el “reduced model”? ¿Para qué sirve la función update? ¿Usted la ha usado alguna vez? ¿No? Pues úsela de aquí en adelante. Ben escribe “which has a fast implementation of simulation-based tests of null hypotheses about zero variances, for simple tests.” ¿A qué paquete se refiere con esa frase? References "],["var-fun.html", "12 Modelando la heterocedasticidad 12.1 Opciones para modelar la varianza 12.2 varFixed Ejemplo: \\(\\sigma^2_y\\) dependiendo de una variable cuantitativa 12.3 varIdent Ejemplo: \\(\\sigma^2_y\\) dependiendo de una variable cualitativa", " 12 Modelando la heterocedasticidad En este capítulo se mostrará como usar el paquete nlme de José Pinheiro, Bates, and R Core Team (2022) para modelar heterocedasticidad. 12.1 Opciones para modelar la varianza En la siguiente tabla se muestran las diferentes opciones para modelar la varianza \\(\\sigma^2_y\\) de la variable respuesta \\(Y\\). Clase Modelo varFixed \\(\\sigma^2_y = \\sigma^2 x_{ij}\\) varIdent \\(\\sigma^2_y = \\sigma^2 \\delta^2_{Sij}\\) varPower \\(\\sigma^2_y = \\sigma^2 |x_{ij}|^{2\\delta}\\) varExp \\(\\sigma^2_y = \\sigma^2 e^{2 \\delta x_{ij}}\\) varConstPower \\(\\sigma^2_y = \\sigma^2 (\\delta_1 + |x_{ij}|^{\\delta_2})^2\\) varComb 12.2 varFixed En esta sección vamos a simular datos de un modelo lineal mixto en el cual \\(\\sigma^2_y\\) dependa de una variable cuantitativa para luego estimar los parámetros del modelo. Ejemplo: \\(\\sigma^2_y\\) dependiendo de una variable cuantitativa En este ejemplo vamos a simular observaciones \\(n_i=10\\) observaciones para \\(G=20\\) grupos (en total 200 obs) que tengan la estructura mostrada abajo. En este ejemplo la varianza \\(\\sigma^2_y\\) no es constante, depende de la varianza general \\(\\sigma^2=9\\) y de la variable \\(X\\), es decir \\(\\sigma^2_y = 9 \\, x_{ij}\\). \\[\\begin{align*} y_{ij} | b_0 &amp;\\sim N(\\mu_{ij}, \\sigma^2_y) \\\\ \\mu_{ij} &amp;= 4 - 6 x_{ij} + b_{0i} \\\\ \\sigma^2_y &amp;= 9 \\times x_{ij} \\\\ b_{0} &amp;\\sim N(0, \\sigma^2_{b0}=64) \\\\ x_{ij} &amp;\\sim U(0, 200) \\end{align*}\\] El vector de parámetros de este modelo es \\(\\boldsymbol{\\Theta}=(\\beta_0=4, \\beta_1=-6, \\sigma=3, \\sigma_{b0}=8)^\\top\\). Solución. El código para simular las 500 observaciones se muestra a continuación. Observe que se fijó la semilla para que el lector pueda replicar el ejemplo y obtener los mismos resultados. ni &lt;- 10 G &lt;- 20 nobs &lt;- ni * G grupo &lt;- factor(rep(x=1:G, each=ni)) obs &lt;- rep(x=1:ni, times=G) set.seed(123) x &lt;- runif(n=nobs, min=0, max=200) set.seed(123) b0 &lt;- rnorm(n=G, mean=0, sd=sqrt(64)) # Intercepto aleatorio b0 &lt;- rep(x=b0, each=ni) # El mismo intercepto aleatorio pero repetido media &lt;- 4 - 6 * x + b0 sigma2_y &lt;- 9 * x set.seed(123) y &lt;- rnorm(n=nobs, mean=media, sd=sqrt(sigma2_y)) datos &lt;- data.frame(obs, grupo, x, y) Primero vamos a ajustar un modelo fit0 que asume varianza \\(\\sigma^2_y\\) constante para compararlo con el modelo fit1 que si modela la varianza en función de la covariable \\(X\\). library(nlme) fit0 &lt;- lme(y ~ x, random = ~ 1 | grupo, data=datos) Vamos a explorar el gráfico de residuales versus la covariable \\(X\\) para ver si hay un indicio de heterocedasticidad (varianza no costante). plot(fit0, resid(., type = &quot;p&quot;) ~ x, abline = 0, pch=20) De la figura anterior vemos claramente una forma de “corneta”, cerrada a izquierda y abierta a la derecha, esto es un indicio de que se debe modelar la varianza \\(\\sigma^2_y\\). El siguiente modelo permite que la varianza \\(\\sigma^2_y\\) sea función de \\(X\\) usando una estructura varFixed. fit1 &lt;- lme(y ~ x, random = ~ 1 | grupo, weights=varFixed(~ x), data=datos) A continuación repetimos la misma figura de residuales anterior. De esta figura logramos ver que se eliminó el patrón de “corneta” observado antes. plot(fit1, resid(., type = &quot;p&quot;) ~ x, abline = 0, pch=20) La función summary se puede usar sobre el objeto fit1 para obtener una tabla de resumen, a continuación se ilustra el uso y la salida de summary. summary(fit1) ## Linear mixed-effects model fit by REML ## Data: datos ## AIC BIC logLik ## 1886.683 1899.836 -939.3417 ## ## Random effects: ## Formula: ~1 | grupo ## (Intercept) Residual ## StdDev: 7.182138 2.841913 ## ## Variance function: ## Structure: fixed weights ## Formula: ~x ## Fixed effects: y ~ x ## Value Std.Error DF t-value p-value ## (Intercept) 4.262272 2.7075258 179 1.57423 0.1172 ## x -5.994199 0.0293592 179 -204.16788 0.0000 ## Correlation: ## (Intr) ## x -0.59 ## ## Standardized Within-Group Residuals: ## Min Q1 Med Q3 Max ## -2.44109665 -0.63620797 -0.05268718 0.61698526 3.36214890 ## ## Number of Observations: 200 ## Number of Groups: 20 Según el resultado anterior \\(\\hat{\\boldsymbol{\\Theta}}=(\\hat{\\beta}_0=4.2623, \\hat{\\beta}_1=-5.9942, \\hat{\\sigma}=2.8419, \\hat{\\sigma}_{b0}=7.1821)^\\top\\) mientras que el vector real de parámetros es \\(\\boldsymbol{\\Theta}=(\\beta_0=4, \\beta_1=-6, \\sigma=3, \\sigma_{b0}=8)^\\top\\). En el código de abajo usamos la función anova.lme para comparar los dos modelos anteriores. Del resultado vemos que ambos modelos tienen 4 parámetros y que el modelo fit1 tiene el menor valor de BIC y mayor valor de verosimilitud, esto indica que el modelo fit1 es más apropiado para modelar los datos. anova(fit0, fit1) ## Model df AIC BIC logLik ## fit0 1 4 1912.618 1925.771 -952.3089 ## fit1 2 4 1886.683 1899.836 -939.3417 La varianza \\(\\sigma^2_y\\) se puede modelar también para modelos lineales, se le recomienda al lector consultar los siguiente enlaces para ver ejemplos: https://data.library.virginia.edu/modeling-non-constant-variance/ y https://pegasus.uprm.edu/~pedro.torres/book/chapter3.html#modelo-con-varianza-heterogenea 12.3 varIdent En esta sección vamos a simular datos de un modelo lineal mixto en el cual \\(\\sigma^2_y\\) dependa de una variable cualitativa para luego estimar los parámetros del modelo. Ejemplo: \\(\\sigma^2_y\\) dependiendo de una variable cualitativa En este ejemplo vamos a simular observaciones \\(n_i=10\\) observaciones para \\(G=20\\) grupos (en total 200 obs) que tengan la estructura mostrada abajo. En este ejemplo la varianza \\(\\sigma^2_y\\) no es constante, depende de la varianza general \\(\\sigma^2=9\\) y de la variable sexo, para los hombres la varianza será \\(\\sigma^2_y = 9 \\times \\delta_H\\) y para las mujeres la varianza será \\(\\sigma^2_y = 9 \\times \\delta_M\\). Los valores de \\(\\delta\\) a usar en la simulación son \\(\\delta_H=1\\) y \\(\\delta_M=6\\), esto para hacer que las observaciones de la mujeres tengan mayor variabilidad. El modelo de interés se puede resumir de la siguiente manera. \\[\\begin{align*} y_{ij} | b_0 &amp;\\sim N(\\mu_{ij}, \\sigma^2_y) \\\\ \\mu_{ij} &amp;= 4 - 6 x_{ij} + b_{0i} \\\\ \\text{Hombre} \\quad \\sigma^2_y &amp;= 9 \\times 1 \\\\ \\text{Mujer} \\quad \\sigma^2_y &amp;= 9 \\times 6 \\\\ b_{0} &amp;\\sim N(0, \\sigma^2_{b0}=64) \\\\ x_{ij} &amp;\\sim U(0, 200) \\end{align*}\\] El vector de parámetros de este modelo es \\(\\boldsymbol{\\Theta}=(\\beta_0=4, \\beta_1=-6, \\sigma=3, \\delta_H=1, \\delta_H=6, \\sigma_{b0}=8)^\\top\\). Solución. El código para simular las 500 observaciones se muestra a continuación. Observe que se fijó la semilla para que el lector pueda replicar el ejemplo y obtener los mismos resultados. ni &lt;- 10 G &lt;- 20 nobs &lt;- ni * G grupo &lt;- factor(rep(x=1:G, each=ni)) set.seed(123) sexo &lt;- sample(x=c(&quot;Hombre&quot;, &quot;Mujer&quot;), size=nobs, replace=TRUE) obs &lt;- rep(x=1:ni, times=G) set.seed(123) x &lt;- runif(n=nobs, min=0, max=200) set.seed(123) b0 &lt;- rnorm(n=G, mean=0, sd=sqrt(64)) # Intercepto aleatorio b0 &lt;- rep(x=b0, each=ni) # El mismo intercepto aleatorio pero repetido media &lt;- 4 - 6 * x + b0 delta_h &lt;- 1 delta_m &lt;- 6 sigma2_y &lt;- ifelse(sexo == &quot;Hombre&quot;, 9 * delta_h^2, 9 * delta_m^2) set.seed(123) y &lt;- rnorm(n=nobs, mean=media, sd=sqrt(sigma2_y)) datos &lt;- data.frame(obs, grupo, sexo, x, y) Primero vamos a ajustar un modelo fit0 que asume varianza \\(\\sigma^2_y\\) constante para compararlo con el modelo fit1 que si modela la varianza en función de la covariable sexo. library(nlme) fit0 &lt;- lme(y ~ x, random = ~ 1 | grupo, data=datos) Vamos a explorar el gráfico de residuales versus la covariable sexo para ver si hay un indicio de heterocedasticidad (varianza no costante). plot(fit0, resid(., type = &quot;p&quot;) ~ x | sexo, abline = 0, pch=20) De la figura anterior vemos claramente los residuales no se comportan igual para hombres y mujeres, esto es un indicio de que se debe modelar la varianza \\(\\sigma^2_y\\) teniendo en cuenta el sexo. El siguiente modelo permite que la varianza \\(\\sigma^2_y\\) sea función del sexo usando una estructura varIdent. fit1 &lt;- lme(y ~ x, random = ~ 1 | grupo, weights = varIdent(form = ~ 1| sexo), data=datos) A continuación repetimos la misma figura de residuales anterior. De esta figura logramos ver que se eliminó el patrón observado antes. plot(fit1, resid(., type = &quot;p&quot;) ~ x | sexo, abline = 0, pch=20) La función summary se puede usar sobre el objeto fit1 para obtener una tabla de resumen, a continuación se ilustra el uso y la salida de summary. summary(fit1) ## Linear mixed-effects model fit by REML ## Data: datos ## AIC BIC logLik ## 1413.453 1429.895 -701.7267 ## ## Random effects: ## Formula: ~1 | grupo ## (Intercept) Residual ## StdDev: 7.844797 2.62634 ## ## Variance function: ## Structure: Different standard deviations per stratum ## Formula: ~1 | sexo ## Parameter estimates: ## Hombre Mujer ## 1.000000 6.725537 ## Fixed effects: y ~ x ## Value Std.Error DF t-value p-value ## (Intercept) 3.917506 1.8639114 179 2.1018 0.037 ## x -5.990032 0.0054473 179 -1099.6411 0.000 ## Correlation: ## (Intr) ## x -0.305 ## ## Standardized Within-Group Residuals: ## Min Q1 Med Q3 Max ## -2.01600189 -0.58592550 -0.02227228 0.49152791 3.26640788 ## ## Number of Observations: 200 ## Number of Groups: 20 Según el resultado anterior \\(\\hat{\\boldsymbol{\\Theta}}=(\\hat{\\beta}_0=3.92, \\hat{\\beta}_1=-5.99, \\hat{\\sigma}=2.63, \\hat{\\delta}_H=1, \\hat{\\delta}_M=6.73, \\hat{\\sigma}_{b0}=7.84)^\\top\\) mientras que el vector real de parámetros es \\(\\boldsymbol{\\Theta}=(\\beta_0=4, \\beta_1=-6, \\sigma=3, \\delta_H=1, \\delta_H=6, \\sigma_{b0}=8)^\\top\\). References "],["predict-new.html", "13 Predicción", " 13 Predicción En este capítulo se mostrará como usar hacer predicciones para nuevas observaciones. Debo revisar la siguiente pregunta. https://stats.stackexchange.com/questions/147836/prediction-interval-for-lmer-mixed-effects-model-in-r "],["glmm.html", "14 Modelos Lineales Generalizados Mixtos 14.1 Videos de apoyo", " 14 Modelos Lineales Generalizados Mixtos Los modelos lineales generalizados mixtos (glmm) fueron propuestos por (Breslow and Clayton 1993) y en ellos se asume que existe una relación entre el vector de observaciones \\(\\boldsymbol{Y}_i\\) del sujeto o grupo \\(i\\) y las covariables por medio de la siguiente expresión \\[\\begin{equation} \\begin{aligned} \\boldsymbol{Y}_i \\mid \\boldsymbol{b}_i &amp;\\sim \\mathcal{F}(\\boldsymbol{X}_i \\boldsymbol{\\beta} + \\boldsymbol{Z}_i \\boldsymbol{b}_i, \\phi), \\\\ \\boldsymbol{b}_i &amp;\\sim \\mathcal{N}(\\boldsymbol{0}, \\boldsymbol{D}), \\end{aligned} \\tag{14.1} \\end{equation}\\] donde \\(\\mathcal{F}\\) corresponde a una distribución de la familia exponencial que incluye las distribuciones normal, Poisson, binomial negativa, gamma e inversa gaussiana. Las matrices \\(\\boldsymbol{X}_i\\) y \\(\\boldsymbol{Z}_i\\) son matrices de diseño conocidas con la información de las covariables, siendo \\(\\boldsymbol{X}_i\\) de dimensión \\(n_i \\times p\\) y \\(\\boldsymbol{Z}_i\\) de dimensión \\(n_i \\times q\\). El elemento \\(\\boldsymbol{\\beta}\\) representa el vector de efectos fijos general, \\(\\boldsymbol{b}_i\\) el vector de efectos aleatorios exclusivo para el grupo \\(i\\). El vector \\(\\boldsymbol{b}_i\\) en la expresión (14.1) es llamado efecto aleatorio porque éste cambia la media de sujeto a sujeto y su función es la de mejorar el ajuste general dado por el elemento \\(\\boldsymbol{X}_i \\boldsymbol{\\beta}\\) al agregar la cantidad \\(\\boldsymbol{Z}_i \\boldsymbol{b}_i\\). El modelo dado en la expresión (14.1) es llamado también modelo mixto porque involucra tanto efectos fijos (\\(\\boldsymbol{\\beta}\\)) como efectos aleatorios (\\(\\boldsymbol{b}_i\\)). La distribución marginal de \\(\\boldsymbol{Y}_i\\) está dada por \\[\\begin{equation} f_i(\\boldsymbol{Y}_i) = \\int f(\\boldsymbol{Y}_i | \\boldsymbol{b}_i) f(\\boldsymbol{b}_i) \\, d \\boldsymbol{b}_i \\end{equation}\\] donde \\(f(\\boldsymbol{Y}_i | \\boldsymbol{b}_i)\\) corresponde a la densidad normal, Poisson, binomial negativa, gamma o inversa gaussina y \\(f(\\boldsymbol{b}_i)\\) corresponde a la distribución normal bivariada mostrada en (14.1). La función de verosimilitud para el vector de parámetros \\(\\boldsymbol{\\Theta}=(\\boldsymbol{\\beta}, \\phi, \\boldsymbol{D})^\\top\\) se puede escribir como \\[ L(\\boldsymbol{\\Theta}) = \\prod_{i=1}^{n} \\int f(\\boldsymbol{Y}_i | \\boldsymbol{b}_i) f(\\boldsymbol{b}_i) \\, d \\boldsymbol{b}_i . \\] 14.1 Videos de apoyo A continuación se muestran los videos sobre glmm creados por la profesora Christina Knudson. Esta lista de reproducción contiene varios con explicaciones sencillas sobre los glmm que sirven como introducción al tema. A continuación el primer video de la lista de reproducción. A continuación se muestran los videos sobre glmm creados por Mark Williamson. References "],["pac-glmmTMB.html", "15 Paquete glmmTMB 15.1 Función glmmTMB Ejemplo: modelo normal con intercepto aleatorio Ejemplo: recuperando los interceptos aleatorios Ejemplo: modelo gamma con intercepto aleatorio", " 15 Paquete glmmTMB El paquete glmmTMB de Brooks et al. (2022) se utiliza para estimar modelos glmm por medio de máxima verosimilitud a través de ‘TMB’ (Template Model Builder). Se supone que los efectos aleatorios son gaussianos en la escala del predictor lineal y se integran utilizando la aproximación de Laplace. Los gradientes se calculan mediante la diferenciación automática. Al visitar este enlace se encontrará la página de apoyo del paquete, allí se puede consultar el manual de referencia y las viñetas. 15.1 Función glmmTMB La función glmmTMB es la principal función del paquete glmmTMB. Esta función sirve para ajustar un glmm y su estructura es la siguiente: glmmTMB(formula, data = NULL, family = gaussian(), ziformula = ~0, dispformula = ~1, weights = NULL, offset = NULL, contrasts = NULL, na.action, se = TRUE, verbose = FALSE, doFit = TRUE, control = glmmTMBControl(), REML = FALSE, start = NULL, map = NULL, sparseX = NULL ) Los principales argumentos de la función son: formula: es una fórmula similar a la usada en el modelo lineal clásico. Un ejemplo de fórmula sería y ~ 1 + x1 + x2 + (1 + x2 | grupo) con la cual se indican los efectos fijos y los efectos aleatorios del modelo. Más abajo hay una tabla con más detalles sobre la fórmula. data: marco de datos donde están las variables. family: argumento para indicar la distribución de la variable respuesta. REML: valor lógico que sirve para indicar si queremos estimaciones maximizando la verosimilitud restringida o la verosimilitud usual. Ejemplo: modelo normal con intercepto aleatorio En este ejemplo vamos a simular observaciones \\(n_i=50\\) observaciones para \\(G=10\\) grupos (en total 500 obs) que tengan la estructura mostrada abajo. El objetivo del ejemplo es ilustrar el uso de la función glmmTMB para estimar los parámetros del modelo. \\[\\begin{align*} y_{ij} | b_0 &amp;\\sim N(\\mu_{ij}, \\sigma^2_y) \\\\ \\mu_{ij} &amp;= 4 - 6 x_{ij} + b_{0i} \\\\ \\sigma^2_y &amp;= 16 \\\\ b_{0} &amp;\\sim N(0, \\sigma^2_{b0}=625) \\\\ x_{ij} &amp;\\sim U(-5, 6) \\end{align*}\\] El vector de parámetros de este modelo es \\(\\boldsymbol{\\Theta}=(\\beta_0=4, \\beta_1=-6, \\sigma_y=4, \\sigma_{b0}=25)^\\top\\). Solución. El código para simular las 500 observaciones se muestra a continuación. Observe que se fijó la semilla en dos ocasiones para que el lector pueda replicar el ejemplo y obtener los mismos resultados. ni &lt;- 50 G &lt;- 10 nobs &lt;- ni * G grupo &lt;- factor(rep(x=1:G, each=ni)) obs &lt;- rep(x=1:ni, times=G) set.seed(1234567) x &lt;- runif(n=nobs, min=-5, max=6) set.seed(1234567) b0 &lt;- rnorm(n=G, mean=0, sd=sqrt(625)) # Intercepto aleatorio b0 &lt;- rep(x=b0, each=ni) # El mismo intercepto aleatorio pero repetido media &lt;- 4 - 6 * x + b0 set.seed(1234567) y &lt;- rnorm(n=nobs, mean=media, sd=sqrt(16)) datos &lt;- data.frame(obs, grupo, b0, x, media, y) Vamos a explorar los datos simulados. library(rmarkdown) paged_table(datos, options = list(rows.print = 6)) El siguiente paso es dibujar los datos para explorar si sería apropiado usar un modelo con intercepto aleatorio (obvio porque así se simularon los datos). El código para dibujar los datos se muestra abajo. library(ggplot2) ggplot(datos, aes(x, y, color=grupo) ) + geom_point() + labs(colour=&quot;Grupo/Cluster&quot;) En la figura anterior se observa un patrón claro, todas las 10 nubes de puntos tienen la misma pendiente pero diferente intercepto con el eje vertical, eso se debe a que en la simulación se incluyó un \\(b_0\\). Para estimar los parámetros del modelo se usa la función glmmTMB de la siguiente forma. library(glmmTMB) fit1 &lt;- glmmTMB(y ~ x + (1 | grupo), data = datos) La función summary se puede usar sobre el objeto fit1 para obtener una tabla de resumen, a continuación se ilustra el uso y la salida de summary. summary(fit1) ## Family: gaussian ( identity ) ## Formula: y ~ x + (1 | grupo) ## Data: datos ## ## AIC BIC logLik deviance df.resid ## 2871.3 2888.1 -1431.6 2863.3 496 ## ## Random effects: ## ## Conditional model: ## Groups Name Variance Std.Dev. ## grupo (Intercept) 579.20 24.066 ## Residual 15.46 3.931 ## Number of obs: 500, groups: grupo, 10 ## ## Dispersion estimate for gaussian family (sigma^2): 15.5 ## ## Conditional model: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) 2.23779 7.61256 0.29 0.769 ## x -6.02640 0.05614 -107.35 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Según el resultado anterior \\(\\hat{\\boldsymbol{\\Theta}}=(\\hat{\\beta}_0=2.2378, \\hat{\\beta}_1=-6.0264, \\hat{\\sigma}_y=3.931, \\hat{\\sigma}_{b0}=24.066)^\\top\\) mientras que el vector real de parámetros es \\(\\boldsymbol{\\Theta}=(\\beta_0=4, \\beta_1=-6, \\sigma_y=4, \\sigma_{b0}=25)^\\top\\). Compare los resultados de la tabla anterior obtenida con la función lmer anterior con los resultados obtenidos con la función lme de capítulo 7. ¿Hay alguna similitud? Ejemplo: recuperando los interceptos aleatorios ¿Cómo se pueden obtener los interceptos aleatorios a partir del modelo ajustado en la sección anterior? Solución. Para obtener los interceptos aleatorios se usa la función ranef del paquete glmmTMB de Brooks et al. (2022). A continuación vamos a obtener los interceptos aleatorios y los vamos a comparar con los \\(b_0\\) simulados. interceptos_aleatorios &lt;- ranef(fit1) cbind(interceptos_aleatorios$grupo, b0=unique(b0)) ## b0 ## [1,] 3.917594 ## [2,] 34.345280 ## [3,] 18.266756 ## [4,] -33.770023 ## [5,] -0.212874 ## [6,] 8.024547 ## [7,] -44.453710 ## [8,] 22.737596 ## [9,] -22.985108 ## [10,] -3.942871 De la salida anterior vemos que los \\(\\tilde{b}_0\\) son cercanos a los valores reales de \\(b_0\\). La comparación anterior solo es posible cuando usamos datos simulados. Cuando se usan datos de un fenómeno real no se tienen los valores de \\(b_0\\). Ejemplo: modelo gamma con intercepto aleatorio En este ejemplo vamos a simular observaciones \\(n_i=20\\) observaciones para \\(G=10\\) grupos (en total 200 obs) que tengan la estructura mostrada abajo. El objetivo del ejemplo es ilustrar el uso de la función glmmTMB para estimar los parámetros del modelo. \\[\\begin{align*} y_{ij} | b_0 &amp;\\sim Gamma(\\mu_{ij}, \\phi) \\\\ \\log(\\mu_{ij}) &amp;= 2 - 8 x_{ij} + b_{0i} \\\\ \\phi &amp;= 0.5 \\\\ b_{0} &amp;\\sim N(0, \\sigma^2_{b0}=9) \\\\ x &amp;\\sim U(0, 1) \\end{align*}\\] El vector de parámetros de este modelo es \\(\\boldsymbol{\\Theta}=(\\beta_0=2, \\beta_1=-8, \\phi=0.5, \\sigma_{b0}=3)^\\top\\). Solución. La función rgamma_glm que se muestra a continuación es una modificación de la función rgamma para tener la parametrización usada en los glm. rgamma_glm &lt;- function(n, mu, phi) { x &lt;- rgamma(n=n, shape=1/phi, scale=mu*phi) return(x) } A continuación el código para simular datos del modelo de interés. ni &lt;- 20 G &lt;- 10 nobs &lt;- ni * G grupo &lt;- factor(rep(x=1:G, each=ni)) obs &lt;- rep(x=1:ni, times=G) set.seed(123456) x &lt;- runif(n=nobs, min=0, max=1) set.seed(123456) b0 &lt;- rnorm(n=G, mean=0, sd=sqrt(9)) # Intercepto aleatorio b0 &lt;- rep(x=b0, each=ni) # El mismo intercepto aleatorio pero repetido media &lt;- exp(2 - 8 * x + b0) set.seed(123456) y &lt;- rgamma_glm(n=nobs, mu=media, phi=0.5) datos &lt;- data.frame(obs, grupo, b0, x, media, y) Vamos a explorar los datos simulados. library(rmarkdown) paged_table(datos, options = list(rows.print = 6, cols.print=6)) El siguiente paso es explorar los datos simulados. El código para dibujar los datos se muestra abajo. library(ggplot2) ggplot(datos, aes(x, y, color=grupo) ) + geom_point() + labs(colour=&quot;Grupo/Cluster&quot;) Para estimar los parámetros del modelos se usa la función glmer de la siguiente forma. library(glmmTMB) fit2 &lt;- glmmTMB(y ~ x + (1 | grupo), family=Gamma(link=&quot;log&quot;), data = datos) La función summary se puede usar sobre el objeto fit2 para obtener una tabla de resumen, a continuación se la salida de summary. summary(fit2) ## Family: Gamma ( log ) ## Formula: y ~ x + (1 | grupo) ## Data: datos ## ## AIC BIC logLik deviance df.resid ## 595.9 609.1 -294.0 587.9 196 ## ## Random effects: ## ## Conditional model: ## Groups Name Variance Std.Dev. ## grupo (Intercept) 9.073 3.012 ## Number of obs: 200, groups: grupo, 10 ## ## Dispersion estimate for Gamma family (sigma^2): 0.507 ## ## Conditional model: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) 4.4102 0.9581 4.60 4.16e-06 *** ## x -8.0789 0.1830 -44.14 &lt; 2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Según el resultado anterior \\(\\hat{\\boldsymbol{\\Theta}}=(\\hat{\\beta}_0=4.4102, \\hat{\\beta}_1=-8.0789, \\hat{\\phi}=0.507, \\hat{\\sigma}_{bo}=3.012)^\\top\\) mientras que el vector real de parámetros es \\(\\boldsymbol{\\Theta}=(\\beta_0=2, \\beta_1=-8, \\phi=0.50, \\sigma_{b0}=3)^\\top\\). References "],["pac-glmm.html", "16 Paquete glmm 16.1 Función glmm Ejemplo: modelo Poisson con intercepto aleatorio", " 16 Paquete glmm El paquete glmm de Knudson (2022) aproxima la verosimilitud de un modelo mixto lineal generalizado mediante aproximación de Monte Carlo. Al visitar este enlace se encontrará la página de apoyo del paquete, allí se puede consultar el manual de referencia y las viñetas. 16.1 Función glmm La función glmm es la principal función del paquete glmm. Esta función sirve para ajustar un glmm y su estructura es la siguiente: glmm(fixed, random, varcomps.names, data, family.glmm, m, varcomps.equal, weights=NULL, doPQL = TRUE,debug=FALSE, p1=1/3,p2=1/3, p3=1/3, rmax=1000,iterlim=1000, par.init, zeta=5, cluster=NULL) Los principales argumentos de la función son: formula: es una fórmula similar a la usada en el modelo lineal clásico. Un ejemplo de fórmula sería y ~ 1 + x1 + x2. random: es una fórmula solo con lado derecho. Si queremos indicar intercepto aleatorio se escribe ~ 1 | group y si se desea intercepto y pendiente aleatoria se escribe ~ 1 + x2 | group. data: marco de datos donde están las variables. family.glm: argumento para indicar la distribución de la variable respuesta. Ejemplo: modelo Poisson con intercepto aleatorio En este ejemplo vamos a simular observaciones \\(n_i=50\\) observaciones para \\(G=10\\) grupos (en total 500 obs) que tengan la estructura mostrada abajo. El objetivo del ejemplo es ilustrar el uso de la función glmm para estimar los parámetros del modelo. \\[\\begin{align*} y_{ij} | b_0 &amp;\\sim Poisson(\\mu_{ij}) \\\\ \\log(\\mu_{ij}) &amp;= 4 - 6 x_{ij} + b_{0i} \\\\ \\sigma^2_y &amp;= 16 \\\\ b_{0} &amp;\\sim N(0, \\sigma^2_{b0}=4) \\\\ x_{ij} &amp;\\sim U(0, 1) \\end{align*}\\] El vector de parámetros de este modelo es \\(\\boldsymbol{\\Theta}=(\\beta_0=4, \\beta_1=-6, \\sigma_y=4, \\sigma_{b0}=4)^\\top\\). Solución. El código para simular las 500 observaciones se muestra a continuación. Observe que se fijó la semilla en dos ocasiones para que el lector pueda replicar el ejemplo y obtener los mismos resultados. ni &lt;- 50 G &lt;- 10 nobs &lt;- ni * G grupo &lt;- factor(rep(x=1:G, each=ni)) obs &lt;- rep(x=1:ni, times=G) set.seed(1234567) x &lt;- runif(n=nobs, min=0, max=1) set.seed(1234567) b0 &lt;- rnorm(n=G, mean=0, sd=sqrt(4)) # Intercepto aleatorio b0 &lt;- rep(x=b0, each=ni) # El mismo intercepto aleatorio pero repetido media &lt;- exp(4 - 6 * x + b0) set.seed(1234567) y &lt;- rpois(n=nobs, lambda=media) datos &lt;- data.frame(obs, grupo, b0, x, media, y) Vamos a explorar los datos simulados. library(rmarkdown) paged_table(datos, options = list(rows.print = 6)) El siguiente paso es dibujar los datos para explorar si sería apropiado usar un modelo con intercepto aleatorio (obvio porque así se simularon los datos). El código para dibujar los datos se muestra abajo. library(ggplot2) ggplot(datos, aes(x, y, color=grupo) ) + geom_point() + labs(colour=&quot;Grupo/Cluster&quot;) Para estimar los parámetros del modelo se usa la función glmm de la siguiente forma. library(glmm) fit1 &lt;- glmm(y ~ x, random = list(y ~ 0 + grupo), varcomps.names = c(&quot;b0&quot;), family.glmm = poisson.glmm, data = datos, m = 10000) La función summary se puede usar sobre el objeto fit1 para obtener una tabla de resumen, a continuación se ilustra el uso y la salida de summary. summary(fit1) Call: glmm(fixed = y ~ x, random = list(y ~ 0 + grupo), varcomps.names = c(&quot;b0&quot;), data = datos, family.glmm = poisson.glmm, m = 10000) Link is: &quot;log&quot; Fixed Effects: Estimate Std. Error z value Pr(&gt;|z|) (Intercept) 0 0 28.39 &lt;2e-16 *** x -10 0 -115.47 &lt;2e-16 *** --- Signif. codes: 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 Variance Components for Random Effects (P-values are one-tailed): Estimate Std. Error z value Pr(&gt;|z|)/2 b0 0 0 2.212 0.0135 * --- Signif. codes: 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 Nota: este paquete se debe usar con precaución. References "],["pac-MASS.html", "17 Paquete MASS 17.1 Función glmmPQL Ejemplo: modelo Bernoulli (binomial) con intercepto aleatorio 17.2 what it means for AIC NA in glmmPQL (MASS) summary output? 17.3 Two questions on the results from glmmPQL(MASS) 17.4 How do I interpret the variance of random effect in a generalized linear mixed model?", " 17 Paquete MASS El paquete MASS de Ripley (2022) se utiliza para estimar modelos glmm por medio de Penalized Quasi-Likelihood (PQL). Al visitar este enlace se encontrará la página de apoyo del paquete, allí se puede consultar el manual de referencia y las viñetas. 17.1 Función glmmPQL La función glmmPQL es la principal función del paquete glmmMAAS. Esta función sirve para ajustar un glmm y su estructura es la siguiente: glmmPQL(fixed, random, family, data, correlation, weights, control, niter = 10, verbose = TRUE, ...) Los principales argumentos de la función son: formula: es una fórmula similar a la usada en el modelo lineal clásico. Un ejemplo de fórmula sería y ~ 1 + x1 + x2 + (1 + x2 | grupo) con la cual se indican los efectos fijos y los efectos aleatorios del modelo. Más abajo hay una tabla con más detalles sobre la fórmula. random: es una fórmula solo con lado derecho. Si queremos indicar intercepto aleatorio se escribe ~ 1 | group y si se desea intercepto y pendiente aleatoria se escribe ~ 1 + x2 | group. data: marco de datos donde están las variables. family: argumento para indicar la distribución de la variable respuesta. Ejemplo: modelo Bernoulli (binomial) con intercepto aleatorio En este ejemplo vamos a simular observaciones \\(n_i=50\\) observaciones para \\(G=10\\) grupos (en total 500 obs) que tengan la estructura mostrada abajo. El objetivo del ejemplo es ilustrar el uso de la función glmmPQL para estimar los parámetros del modelo. \\[\\begin{align*} y_{ij} | b_0 &amp;\\sim \\text{Bernoulli}(\\mu_{ij}) \\\\ \\text{logit}(\\mu_{ij}) &amp;= 4 - 8 x_{ij} + b_{0i} \\\\ b_{0} &amp;\\sim N(0, \\sigma^2_{b0}=4) \\\\ x_{ij} &amp;\\sim U(0, 1) \\end{align*}\\] El vector de parámetros de este modelo es \\(\\boldsymbol{\\Theta}=(\\beta_0=4, \\beta_1=-8, \\sigma_{b0}=2)^\\top\\). Solución. El código para simular las 500 observaciones se muestra a continuación. Observe que se fijó la semilla en dos ocasiones para que el lector pueda replicar el ejemplo y obtener los mismos resultados. logit_inv &lt;- function(x) exp(x) / (exp(x) + 1) # Función enlace inversa ni &lt;- 50 G &lt;- 10 nobs &lt;- ni * G grupo &lt;- factor(rep(x=1:G, each=ni)) obs &lt;- rep(x=1:ni, times=G) set.seed(12345) x &lt;- runif(n=nobs, min=0, max=1) set.seed(12345) b0 &lt;- rnorm(n=G, mean=0, sd=sqrt(4)) # Intercepto aleatorio b0 &lt;- rep(x=b0, each=ni) # El mismo intercepto aleatorio pero repetido prob &lt;- logit_inv(4 - 8 * x + b0) set.seed(12345) y &lt;- rbinom(n=nobs, size=1, prob=prob) datos &lt;- data.frame(obs, grupo, b0, x, prob, y) Para estimar los parámetros del modelo se usa la función glmmPQL de la siguiente forma. library(nlme) library(MASS) fit1 &lt;- glmmPQL(y ~ x, random = ~ 1 | grupo, niter=20, family = binomial(link = &quot;logit&quot;), data = datos) La función summary se puede usar sobre el objeto fit1 para obtener una tabla de resumen, a continuación se ilustra el uso y la salida de summary. summary(fit1) ## Linear mixed-effects model fit by maximum likelihood ## Data: datos ## AIC BIC logLik ## NA NA NA ## ## Random effects: ## Formula: ~1 | grupo ## (Intercept) Residual ## StdDev: 3.089343 1.195473 ## ## Variance function: ## Structure: fixed weights ## Formula: ~invwt ## Fixed effects: y ~ x ## Value Std.Error DF t-value p-value ## (Intercept) 4.864553 1.1476975 489 4.238533 0 ## x -7.811406 0.9982813 489 -7.824854 0 ## Correlation: ## (Intr) ## x -0.493 ## ## Standardized Within-Group Residuals: ## Min Q1 Med Q3 Max ## -5.88958933 -0.20167529 0.02509534 0.24445852 8.17974927 ## ## Number of Observations: 500 ## Number of Groups: 10 Según el resultado anterior \\(\\hat{\\boldsymbol{\\Theta}}=(\\hat{\\beta}_0=4.86, \\hat{\\beta}_1=-7.81, \\hat{\\sigma}_{b0}=3.09)^\\top\\) mientras que el vector real de parámetros es \\(\\boldsymbol{\\Theta}=(\\beta_0=4, \\beta_1=-8, \\sigma_{b0}=2)^\\top\\). 17.2 what it means for AIC NA in glmmPQL (MASS) summary output? Esta pregunta fue hecha en StackOverFlow y puede ser consultada en este enlace. 17.3 Two questions on the results from glmmPQL(MASS) Esta pregunta fue hecha en la comunidad de usuarios de R y puede ser consultada en este enlace. 17.4 How do I interpret the variance of random effect in a generalized linear mixed model? Esta pregunta fue hecha en CrossValidated y puede ser consultada en este enlace. References "],["glmm_poisson.html", "18 GLMM Poisson", " 18 GLMM Poisson En este capítulo se presenta un ejemplo de glmm con variable respuesta Poisson y está basado en esta publicación. A continuación la base de datos a utilizar. require(foreign) datos &lt;- read.dta(&quot;https://stats.idre.ucla.edu/stat/data/hsbdemo.dta&quot;) # Cambios menores a algunas variables datos$cid &lt;- factor(datos$cid) datos$female &lt;- ifelse(datos$female == &#39;female&#39;, 1, 0) Los datos corresponden a una muestra de 200 estudiantes de educación secundaria, los cuales están agrupados en 20 escuelas diferentes. El propósito es modelar el número de premios que recibe un estudiante dada la escuela a la cual pertenece, teniendo en cuenta la variable género como la variable que mejor podría ayudar en la predicción. Las variables de la base de datos son: awards: Variable respuesta que hace referencia al número de premios que recibe un estudiante. id: Identificación única de los estudiantes de educación secundaria que participaron en el estudio. female: Variable correspondiente al género de los estudiantes. ses: Variable categórica que representa el estatus socioeconómico del estudiante, teniendo tres distinciones las cuales son: bajo, medio y alto. schtyp: Tipo de escuela, ya sea privado o público. prog: Programa de formación del estudiante, ya sea general, vocación o académico. read: Puntuación del estudiante en comprensión lectora. write: Puntuación del estudiante en escritura. math: Puntuación del estudiante en matemáticas. science: Puntuación del estudiante en ciencias. honors: Variable que hace referencia si el estudiante presenta matrículas de honor o no. cid: Variable que indica la escuela a la cual pertenece el estudiante. Vamos a explorar las primeras líneas de la base de datos. head(datos, n=5) ## id female ses schtyp prog read write math science socst honors ## 1 45 1 low public vocation 34 35 41 29 26 not enrolled ## 2 108 0 middle public general 34 33 41 36 36 not enrolled ## 3 15 0 high public vocation 39 39 44 26 42 not enrolled ## 4 67 0 low public vocation 37 37 42 33 32 not enrolled ## 5 153 0 middle public vocation 39 31 40 39 51 not enrolled ## awards cid ## 1 0 1 ## 2 0 1 ## 3 0 1 ## 4 0 1 ## 5 0 1 El siguiente código sirve para construir un histograma que muestra el número de premios por cada escuela. library(ggplot2) ggplot(datos, aes(awards)) + geom_histogram(binwidth = 0.5) + facet_wrap(~cid) De la figura anterior vemos que el comportamiento de la variable respuesta awards es muy diferente dada la escuela. En la siguiente figura se relaciona el número de premios awards con la variable género. ggplot(datos, aes(factor(awards))) + geom_bar(aes(fill = factor(female)), position = &quot;fill&quot;) + geom_hline(yintercept = 0.5) De la figura anterior se observa una posible relación entre el número de premios está relacionado y el género. Los modelos lineales generalizados mixtos nos permiten modelar la variable respuesta con la distribución Poisson o la binomial negativa, en este caso, vamos a usar la distribución Poisson. El primer modelo que vamos a considerar aquí es el siguiente: \\[\\begin{align*} y_{ij} | b_0 &amp;\\sim Poisson(\\mu_{ij}) \\\\ \\log(\\mu_{ij}) &amp;= \\beta_0 + b_{0i} \\\\ b_0 &amp;\\sim N(0, \\sigma_{b0}^2) \\end{align*}\\] con \\(i=1, 2, \\ldots, 20\\) y \\(j=1, 2, \\ldots, n_i\\). El modelo anterior se va a ajustar con la función glmer del paquete lme4 de Bates et al. (2022) y utilizando 15 puntos en la aproximación de Gauss para la log-verosimilitud. require(lme4) m1 &lt;- glmer(awards ~ 1 + (1 | cid), data = datos, family = poisson(link = &quot;log&quot;), nAGQ = 15) Los resultados del modelo se muestran a continuación. summary(m1) ## Generalized linear mixed model fit by maximum likelihood (Adaptive ## Gauss-Hermite Quadrature, nAGQ = 15) [glmerMod] ## Family: poisson ( log ) ## Formula: awards ~ 1 + (1 | cid) ## Data: datos ## ## AIC BIC logLik deviance df.resid ## 228.6 235.2 -112.3 224.6 198 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -1.3857 -0.5260 -0.3383 0.3379 3.3769 ## ## Random effects: ## Groups Name Variance Std.Dev. ## cid (Intercept) 1.458 1.207 ## Number of obs: 200, groups: cid, 20 ## ## Fixed effects: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) -0.009572 0.290292 -0.033 0.974 El segundo modelo que se propone es una modificación del modelo 1, agregando como variable explicativa el género femenino. El modelo propuesto es el siguiente: \\[\\begin{align*} y_{ij} | b_0 &amp;\\sim Poisson(\\mu_{ij}) \\\\ \\log(\\mu_{ij}) &amp;= \\beta_0 + \\beta_1 female_{ij} + b_{0i} \\\\ b_0 &amp;\\sim N(0, \\sigma_{b0}^2) \\end{align*}\\] con \\(i=1, 2, \\ldots, 20\\) y \\(j=1, 2, \\ldots, n_i\\). require(lme4) m2 &lt;- glmer(awards ~ 1 + female + (1 | cid), data = datos, family = poisson(link = &quot;log&quot;), nAGQ = 15) Los resultados del modelo se muestran a continuación. summary(m2) ## Generalized linear mixed model fit by maximum likelihood (Adaptive ## Gauss-Hermite Quadrature, nAGQ = 15) [glmerMod] ## Family: poisson ( log ) ## Formula: awards ~ 1 + female + (1 | cid) ## Data: datos ## ## AIC BIC logLik deviance df.resid ## 221.1 231.0 -107.6 215.1 197 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -1.5312 -0.5919 -0.3304 0.2047 2.8806 ## ## Random effects: ## Groups Name Variance Std.Dev. ## cid (Intercept) 1.431 1.196 ## Number of obs: 200, groups: cid, 20 ## ## Fixed effects: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) -0.2229 0.2975 -0.749 0.45370 ## female 0.3632 0.1193 3.044 0.00234 ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Correlation of Fixed Effects: ## (Intr) ## female -0.252 Para comparar los dos modelos ajustados propuestos colocamos los resultados en una única tabla como se muestra a continuación. library(&quot;texreg&quot;) screenreg(list(m1, m2)) ## ## ========================================== ## Model 1 Model 2 ## ------------------------------------------ ## (Intercept) -0.01 -0.22 ## (0.29) (0.30) ## female 0.36 ** ## (0.12) ## ------------------------------------------ ## AIC 228.63 221.12 ## BIC 235.23 231.01 ## Log Likelihood -112.32 -107.56 ## Num. obs. 200 200 ## Num. groups: cid 20 20 ## Var: cid (Intercept) 1.46 1.43 ## ========================================== ## *** p &lt; 0.001; ** p &lt; 0.01; * p &lt; 0.05 library(stargazer) stargazer(m1, m2, type = &quot;html&quot;) Dependent variable: awards (1) (2) female 0.363*** (0.119) Constant -0.010 -0.223 (0.290) (0.298) Observations 200 200 Log Likelihood -112.315 -107.558 Akaike Inf. Crit. 228.630 221.116 Bayesian Inf. Crit. 235.227 231.011 Note: p&lt;0.1; p&lt;0.05; p&lt;0.01 En los resultados que obtenemos de esta tabla podemos ver que la log-verosimilitud aument para el modelo 2 en relación ál modelo 1. Además podemos observar que tanto el AIC como el BIC del modelo 2 son menores que los del modelo 1. Por lo tanto, basados en esto, concluimos que el mejor modelo propuesto es el modelo 2, es decir, vale la pena agregarle como variable explicativa el género femenino, va a generar un modelo más confiable. ## QQ plot plot(ranef(m2)) ## $cid ## Caterpillar plot lattice::dotplot(ranef(m2, condVar = TRUE)) ## $cid Los modelos anteriores se pueden ajustar usando la función glmmadmb del paquete glmmADMB, a continuación se muestra el código. Para conocer más sobre este paquete se recomienda visitar este enlace library(glmmADMB) m1_alt &lt;- glmmadmb(awards ~ 1 + (1 | cid), data = datos, family = &quot;poisson&quot;, link = &quot;log&quot;) m2_alt &lt;- glmmadmb(awards ~ 1 + female + (1 | cid), data = datos, family = &quot;poisson&quot;, link = &quot;log&quot;) References "],["glmm_gamma.html", "19 GLMM gamma", " 19 GLMM gamma En este capítulo se presenta un ejemplo de glmm con variable respuesta gamma. A continuación la base de datos a utilizar. library(hglm) data(semiconductor) En este ejemplo, analizamos los datos de semiconductores tomados de Myers et al. (2002), que implica un experimento diseñado en una planta de semiconductores. Se emplean seis factores, temperatura de laminación, tiempo de laminación, presión de laminación, temperatura de cocción, tiempo de ciclo de cocción y punto de rocío de cocción, y estamos interesados en la curvatura de los dispositivos de sustrato producidos en la planta. La medición de la curvatura se realiza cuatro veces en cada dispositivo fabricado. Cada variable de diseño se toma en dos niveles. Se sabe que la medida no tiene una distribución normal y las medidas tomadas en el mismo dispositivo están correlacionadas. Myers et al. (2002) consideraron un modelo de respuesta gamma con un enlace logarítmico y utilizaron un método GEE asumiendo una correlación de trabajo AR(1). Las variables de la base de datos se muestran a continuación. Device: Subtrate device x1: Lamination Temperature; two levels +1 and -1. x2: Lamination Time; two levels: +1 and -1. x3: Lamination Presure; two levels: +1 and -1. x4: Firing Temperature; two levels: +1 and -1. x5: Firing Cycle Time; two levels: +1 and -1. x6: Firing Dew Point: two levels: +1 and -1. y: Camber measure; in 1e-4 in./in. Vamos a explorar las primeras líneas de la base de datos. head(semiconductor, n=5) ## Device x1 x2 x3 x4 x5 x6 y ## 1 1 -1 -1 -1 -1 -1 -1 0.0167 ## 2 1 -1 -1 -1 -1 -1 -1 0.0128 ## 3 1 -1 -1 -1 -1 -1 -1 0.0149 ## 4 1 -1 -1 -1 -1 -1 -1 0.0185 ## 5 2 1 -1 -1 -1 1 1 0.0062 El siguiente código sirve para construir una densidad para la variable respuesta. library(ggplot2) ggplot(semiconductor, aes(y)) + geom_density() De la figura anterior vemos que la variable respuesta tomá solo valores positivos. # install.packages(&quot;GGally&quot;) library(GGally) ## Registered S3 method overwritten by &#39;GGally&#39;: ## method from ## +.gg ggplot2 ggpairs(semiconductor, # Data frame columns = 2:8) # Columns El primer modelo que vamos a ajustar contiene todos los factores x y se puede representar de la siguiente manera. \\[\\begin{align*} y_{ij} | b_0 &amp;\\sim Gamma(\\mu_{ij}, \\phi) \\\\ \\log(\\mu_{ij}) &amp;= \\beta_0 + \\beta_1 x1_{ij} + \\beta_2 x2_{ij} + \\beta_3 x3_{ij} + \\beta_4 x4_{ij} + \\beta_5 x5_{ij} + \\beta_6 x6_{ij} + b_{0i} \\\\ b_{0} &amp;\\sim N(0, \\sigma^2_{b0}) \\end{align*}\\] Para ajustar el modelo anterior usamos el siguiente código. library(lme4) mod1 &lt;- glmer(y ~ x1 + x2 + x3 + x4 + x5 + x6 + (1 | Device), data = semiconductor, family = Gamma(link = log)) summary(mod1) ## Generalized linear mixed model fit by maximum likelihood (Laplace ## Approximation) [glmerMod] ## Family: Gamma ( log ) ## Formula: y ~ x1 + x2 + x3 + x4 + x5 + x6 + (1 | Device) ## Data: semiconductor ## ## AIC BIC logLik deviance df.resid ## -547.0 -527.6 282.5 -565.0 55 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -1.8492 -0.5712 -0.1592 0.7227 2.5022 ## ## Random effects: ## Groups Name Variance Std.Dev. ## Device (Intercept) 0.02734 0.1653 ## Residual 0.09655 0.3107 ## Number of obs: 64, groups: Device, 16 ## ## Fixed effects: ## Estimate Std. Error t value Pr(&gt;|z|) ## (Intercept) -4.7117204 0.0752768 -62.592 &lt; 2e-16 *** ## x1 0.1842486 0.0752816 2.447 0.01439 * ## x2 0.0008432 0.0752894 0.011 0.99106 ## x3 0.3074319 0.0752836 4.084 4.43e-05 *** ## x4 -0.0125486 0.0752601 -0.167 0.86758 ## x5 -0.1943372 0.0752885 -2.581 0.00984 ** ## x6 -0.3660413 0.0752584 -4.864 1.15e-06 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Correlation of Fixed Effects: ## (Intr) x1 x2 x3 x4 x5 ## x1 0.000 ## x2 0.001 0.021 ## x3 0.000 0.008 0.023 ## x4 -0.001 0.005 0.014 -0.007 ## x5 0.000 0.023 0.008 0.021 0.008 ## x6 0.000 -0.007 0.008 0.005 0.008 0.014 Del resumen anterior se observa que los factores x2 y x4 no son significativos, por esa razón vamos a ajustar otro modelo sin esos factores, el modelo se puede representar así. \\[\\begin{align*} y_{ij} | b_0 &amp;\\sim Gamma(\\mu_{ij}, \\phi) \\\\ \\log(\\mu_{ij}) &amp;= \\beta_0 + \\beta_1 x1_{ij} + \\beta_3 x3_{ij} + \\beta_5 x5_{ij} + \\beta_6 x6_{ij} + b_{0i} \\\\ b_{0} &amp;\\sim N(0, \\sigma^2_{b0}) \\end{align*}\\] Para ajustar el modelo anterior usamos el siguiente código. mod2 &lt;- glmer(y ~ x1 + x3 + x5 + x6 + (1 | Device), data = semiconductor, family = Gamma(link = log)) summary(mod2) ## Generalized linear mixed model fit by maximum likelihood (Laplace ## Approximation) [glmerMod] ## Family: Gamma ( log ) ## Formula: y ~ x1 + x3 + x5 + x6 + (1 | Device) ## Data: semiconductor ## ## AIC BIC logLik deviance df.resid ## -551.0 -535.9 282.5 -565.0 57 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -1.8424 -0.5565 -0.1762 0.7429 2.4663 ## ## Random effects: ## Groups Name Variance Std.Dev. ## Device (Intercept) 0.02744 0.1657 ## Residual 0.09652 0.3107 ## Number of obs: 64, groups: Device, 16 ## ## Fixed effects: ## Estimate Std. Error t value Pr(&gt;|z|) ## (Intercept) -4.71177 0.07542 -62.475 &lt; 2e-16 *** ## x1 0.18429 0.07541 2.444 0.0145 * ## x3 0.30732 0.07540 4.076 4.59e-05 *** ## x5 -0.19423 0.07543 -2.575 0.0100 * ## x6 -0.36594 0.07540 -4.853 1.21e-06 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Correlation of Fixed Effects: ## (Intr) x1 x3 x5 ## x1 0.000 ## x3 0.000 0.008 ## x5 0.000 0.023 0.021 ## x6 0.000 -0.007 0.005 0.014 Para comparar los dos modelos ajustados propuestos colocamos los resultados en una única tabla como se muestra a continuación. library(&quot;texreg&quot;) screenreg(list(mod1, mod2)) ## ## ================================================= ## Model 1 Model 2 ## ------------------------------------------------- ## (Intercept) -4.71 *** -4.71 *** ## (0.08) (0.08) ## x1 0.18 * 0.18 * ## (0.08) (0.08) ## x2 0.00 ## (0.08) ## x3 0.31 *** 0.31 *** ## (0.08) (0.08) ## x4 -0.01 ## (0.08) ## x5 -0.19 ** -0.19 * ## (0.08) (0.08) ## x6 -0.37 *** -0.37 *** ## (0.08) (0.08) ## ------------------------------------------------- ## AIC -546.99 -550.96 ## BIC -527.56 -535.85 ## Log Likelihood 282.50 282.48 ## Num. obs. 64 64 ## Num. groups: Device 16 16 ## Var: Device (Intercept) 0.03 0.03 ## Var: Residual 0.10 0.10 ## ================================================= ## *** p &lt; 0.001; ** p &lt; 0.01; * p &lt; 0.05 El problema de comparar los dos modelos se puede resumir con \\(H_0:\\) las variables x2 y x4 no aportan al modelo, versus, \\(H_A:\\) al menos una de esas variables si aporta al modelo. Para abordar el problema lo podemos hacer por medio de la prueba razón de verosimilitud. Debemos tener en cuenta que el modelo 1 tiene 9 parámetros y el modelo 2 tiene 7 parámetros. lrt &lt;- -2 * (logLik(mod2) - logLik(mod1)) lrt ## &#39;log Lik.&#39; 0.02762921 (df=7) pchisq(q=lrt, df=9-7, lower.tail=FALSE) ## &#39;log Lik.&#39; 0.9862804 (df=7) De la salida anterior se tiene que el valor-P = 0.9862804 y mayor que cualquier \\(\\alpha\\), eso significa que no hay evidencia para rechazar \\(H_0\\), en otras palabras, las variables x2 y x4 no aportan al modelo. La prueba de verosimilitud se puede obtener también así: anova(mod1, mod2) ## Data: semiconductor ## Models: ## mod2: y ~ x1 + x3 + x5 + x6 + (1 | Device) ## mod1: y ~ x1 + x2 + x3 + x4 + x5 + x6 + (1 | Device) ## npar AIC BIC logLik deviance Chisq Df Pr(&gt;Chisq) ## mod2 7 -550.96 -535.85 282.48 -564.96 ## mod1 9 -546.99 -527.56 282.50 -564.99 0.0276 2 0.9863 Es posible obtener el valor-P anterior usando boostrap por medio de la función PBmodcomp del paquete pbkrtest de Halekoh and Højsgaard (2021). library(pbkrtest) PBmodcomp(largeModel=mod1, smallModel=mod2, nsim=100, seed=123) Bootstrap test; time: 100.44 sec; samples: 100; extremes: 100; large : y ~ x1 + x2 + x3 + x4 + x5 + x6 + (1 | Device) y ~ x1 + x3 + x5 + x6 + (1 | Device) stat df p.value LRT 0.0276 2 0.9863 PBtest 0.0276 1.0000 --- Signif. codes: 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 En el código anterior se usó la semilla seed = 123 para simular los nuevos conjuntos de datos. De la salida anterior se observa que el valor-P es mayor que un 5% con lo que se concluye que no hay evidencias para rechazar \\(H_0\\). References "],["residuals.html", "20 Diagnósticos con DHARMa Ejemplo: modelo gamma mixto", " 20 Diagnósticos con DHARMa En este capítulo vamos mostrar el uso del paquete DHARMa de Hartig (2022) para explorar los residuales escalados (scaled residuals) obtenidos por medio de la función residuals. Al visitar este enlace se encontrará la página de apoyo del paquete, allí se puede consultar el manual de referencia. DHARMa stands for “Diagnostics for HierArchical Regression Models” - which, strictly speaking, would make DHARM. But in German, Darm means intestines; plus, the meaning of DHARMa in Hinduism makes the current abbreviation so much more suitable for a package that tests whether your model is in harmony with your data. Tomado de la viñeta del paquete. Ejemplo: modelo gamma mixto En este ejemplo vamos a simular observaciones \\(n_i=50\\) observaciones para \\(G=10\\) grupos (en total 500 obs) que tengan la estructura mostrada abajo. El objetivo del ejemplo es ilustrar el uso del paquete DHARMa para determinar entre dos modelos, el modelo fit1 será el modelo correcto mientras que el modelo fit0 será un modelo sin intercepto aleatorio. \\[\\begin{align*} y_{ij} | b_0 &amp;\\sim Gamma(\\mu_{ij}, \\phi) \\\\ \\log(\\mu_{ij}) &amp;= 2 - 8 x1_{ij} + 3 x2_{ij} + b_{0i} \\\\ \\phi &amp;= 0.5 \\\\ b_{0} &amp;\\sim N(0, \\sigma^2_{b0}=9) \\\\ x1 &amp;\\sim U(0, 1) \\\\ x2 &amp;\\sim U(0, 1) \\end{align*}\\] Solución. Lo primero es simular los datos. La función rgamma_glm sirve para simular observaciones \\(Y\\) con la parametrización gamma de los glm. rgamma_glm &lt;- function(n, mu, phi) { x &lt;- rgamma(n=n, shape=1/phi, scale=mu*phi) return(x) } ni &lt;- 15 G &lt;- 15 nobs &lt;- ni * G grupo &lt;- factor(rep(x=1:G, each=ni)) obs &lt;- rep(x=1:ni, times=G) set.seed(123) x1 &lt;- runif(n=nobs, min=0, max=1) x2 &lt;- runif(n=nobs, min=0, max=1) set.seed(123) b0 &lt;- rnorm(n=G, mean=0, sd=sqrt(9)) # Intercepto aleatorio b0 &lt;- rep(x=b0, each=ni) # El mismo intercepto aleatorio pero repetido media &lt;- exp(2 - 8 * x1 + 3 * x2 + b0) set.seed(123) y &lt;- rgamma_glm(n=nobs, mu=media, phi=0.5) datos &lt;- data.frame(obs, grupo, b0, x1, x2, media, y) A continuación se ajustan los dos modelos de interés. library(glmmTMB) fit0 &lt;- glmmTMB(y ~ x1 + x2, family=Gamma(link=&quot;log&quot;), data = datos) fit1 &lt;- glmmTMB(y ~ x1 + x2 + (1 | grupo), family=Gamma(link=&quot;log&quot;), data = datos) Con el siguiente código se constuyen los gráficos de residuales para el modelo fit0. library(DHARMa) ## This is DHARMa 0.4.6. For overview type &#39;?DHARMa&#39;. For recent changes, type news(package = &#39;DHARMa&#39;) simulationOutput0 &lt;- simulateResiduals(fittedModel = fit0, plot = F) plot(simulationOutput0) De la figura anterior vemos que el valor-P de la prueba KS de normalidad (\\(H_0:\\) la muestra de residuos tiene distribución normal) es 0, lo que indica que hay evidencias para rechazar la normalidad de los errores. Eso implica que el modelo fit0 no es el modelo apropiado para los datos. Este resultado es correcto porque sabemos que fit0 no incluyó el intercepto aleatorio \\(b_0\\). Con el siguiente código se constuyen los gráficos de residuales para el modelo fit1. simulationOutput1 &lt;- simulateResiduals(fittedModel = fit1, plot = F) plot(simulationOutput1) De la figura anterior vemos que el valor-P de la prueba KS de normalidad (\\(H_0:\\) la muestra de residuos tiene distribución normal) es 0.10871, lo que indica que hay NO hay evidencias para rechazar la normalidad de los errores. Eso implica que el modelo fit1 podría ser un modelo apropiado para los datos. Este resultado es correcto porque sabemos que fit1 tiene los elementos con los que se simularon los datos. Consulte las viñetas del paquete para ver más ejemplos sobre el paquete DHARMa. References "],["simul-glmm.html", "21 Simulación de glmm", " 21 Simulación de glmm Simular observaciones de un glmm es muy importante para comprender este tipo de modelos y para estudiar las propiedades de estos modelos. A continuación se muestran los enlaces a varias publicaciones. glmm binomial. glmm Poisson. "],["blobs.html", "22 Otro material interesante", " 22 Otro material interesante En este capítulo se listan algunos blogs y publicaciones interesantes relacionados con modelos mixtos. A Practical Guide to Mixed Models in R. Introduction to linear mixed models. How to choose nlme or lme4 R library for mixed effects models?. GLMM FAQ. Paquete glmmsr. https://stats.stackexchange.com/questions/486561/can-i-compare-lmer-models-with-different-fixed-effects-using-anova "],["references.html", "References", " References "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
