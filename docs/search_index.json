[
["index.html", "Modelos Mixtos con R Bienvenido Estructura del libro Software y convenciones Bloques informativos", " Modelos Mixtos con R Freddy Hern√°ndez Barajas Jorge Leonardo L√≥pez Mart√≠nez 2020-02-18 Bienvenido Este libro est√° destinado para usuarios de R interesados en aplicar modelos mixtos. Freddy Hern√°ndez Barajas Jorge Leonardo L√≥pez Mart√≠nez Estructura del libro En el cap√≠tulo 1 se hace un repaso b√°sico del modelo de regresi√≥n lineal cl√°sico. En el cap√≠tulo 2 se presentan los modelos mixtos. En el cap√≠tulo 3 se presenta el paquete lme4 y sus principales funciones para modelaci√≥n, mientras que en el cap√≠tulo 4 se presenta el paquete nlme y sus principales funciones para modelaci√≥n. Software y convenciones Para realizar este libro usamos los paquetes knitr (Xie 2015) y bookdown (Xie 2019) que permiten unir la ventajas de LaTeX y R en un mismo archivo. En todo el libro se presentar√°n c√≥digos que el lector puede copiar y pegar en su consola de R para obtener los mismos resultados aqu√≠ del libro. Los c√≥digos se destacan en una caja de color similar a la mostrada a continuaci√≥n. 4 + 6 a &lt;- c(1, 5, 6) 5 * a 1:10 Los resultados o salidas obtenidos de cualquier c√≥digo se destacan con dos s√≠mbolos de n√∫meral (##) al inicio de cada l√≠nea o rengl√≥n, esto quiere decir que todo lo que inicie con ## son resultados obtenidos y NO los debe copiar. Abajo se muestran los resultados obtenidos luego de correr el c√≥digo anterior. ## [1] 10 ## [1] 5 25 30 ## [1] 1 2 3 4 5 6 7 8 9 10 Bloques informativos En varias partes del libro usaremos bloques informativos para resaltar alg√∫n aspecto importante. Abajo se encuentra un ejemplo de los bloques y su significado. Nota aclaratoria. Sugerencia. Advertencia. References "],
["reg-lin.html", "1 Regresi√≥n lineal 1.1 Modelo estad√≠stico 1.2 Verosimilitud del modelo", " 1 Regresi√≥n lineal En este cap√≠tulo se presenta el modelo de regresi√≥n lineal cl√°sico. 1.1 Modelo estad√≠stico El modelo estad√≠stico en regresi√≥n lineal cl√°sico permite modelar la media de una variable \\(Y\\) en funci√≥n de \\(k\\) covariables. El modelo se puede expresar como sigue. \\[\\begin{align} \\label{mod2} y_i &amp;\\sim N(\\mu_i, \\sigma^2), \\\\ \\mu_i &amp;= \\beta_0 + \\beta_1 x_{1i} + \\beta_2 x_{2i} + \\cdots + \\beta_k x_{ki}, \\\\ \\sigma^2 &amp;= \\text{constante} \\end{align}\\] donde \\(i=1, 2, \\ldots, n\\) es el √≠ndice que identifica las \\(n\\) observaciones del conjunto de entrenamiento. El vector de par√°metros del modelo es \\(\\boldsymbol{\\theta}=(\\beta_0, \\beta_1, \\cdots, \\beta_k, \\sigma)^\\top\\). 1.2 Verosimilitud del modelo La funci√≥n de verosimilitud \\(L\\) para el modelo es la siguiente: \\[ L(\\boldsymbol{\\theta}) = \\prod_i^n f(y_i \\vert \\beta_0, \\beta_1, \\cdots, \\beta_k, \\sigma), \\] donde \\(f\\) corresponde a la funci√≥n de densidad de la normal. Para estimar el vector de par√°metros \\(\\boldsymbol{\\theta}\\) del modelo se usa el m√©todo de M√°xima Verosimilitud sobre la funci√≥n \\(L\\) o sobre la funci√≥n de log-verosimilitud siguiente: \\[ l(\\boldsymbol{\\theta}) = \\sum_i^n \\log(f(y_i \\vert \\beta_0, \\beta_1, \\cdots, \\beta_k, \\sigma)), \\] Ejemplo Como ilustraci√≥n vamos a usar los datos del ejemplo 3.1 del libro de Montgomery, Peck and Vining (2003). En el ejemplo 3.1 los autores ajustaron un modelo de regresi√≥n lineal m√∫ltiple para explicar el Tiempo necesario para que un trabajador haga el mantenimiento y surta una m√°quina dispensadora de refrescos en funci√≥n de las variables N√∫mero de Cajas y Distancia. Los datos del ejemplo est√°n disponibles en el paquete MPV (por los apellidos de los autores). A continuaci√≥n el c√≥digo para cargar los datos y una muestra de las 6 primeras observaciones de la base de datos, en total se disponen de 20 observaciones. require(MPV) colnames(softdrink) &lt;- c(&#39;tiempo&#39;, &#39;cantidad&#39;, &#39;distancia&#39;) head(softdrink) ## tiempo cantidad distancia ## 1 16.68 7 560 ## 2 11.50 3 220 ## 3 12.03 3 340 ## 4 14.88 4 80 ## 5 13.75 6 150 ## 6 18.11 7 330 Un gr√°fico en 3d es obligratorio para explorar la relaci√≥n entre las variables, este diagrama de puede obtener usando el paquete scatterplot3d. A continuaci√≥n el c√≥digo para construirlo. library(scatterplot3d) attach(softdrink) scatterplot3d(x=cantidad, y=distancia, z=tiempo, pch=16, cex.lab=1, highlight.3d=TRUE, type=&quot;h&quot;, xlab=&#39;Cantidad de cajas&#39;, ylab=&#39;Distancia (pies)&#39;, zlab=&#39;Tiempo (min)&#39;) De la figura anterior se ve claramente que a medida que aumenta el n√∫mero de cajas y la distancia los tiempos tienden a ser mayores. A continuaci√≥n se define la funci√≥n de menos log-verosimilitud para el modelo anterior. A pesar de que nos interesa maximizar la funci√≥n de log-verosimilitud hemos creado su negativo, esto porque la mayor√≠a de las funciones de optimizaci√≥n minimizan y no maximizan; maximizar \\(f(x)\\) es equivalente a minimizar \\(-f(x)\\). minusll &lt;- function(theta, y, x1, x2) { media &lt;- theta[1] + theta[2] * x1 + theta[3] * x2 # Se define la media desvi &lt;- theta[4] # Se define la desviaci√≥n. - sum(dnorm(x=y, mean=media, sd=desvi, log=TRUE)) } Ahora vamos a usar la funci√≥n optim para encontrar los valores que maximizan la funci√≥n de log-verosimilitud, el c√≥digo para hacer eso se muestra a continuaci√≥n. En el par√°metro par se coloca un vector de posibles valores de \\(\\boldsymbol{\\Theta}\\) para iniciar la b√∫squeda, en fn se coloca la funci√≥n de inter√©s, en lower y upper se colocan vectores que indican los l√≠mites de b√∫squeda de cada par√°metro, los \\(\\beta_k\\) pueden variar entre \\(-\\infty\\) y \\(\\infty\\) mientras que el par√°metro \\(\\sigma\\) toma valores en el intervalo \\((0, \\infty)\\). Como la funci√≥n minusll tiene argumentos adicionales y, x1 y x2, estos pasan a la funci√≥n optim al final como se muestra en el c√≥digo. mod1 &lt;- optim(par=c(0, 0, 0, 1), fn=minusll, method=&#39;L-BFGS-B&#39;, lower=c(-Inf, -Inf, -Inf, 0), upper=c(Inf, Inf, Inf, Inf), y=softdrink$tiempo, x1=softdrink$cantidad, x2=softdrink$distancia) En el objeto res1 est√° el resultado de la optimizaci√≥n, para explorar los resultados usamos mod1 ## $par ## [1] 2.34103296 1.61590757 0.01438512 3.05769678 ## ## $value ## [1] 63.41469 ## ## $counts ## function gradient ## 58 58 ## ## $convergence ## [1] 0 ## ## $message ## [1] &quot;CONVERGENCE: REL_REDUCTION_OF_F &lt;= FACTR*EPSMCH&quot; De esta forma el vector de par√°metros estimados del modelo es \\(\\hat{\\boldsymbol{\\theta}}=(2.34, 1.62, 0.01, 3.06)^\\top\\). Usualmente en la pr√°ctica se usa la funci√≥n lm para estimar el vector de par√°metros, a continuaci√≥n el c√≥digo necesario para usar la funcion lm. mod2 &lt;- lm(tiempo ~ cantidad + distancia, data=softdrink) summary(mod2) ## ## Call: ## lm(formula = tiempo ~ cantidad + distancia, data = softdrink) ## ## Residuals: ## Min 1Q Median 3Q Max ## -5.7880 -0.6629 0.4364 1.1566 7.4197 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 2.341231 1.096730 2.135 0.044170 * ## cantidad 1.615907 0.170735 9.464 3.25e-09 *** ## distancia 0.014385 0.003613 3.981 0.000631 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 3.259 on 22 degrees of freedom ## Multiple R-squared: 0.9596, Adjusted R-squared: 0.9559 ## F-statistic: 261.2 on 2 and 22 DF, p-value: 4.687e-16 De la salida anterior vemos que el vector de par√°metros estimados del modelo es \\(\\hat{\\boldsymbol{\\theta}}=(2.34, 1.62, 0.01, 3.26)^\\top\\). Para profundizar en el modelo de regresion lineal se recomienda consultar libro Modelos de Regresi√≥n con R "],
["mod-mix.html", "2 Modelos Mixtos", " 2 Modelos Mixtos Los modelos mixtos fueron propuestos por (Laird and Ware 1982) y en ellos se asume que existe una relaci√≥n entre el vector de observaciones \\(\\boldsymbol{Y}_i\\) del sujeto o grupo \\(i\\) y las covariables por medio de la siguiente expresi√≥n \\[\\begin{equation} \\begin{aligned} \\label{mixedmodel1} \\boldsymbol{Y}_i \\mid \\boldsymbol{b}_i &amp;\\sim \\mathcal{N}(\\boldsymbol{X}_i \\boldsymbol{\\beta} + \\boldsymbol{Z}_i \\boldsymbol{b}_i, \\boldsymbol{\\Sigma}_i), \\\\ \\boldsymbol{b}_i &amp;\\sim \\mathcal{N}(\\boldsymbol{0}, \\boldsymbol{D}), \\end{aligned} \\end{equation}\\] donde \\(\\boldsymbol{X}_i\\) y \\(\\boldsymbol{Z}_i\\) son matrices de dise√±o conocidas con la informaci√≥n de las covariables, siendo \\(\\boldsymbol{X}_i\\) de dimensi√≥n \\(n_i \\times p\\) y \\(\\boldsymbol{Z}_i\\) de dimensi√≥n \\(n_i \\times q\\). El elemento \\(\\boldsymbol{\\beta}\\) representa el vector de efectos fijos general, \\(\\boldsymbol{b}_i\\) el vector de efectos aleatorios exclusivos para el grupo \\(i\\) y las matrices. El vector \\(\\boldsymbol{b}_i\\) en la expresi√≥n es llamado efecto aleatorio porque √©ste cambia la media de sujeto a sujeto y su funci√≥n es la de mejorar el ajuste general dado por el elemento \\(\\boldsymbol{X}_i \\boldsymbol{\\beta}\\) al agregar la cantidad \\(\\boldsymbol{Z}_i \\boldsymbol{b}_i\\). El modelo dado en la expresi√≥n es llamado tambi√©n modelo mixto porque involucra tanto efectos fijos (\\(\\boldsymbol{\\beta}\\)) como efectos aleatorios (\\(\\boldsymbol{b}_i\\)). La distribuci√≥n marginal de \\(\\boldsymbol{Y}_i\\) est√° dada por \\[\\begin{equation} f_i(\\boldsymbol{Y}_i) = \\int f(\\boldsymbol{Y}_i | \\boldsymbol{b}_i) f(\\boldsymbol{b}_i) \\, d \\boldsymbol{b}_i \\end{equation}\\] donde \\(f(\\boldsymbol{Y}_i | \\boldsymbol{b}_i)\\) y \\(f(\\boldsymbol{b}_i)\\) corresponden a las densidades normales mostradas en la expresi√≥n . Esta distribuci√≥n marginal tiene forma cerrada y se puede mostrar f√°cilmente que la distribuci√≥n de \\(\\boldsymbol{Y}_i\\) es una normal multivariada con vector de medias y matriz de covarianzas como se muestra a continuaci√≥n. \\[\\begin{equation} \\boldsymbol{Y}_i \\sim \\mathcal{N}(\\boldsymbol{X}_i \\boldsymbol{\\beta}, \\boldsymbol{V}_i), \\end{equation}\\] donde \\(\\boldsymbol{V}_i=\\boldsymbol{Z}_i \\boldsymbol{D} \\boldsymbol{Z}_i^\\top + \\boldsymbol{\\Sigma}_i\\). El vector de par√°metros en este caso es \\(\\boldsymbol{\\theta}=(\\boldsymbol{\\beta}, \\boldsymbol{\\alpha})^\\top\\) donde \\(\\boldsymbol{\\alpha}\\) consiste de los \\(q(q+1)/2\\) elementos diferentes de la matriz \\(\\boldsymbol{D}\\) y todos los elementos de la matriz \\(\\boldsymbol{\\Sigma}_i\\). References "],
["pac-lme4.html", "3 Paquete lme4 3.1 Funci√≥n lmer Ejemplo: modelo con intercepto aleatorio", " 3 Paquete lme4 El paquete lme4 (Bates et al. 2019) es uno de los paquetes m√°s completos para modelos mixtos. Al visitar este enlace se encontrar√° la p√°gina de apoyo del paquete, all√≠ se puede consultar el manual de referencia y las vi√±etas. 3.1 Funci√≥n lmer La funci√≥n lmer es la principal funci√≥n del paquete (Bates et al. 2019). Esta funci√≥n sirve para ajustar un modelo mixto y su estructura es la siguiente: lmer(formula, data = NULL, REML = TRUE, control = lmerControl(), start = NULL, verbose = 0L, subset, weights, na.action, offset, contrasts = NULL, devFunOnly = FALSE, ...) Los principales argumentos de la funci√≥n son: formula: es una f√≥rmula similar a la usada en el modelo lineal cl√°sico. Un ejemplo de f√≥rmula ser√≠a y ~ 1 + x1 + x2 + (1 + x2) con la cual se indican los efectos fijos y los efectos aleatorios del modelo. M√°s abajo hay una tabla con m√°s detalles sobre la f√≥rmula. data: marco de datos donde est√°n las variables. REML: valor l√≥gico que sirve para indicar si queremos estimaciones maximizando la verosimilitud restringida o la verosimilitud usual. La siguiente imagen corresponde a la tabla 2 de la vi√±eta Fitting Linear Mixed-Effects Models using lme4. En esa tabla las dos primeras columnas muestran formas equivalentes de incluir las estructuras de modelos mixtos m√°s comunes. Ejemplo: modelo con intercepto aleatorio En este ejemplo vamos a simular observaciones \\(ni=50\\) observaciones para \\(G=10\\) grupos (en total 500 obs) que tengan la estructura mostrada abajo. El objetivo del ejemplo es ilustrar el uso de la funci√≥n lmer para estimar los par√°metros del modelo. \\[\\begin{align*} y_{ij} &amp;\\sim N(\\mu_{ij}, \\sigma^2_y) \\\\ \\mu_{ij} &amp;= 4 - 6 x_{ij} + b_{0i} \\\\ \\sigma^2_y &amp;= 16 \\\\ b_{0} &amp;\\sim N(0, \\sigma^2_{b0}=625) \\\\ x_{ij} &amp;\\sim U(-5, 6) \\end{align*}\\] El vector de par√°metros de este modelo es \\(\\boldsymbol{\\Theta}=(\\beta_0=4, \\beta_1=-6, \\sigma_y=4, \\sigma_{bo}=25)^\\top\\). Soluci√≥n El c√≥digo para simular las 500 observaciones se muestra a continuaci√≥n. Observe que se fij√≥ la semilla en dos ocasiones para que el lector pueda replicar el ejemplo y obtener los mismos resultados. ni &lt;- 50 G &lt;- 10 nobs &lt;- ni * G grupo &lt;- factor(rep(x=1:G, each=ni)) obs &lt;- rep(x=1:ni, times=G) set.seed(1234567) x &lt;- runif(n=nobs, min=-5, max=6) b0 &lt;- rnorm(n=G, mean=0, sd=sqrt(625)) # Intercepto aleatorio b0 &lt;- rep(x=b0, each=ni) # El mismo intercepto aleatorio pero repetido media &lt;- 4 - 6 * x + b0 set.seed(123456) y &lt;- rnorm(n=nobs, mean=media, sd=sqrt(16)) datos &lt;- data.frame(grupo, obs, b0, x, media, y) El siguiente paso es dibujar los datos para explorar si ser√≠a apropiado usar un modelo con intercepto aleatorio (obvio porque as√≠ se simularon los datos). El c√≥digo para dibujar los datos se muestra abajo. library(ggplot2) ggplot(datos, aes(x, y, color=grupo) ) + geom_point() + labs(colour=&quot;Grupo/Cluster&quot;) En la figura anterior se observa un patr√≥n claro, todas las 10 nubes de puntos tienen la misma pendiente pero diferente intercepto con el eje vertical, eso se debe a que en la simulaci√≥n se incluy√≥ un \\(b_0\\). Para estimar los par√°metros del modelos se usa la funci√≥n mler de la siguiente forma. library(lme4) fit &lt;- lmer(y ~ x + (1 | grupo), data=datos) La funci√≥n summary se puede usar sobre el objeto fit para obtener una tabla de resumen, a continuaci√≥n se ilustra el uso y la salida de summary. summary(fit) Seg√∫n el resultado anterior \\(\\hat{\\boldsymbol{\\Theta}}=(\\hat{\\beta}_0=3.53363, \\hat{\\beta}_1=-5.97805, \\hat{\\sigma}_y=4.012, \\hat{\\sigma}_{bo}=21.507)^\\top\\) mientras que el vector real de par√°metros es \\(\\boldsymbol{\\Theta}=(\\beta_0=4, \\beta_1=-6, \\sigma_y=4, \\sigma_{bo}=25)^\\top\\). Compare los resultados de la tabla anterior obtenida con la funci√≥n lmer anterior con los resultados obtenidos con la funci√≥n lme de cap√≠tulo 4. ¬øHay alguna similitud? References "],
["pac-nlme.html", "4 Paquete nlme 4.1 Funci√≥n lme Ejemplo: modelo con intercepto aleatorio", " 4 Paquete nlme El paquete nlme (Pinheiro, Bates, and R-core 2019) es otro de los paquetes para modelos mixtos. Al visitar este enlace se encontrar√° la p√°gina de apoyo del paquete, all√≠ se puede consultar el manual de referencia. 4.1 Funci√≥n lme La funci√≥n lme es la principal funci√≥n del paquete (Pinheiro, Bates, and R-core 2019). Esta funci√≥n sirve para ajustar un modelo mixto y su estructura es la siguiente: lme(fixed, data, random, correlation, weights, subset, method, na.action, control, contrasts = NULL, keep.data = TRUE) Los principales argumentos de la funci√≥n son: formula: es una f√≥rmula similar a la usada en el modelo lineal cl√°sico. Un ejemplo de f√≥rmula ser√≠a y ~ 1 + x1 + x2 con la cual se indican los efectos fijos del modelo. data: marco de datos donde est√°n las variables. random: es una f√≥rmula solo con lado derecho. Si queremos indicar intercepto aleatorio se escribe ~ 1 | group y si se desea intercepto y pendiente aleatoria se escribe ~ 1 + x2 | group. correlation: es un par√°metro opcional para indicar la estructura de correlaci√≥n entre las observaciones de cada grupo. Para m√°s detalles consulte la ayuda de la funci√≥n corClasses. method: valor l√≥gico que sirve para indicar si queremos estimaciones maximizando la verosimilitud restringida o la verosimilitud usual, las dos opciones son ML o REML. Ejemplo: modelo con intercepto aleatorio En este ejemplo vamos a simular observaciones \\(ni=50\\) observaciones para \\(G=10\\) grupos (en total 500 obs) que tengan la estructura mostrada abajo. El objetivo del ejemplo es ilustrar el uso de la funci√≥n lmer para estimar los par√°metros del modelo. \\[\\begin{align*} y_{ij} &amp;\\sim N(\\mu_{ij}, \\sigma^2_y) \\\\ \\mu_{ij} &amp;= 4 - 6 x_{ij} + b_{0i} \\\\ \\sigma^2_y &amp;= 16 \\\\ b_{0} &amp;\\sim N(0, \\sigma^2_{b0}=625) \\\\ x_{ij} &amp;\\sim U(-5, 6) \\end{align*}\\] El vector de par√°metros de este modelo es \\(\\boldsymbol{\\Theta}=(\\beta_0=4, \\beta_1=-6, \\sigma_y=4, \\sigma_{b0}=25)^\\top\\). Soluci√≥n El c√≥digo para simular las 500 observaciones se muestra a continuaci√≥n. Observe que se fij√≥ la semilla en dos ocasiones para que el lector pueda replicar el ejemplo y obtener los mismos resultados. ni &lt;- 50 G &lt;- 10 nobs &lt;- ni * G grupo &lt;- factor(rep(x=1:G, each=ni)) obs &lt;- rep(x=1:ni, times=G) set.seed(1234567) x &lt;- runif(n=nobs, min=-5, max=6) b0 &lt;- rnorm(n=G, mean=0, sd=sqrt(625)) # Intercepto aleatorio b0 &lt;- rep(x=b0, each=ni) # El mismo intercepto aleatorio pero repetido media &lt;- 4 - 6 * x + b0 set.seed(123456) y &lt;- rnorm(n=nobs, mean=media, sd=sqrt(16)) datos &lt;- data.frame(grupo, obs, b0, x, media, y) El siguiente paso es dibujar los datos para explorar si ser√≠a apropiado usar un modelo con intercepto aleatorio (obvio porque as√≠ se simularon los datos). El c√≥digo para dibujar los datos se muestra abajo. library(ggplot2) ggplot(datos, aes(x, y, color=grupo) ) + geom_point() + labs(colour=&quot;Grupo/Cluster&quot;) En la figura anterior se observa un patr√≥n claro, todas las 10 nubes de puntos tienen la misma pendiente pero diferente intercepto con el eje vertical, eso se debe a que en la simulaci√≥n se incluy√≥ un \\(b_0\\). Para estimar los par√°metros del modelos se usa la funci√≥n mler de la siguiente forma. library(nlme) fit &lt;- lme(y ~ x, random = ~ 1 | grupo, data=datos) La funci√≥n summary se puede usar sobre el objeto fit para obtener una tabla de resumen, a continuaci√≥n se ilustra el uso y la salida de summary. summary(fit) Seg√∫n el resultado anterior \\(\\hat{\\boldsymbol{\\Theta}}=(\\hat{\\beta}_0=3.533631, \\hat{\\beta}_1=-5.978053, \\hat{\\sigma}_y=4.01157, \\hat{\\sigma}_{b0}=21.50711)^\\top\\) mientras que el vector real de par√°metros es \\(\\boldsymbol{\\Theta}=(\\beta_0=4, \\beta_1=-6, \\sigma_y=4, \\sigma_{b0}=25)^\\top\\). Compare los resultados de la tabla anterior obtenida con la funci√≥n lme anterior con los resultados obtenidos con la funci√≥n lmer de cap√≠tulo 3. ¬øHay alguna similitud? References "],
["ph.html", "5 Pruebas de hip√≥tesis 5.1 Prueba raz√≥n de verosimilitud 5.2 Prueba de Wald 5.3 Prueba de hip√≥tesis sobre los efectos fijos 5.4 Prueba de hip√≥tesis sobre componentes de varianza Ejercicios", " 5 Pruebas de hip√≥tesis En este cap√≠tulo se muestran las pruebas de hip√≥tesis para comparar modelo mixtos. 5.1 Prueba raz√≥n de verosimilitud Supongamos que queremos estudiar \\(H_0: \\theta \\in \\boldsymbol{\\Theta}_0\\) versus \\(H_A: \\theta \\in \\boldsymbol{\\Theta}\\). La prueba raz√≥n de verosimilitud (\\(LR\\)) para \\(H_0\\) est√° dada por: \\[ LR = -2 \\log \\left( \\frac{ sup_{\\theta \\in \\boldsymbol{\\Theta}_0} L(\\theta)}{ sup_{\\theta \\in \\boldsymbol{\\Theta}} L(\\theta)} \\right) \\] Usualmente la prueba de raz√≥n de verosimilitud se expresa en funci√≥n de los valores de log-verosimilitud del modelo asi: \\[ LR = -2 ( l(\\Theta_0) - l(\\hat{\\Theta}) ) \\] y el estad√≠stico \\(LR \\sim \\chi^2_{k-k_0}\\), donde \\(k\\) es el n√∫mero de par√°metros del modelo estimado y \\(k_0\\) el n√∫mero de par√°metros del modelo asumiendo \\(H_0\\) verdadera. 5.2 Prueba de Wald Si el inter√©s es estudiar \\(H_0: \\beta_k = \\beta_{k0}\\) contra \\(H_A: \\beta_k \\neq \\beta_{k0}\\) se puede usar la prueba de Wald que tiene el siguiente estad√≠stico: \\[ t = \\frac{\\hat{\\beta}_k - \\beta_{k0}}{se(\\hat{\\beta}_k)}, \\] donde \\(se(\\hat{\\beta}_k)\\) corresponde al error est√°ndar de la estimaci√≥n \\(\\hat{\\beta}_k\\), todo esto disponible en el summary del modelo ajustado. Si \\(H_0\\) es verdadera, \\(t \\sim t_{n-p}\\), siendo \\(n\\) el n√∫mero de observaciones y \\(p\\) el n√∫mero de efectos fijos estimados (no el n√∫mero de variables) en el modelo. 5.3 Prueba de hip√≥tesis sobre los efectos fijos La prueba raz√≥n de verosimilitud puede ser usada para comparar modelos ajustados por el m√©todo ML y que difieran en su estructura de efectos fijos, pero con la mismas componentes de varianza. Los valores-P de la prueba pueden ser anticonservativos, es decir, m√°s peque√±os de lo normal y por lo tanto se podr√≠a rechazar \\(H_0\\) m√°s f√°cilmente (Pinheiro and Bates 2000). En lugar de usar la distribuci√≥n \\(\\chi^2\\) para el estad√≠stico de la prueba raz√≥n de verosimilitud, se recomienda usar la distribuci√≥n emp√≠rica del estad√≠stico, obtenida al ajustar los modelos nulo y alternativo con m√∫ltiples conjuntos de datos simulados (Galecki and Burzykowski 2012). Ejemplo La base de datos ChickWeight contiene informaci√≥n sobre el peso de un grupo de pollos versus el tiempo bajo diferentes dietas. Abajo una ilustraci√≥n de los datos. library(ggplot2) ggplot(data = ChickWeight, aes(x = Time, y = weight, color = Diet)) + geom_point() + theme_bw() + facet_wrap(~ Chick) El objetivo es comparar los siguientes dos modelos. Modelo 1 \\[\\begin{align*} Weight_{ij} &amp;\\sim N(\\mu_{ij}, \\sigma^2_{weight}) \\\\ \\mu_{ij} &amp;= \\beta_0 + \\beta_1 tiempo_{ij} + b_{0i} \\\\ b_{0} &amp;\\sim N(0, \\sigma^2_{b0}) \\end{align*}\\] Modelo 2 \\[\\begin{align*} Weight_{ij} &amp;\\sim N(\\mu_{ij}, \\sigma^2_{weight}) \\\\ \\mu_{ij} &amp;= \\beta_0 + \\beta_1 tiempo_{ij} + \\beta_2 dieta2_{i} + \\beta_3 dieta3_{i} + \\beta_4 dieta4_{i} + b_{0i} \\\\ b_{0} &amp;\\sim N(0, \\sigma^2_{b0}) \\end{align*}\\] Soluci√≥n El problema de este ejercicio se puede resumir con \\(H_0:\\) la variable Dieta no aporta al modelo, versus, \\(H_A:\\) la variable Dieta si aporta al modelo. Para ajustar ambos modelos se usa el siguiente c√≥digo. library(nlme) mod1 &lt;- lme(weight ~ Time, data = ChickWeight, random = ~ 1 | Chick, method=&#39;ML&#39;) mod2 &lt;- lme(weight ~ Time + Diet, data = ChickWeight, random = ~ 1 | Chick, method=&#39;ML&#39;) Para calcular la prueba raz√≥n de verosimilitud se usa el siguiente c√≥digo. lrt &lt;- -2 * (logLik(mod1) - logLik(mod2)) lrt ## &#39;log Lik.&#39; 17.14349 (df=4) pchisq(q=lrt, df=7-4, lower.tail=FALSE) ## &#39;log Lik.&#39; 0.000660304 (df=4) De la salida anterior se tiene que el valor-P = 0.000660304 y menor que cualquier \\(\\alpha\\). Sin embargo, como este valor-P puede ser ‚Äúanticonservativo‚Äù (m√°s peque√±o de lo que deber√≠a ser), es mejor no sacar conclusiones apresuradas y rechazar \\(H_0\\). La prueba de verosimilitud se puede obtener tambi√©n as√≠: anova(mod1, mod2) ## Model df AIC BIC logLik Test L.Ratio p-value ## mod1 1 4 5630.344 5647.782 -2811.172 ## mod2 2 7 5619.201 5649.718 -2802.600 1 vs 2 17.14349 7e-04 Para obtener un valor-P m√°s acorde al problema podemos usar simulaci√≥n. La funci√≥n simulate.lme simula datos de modelos especificados por medio de los argumentos object y m2, ajusta los modelos, y entrega los valores de log-verosimilitud, con los se puede obtener el estad√≠stico de la prueba de raz√≥n de verosimilitud. A continuaci√≥n el c√≥digo para obtener el valor-P con simulaci√≥n. simul &lt;- simulate.lme(object=mod1, m2=mod2, method = &#39;ML&#39;, nsim=1000) lrts_nlme &lt;- -2 * (simul$null$ML[, 2] - simul$alt$ML[, 2]) acumulada1 &lt;- ecdf(x=lrts_nlme) # F(x) para los valores LRT 1 - acumulada1(17.14349) ## [1] 0.001 De la salida anterior se tiene que el valor-P = 0.001 y ya no es tan peque√±o como el valor-P anterior. Por esta raz√≥n hay evidencias rechazar \\(H_0\\) y por lo tanto la variable Dieta si aporta al modelo. Ejemplo La base de datos Orthodont contiene informaci√≥n sobre una medida de distancia intrafacial para j√≥venes sometidos a ortodoncia. data(Orthodont, package=&quot;nlme&quot;) library(ggplot2) ggplot(data = Orthodont, aes(x = age, y = distance, color = Sex)) + geom_point() + theme_bw() + facet_wrap(~ Subject) El objetivo es comparar los siguientes dos modelos. Modelo 1 \\[\\begin{align*} Distance_{ij} &amp;\\sim N(\\mu_{ij}, \\sigma^2_{distance}) \\\\ \\mu_{ij} &amp;= \\beta_0 + \\beta_1 age_{ij} + b_{0i} \\\\ b_{0} &amp;\\sim N(0, \\sigma^2_{b0}) \\end{align*}\\] Modelo 2 \\[\\begin{align*} Distance_{ij} &amp;\\sim N(\\mu_{ij}, \\sigma^2_{distance}) \\\\ \\mu_{ij} &amp;= \\beta_0 + \\beta_1 age_{ij} + \\beta_2 SexFemale_i + b_{0i} \\\\ b_{0} &amp;\\sim N(0, \\sigma^2_{b0}) \\end{align*}\\] Soluci√≥n El problema de este ejercicio se puede resumir con \\(H_0:\\) la variable Sexo no aporta al modelo, versus, \\(H_A:\\) la variable Sexo si aporta al modelo. Para ajustar ambos modelos se usa el siguiente c√≥digo. library(lme4) mod1 &lt;- lmer(distance ~ age + (1|Subject), data=Orthodont, REML=FALSE) mod2 &lt;- lmer(distance ~ age + Sex + (1|Subject), data=Orthodont, REML=FALSE) Para calcular la prueba raz√≥n de verosimilitud se usa el siguiente c√≥digo. lrt &lt;- -2 * (logLik(mod1) - logLik(mod2)) lrt ## &#39;log Lik.&#39; 8.533057 (df=4) pchisq(q=lrt, df=5-4, lower.tail=FALSE) ## &#39;log Lik.&#39; 0.003487534 (df=4) De la salida anterior se tiene que el valor-P = 0.003487534 y menor que cualquier \\(\\alpha\\). Sin embargo, como este valor-P puede ser ‚Äúanticonservativo‚Äù (m√°s peque√±o de lo que deber√≠a ser), es mejor no sacar conclusiones apresuradas y rechazar \\(H_0\\). La prueba de verosimilitud se puede obtener tambi√©n as√≠: anova(mod1, mod2) ## Data: Orthodont ## Models: ## mod1: distance ~ age + (1 | Subject) ## mod2: distance ~ age + Sex + (1 | Subject) ## Df AIC BIC logLik deviance Chisq Chi Df Pr(&gt;Chisq) ## mod1 4 451.39 462.12 -221.69 443.39 ## mod2 5 444.86 458.27 -217.43 434.86 8.5331 1 0.003488 ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Para obtener un valor-P m√°s acorde al problema podemos usar simulaci√≥n. La funci√≥n simulate.lme simula respuestas \\(y_{ij}\\) del modelo dado. A continuaci√≥n el c√≥digo para obtener el valor-P con simulaci√≥n (¬°tarda varios minutos!). nrep &lt;- 5000 lrts_lme4 &lt;- numeric(nrep) for (i in 1:nrep) { new_y_h0 &lt;- simulate(mod1) # Asumiendo H0 verdadera Orthodont$new_y_h0 &lt;- new_y_h0$sim_1 aux0 &lt;- lmer(new_y_h0 ~ age + (1|Subject), data=Orthodont, REML=FALSE) aux1 &lt;- lmer(new_y_h0 ~ age + Sex + (1|Subject), data=Orthodont, REML=FALSE) lrts_lme4[i] &lt;- -2 * (logLik(aux0) - logLik(aux1)) } acumulada2 &lt;- ecdf(x=lrts_lme4) # F(x) para los valores LRT 1 - acumulada1(8.533057) ## [1] 0.005 De la salida anterior se tiene que el valor-P = 0.005 y ya no es tan peque√±o como el valor-P anterior. Por esta raz√≥n hay evidencias rechazar \\(H_0\\) y por lo tanto la variable Sexo si aporta al modelo. 5.4 Prueba de hip√≥tesis sobre componentes de varianza Las componentes de varianza corresponden a las varianzas y covarianzas del vector de efectos aleatorios. La prueba raz√≥n de verosimilitud puede ser usada para comparar modelos ajustados por el m√©todo REML y que difieran en sus componentes de varianza, pero que tenga igual estructura de efectos fijos. Para hacer pruebas de hip√≥tesis sobre las componentes de varianza se tienen dos casos que se explican en las siguientes subsecciones. 5.4.1 Componentes de varianza lejos del borde Luego un ejemplo. 5.4.2 Componentes de varianza en el borde Este caso se presenta cuando la hip√≥tesis nula considera que uno o varios par√°metros est√°n justo en el borde del dominio del par√°metro en cuestion. Por ejemplo, si queremos estudiar la inclusi√≥n del intercepto aleatorio \\(b_0\\) en un modelo de regresi√≥n cl√°sico, tendr√≠amos las siguientes hip√≥tesis: \\(H_0: \\sigma^2_{b0} = 0\\) versus \\(H_A: \\sigma^2_{b0} &gt; 0\\). Debido a la condici√≥n de \\(\\sigma^2_{b0}\\) en \\(H_0\\), se dice que esa componente de varianza est√° en el borde de su dominio, ya que \\(\\sigma^2_{b0}\\) no puede ser negativa. En este ejemplo particular, rechazar \\(H_0\\) implicar√≠a que es apropiado incluir \\(b_0\\) en el modelo. En el caso de componentes de varianza cerca de la frontera la distribuci√≥n del estad√≠stico raz√≥n de verosimilitud no es una \\(\\chi^2\\) (Galecki and Burzykowski 2012). En la secci√≥n 6.3.4 de (Verbeke and Molenberghs 2000) se listan 4 casos en los cuales se tienen mezclas de distribuciones para calcular el valor-P de la prueba raz√≥n de verosimilitud. Los 4 casos son los siguientes: Sin efecto aleatorio versus 1 efecto aleatorio: en este caso lo que interesa es \\(H_0: \\sigma^2_{b} = 0\\) versus \\(H_A: \\sigma^2_{b} &gt; 0\\), la distribuci√≥n asint√≥tica del estad√≠stico de razon de verosimilitud es una mezcla de \\(\\chi^2_1\\) y \\(\\chi^2_0\\) con pesos iguales a 0.5. 1 efecto aleatorio versus 2 efectos aleatorios: en este caso lo que interesa es \\(H_0: \\boldsymbol{D} = \\begin{pmatrix} d_{11} &amp; 0 \\\\ 0 &amp; 0 \\end{pmatrix}\\) versus \\(H_A: \\boldsymbol{D} \\neq \\boldsymbol{0}\\) para un \\(d_{11}&gt;0\\), en este caso la distribuci√≥n asint√≥tica del estad√≠stico raz√≥n de verosimilitud es una mezcla de \\(\\chi^2_2\\) y \\(\\chi^2_1\\) con pesos iguales a 0.5. \\(q\\) efectos aleatorios versus \\(q+1\\) efectos aleatorios: en este caso lo que interesa es \\(H_0: \\boldsymbol{D} = \\begin{pmatrix} \\boldsymbol{D_{11}} &amp; \\boldsymbol{0}\\\\ \\boldsymbol{0}^\\top &amp; 0 \\end{pmatrix}\\) donde \\(\\boldsymbol{D_{11}}\\) es una matriz de covarianzas (positiva definida) de dimensi√≥n \\(q \\times q\\) versus que \\(\\boldsymbol{D}\\) es una matriz general de dimensi√≥n \\(q+1 \\times q+1\\). En este caso la distribuci√≥n asint√≥tica del estad√≠stica raz√≥n de verosimilitud es una mezcla de \\(\\chi^2_{q+1}\\) y \\(\\chi^2_q\\) con pesos iguales a 0.5. \\(q\\) efectos aleatorios versus \\(q+k\\) efectos aleatorios: en este caso lo que interesa es \\(H_0: \\boldsymbol{D} = \\begin{pmatrix} \\boldsymbol{D_{11}} &amp; \\boldsymbol{0}\\\\ \\boldsymbol{0}^\\top &amp; \\boldsymbol{0} \\end{pmatrix}\\) donde \\(\\boldsymbol{D}\\) es una matriz de covarianzas (positiva definida) de dimensi√≥n \\(q+k \\times q+k\\) versus que \\(H_A: \\boldsymbol{D} = \\begin{pmatrix} \\boldsymbol{D_{11}} &amp; \\boldsymbol{D_{12}}\\\\ \\boldsymbol{D_{12}}^\\top &amp; \\boldsymbol{D_{22}} \\end{pmatrix}\\) es una matriz general de dimensi√≥n \\(q+k \\times q+k\\). En este caso la distribuci√≥n asint√≥tica del estad√≠stica raz√≥n de verosimilitud es una mezcla de \\(\\chi^2_{q+k}\\) y \\(\\chi^2_q\\) con pesos iguales a 0.5. Si la distribuci√≥n nula del estad√≠stico raz√≥n de verosimilitud no puede ser obtenida anal√≠ticamente, una posible soluci√≥n es usar la distribuci√≥n emp√≠rica del estad√≠stico obtenida al ajustar m√∫ltiples modelos nulos y alternativos (Galecki and Burzykowski 2012). Ejemplo Simule 10 observaciones para cada uno de los 10 grupos siguiendo el siguiente modelo y luego aplique la prueba de raz√≥n de verosimilitud para estudiar \\(H_0: \\sigma^2_{b0} = 0\\) versus \\(H_A: \\sigma^2_{b0} &gt; 0\\). \\[\\begin{align*} y_{ij} &amp;\\sim N(\\mu_{ij}, \\sigma^2_y) \\\\ \\mu_{ij} &amp;= 4 - 6 x_{ij} + b_{0i} \\\\ \\sigma^2_y &amp;= 4 \\\\ b_{0} &amp;\\sim N(0, \\sigma^2_{b0}=4) \\\\ x_{ij} &amp;\\sim U(0, 10) \\end{align*}\\] Soluci√≥n La funci√≥n gen_dat_b0 de abajo permite simular m observaciones de n grupos con intercepto aleatorio \\(b_0 \\sim N(0, \\sigma^2_{b0})\\). Adicionalmente, es posible elegir los efectos fijos beta0, beta_1 y la varianza sigma de la variable respuesta. gen_dat_b0 &lt;- function(n, m, beta0, beta1, sigmay, sigmab0, seed=NULL) { if(is.null(seed)) seed &lt;- as.integer(runif(1)*2e9) group &lt;- rep(1:n, each=m) set.seed(seed) b0 &lt;- rep(rnorm(n=n, mean=0, sd=sigmab0), each=m) set.seed(seed) x &lt;- runif(n=n*m, min=0, max=10) set.seed(seed) y &lt;- rnorm(n=n*m, mean=beta0 + beta1 * x + b0, sd=sigmay) data.frame(group=group, x=x, y=y) } Vamos ahora a generar 10 observaciones para 10 grupos con intercepto aleatorio con una varianza \\(\\sigma^2_{b0}=2^2=4\\). La semilla se va a fijar en un valor de 1220872376 por cuestiones did√°cticas. datos &lt;- gen_dat_b0(n=10, m=10, beta0=4, beta1=-6, sigmay=2, sigmab0=2, seed=1220872376) head(datos) ## group x y ## 1 1 3.817132 -20.106729 ## 2 1 8.951117 -49.950457 ## 3 1 5.710726 -33.154170 ## 4 1 7.451320 -39.583303 ## 5 1 1.263282 -1.070788 ## 6 1 6.114367 -33.423587 Vamos a ajustar dos modelos, el primero sin incluir \\(b_0\\) y el segundo incluyendo \\(b_0\\). library(nlme) fit1 &lt;- gls(y ~ x, data=datos, method=&quot;REML&quot;) # Igual resultado con lm fit2 &lt;- lme(y ~ x, random = ~ 1| group, data=datos, method=&quot;REML&quot;) Resultados del primer modelo. summary(fit1) ## Generalized least squares fit by REML ## Model: y ~ x ## Data: datos ## AIC BIC logLik ## 475.8248 483.5797 -234.9124 ## ## Coefficients: ## Value Std.Error t-value p-value ## (Intercept) 4.64931 0.5180190 8.97517 0 ## x -6.00175 0.0814173 -73.71588 0 ## ## Correlation: ## (Intr) ## x -0.875 ## ## Standardized residuals: ## Min Q1 Med Q3 Max ## -2.14346496 -0.64999607 -0.06461389 0.60660976 3.48238119 ## ## Residual standard error: 2.50842 ## Degrees of freedom: 100 total; 98 residual Resultados del segundo modelo. summary(fit2) ## Linear mixed-effects model fit by REML ## Data: datos ## AIC BIC logLik ## 474.7777 485.1175 -233.3888 ## ## Random effects: ## Formula: ~1 | group ## (Intercept) Residual ## StdDev: 0.8166724 2.383898 ## ## Fixed effects: y ~ x ## Value Std.Error DF t-value p-value ## (Intercept) 4.640053 0.5652943 89 8.20821 0 ## x -6.000087 0.0795348 89 -75.43973 0 ## Correlation: ## (Intr) ## x -0.783 ## ## Standardized Within-Group Residuals: ## Min Q1 Med Q3 Max ## -2.19536246 -0.56396957 0.05433633 0.61634184 3.29594400 ## ## Number of Observations: 100 ## Number of Groups: 10 Ahora vamos a calcular el estad√≠stico y su valor-P. lrt &lt;- -2 * (logLik(fit1) - logLik(fit2)) lrt ## &#39;log Lik.&#39; 3.04712 (df=3) my_p.value &lt;- pchisq(q=3.04712, df=1, lower.tail=FALSE) my_p.value ## [1] 0.08088045 De la salida anterior se tiene que \\(valor-P = 0.0809\\) y como \\(\\alpha=0.05\\), por lo tanto NO hay evidencias para rechazar \\(H_0: \\sigma^2_{b0} = 0\\). ¬øNo es extra√±a esta conclusi√≥n ü§î? Los resultados anteriores se pueden obtener por medio de la funci√≥n anova as√≠. anova(fit1, fit2) ## Model df AIC BIC logLik Test L.Ratio p-value ## fit1 1 3 475.8248 483.5797 -234.9124 ## fit2 2 4 474.7777 485.1175 -233.3888 1 vs 2 3.04712 0.0809 Ahora vamos a simular 50 conjuntos de datos suponiendo \\(H_0\\) verdadera y luego calcularemos los lrt para as√≠ tener la distribuci√≥n emp√≠rica de los lrt bajo la hip√≥tesis nula \\(H_0: \\sigma^2_{b0} = 0\\) verdadera. En un aplicaci√≥n se deber√≠an generar m√°s conjuntos de pero aqu√≠ vamos a usar s√≥lo 50 por comodidad. pseudo_gen_dat &lt;- function(nobs, beta0, beta1, sigmay) { group &lt;- datos$group # Aqui la diferencia x &lt;- datos$x # Aqui la diferencia y &lt;- rnorm(n=nobs, mean=beta0 + beta1 * x, sd=sigmay) data.frame(group=group, x=x, y=y) } nrep &lt;- 50 lrts &lt;- numeric(nrep) for (i in 1:nrep) { pseudo_datos &lt;- pseudo_gen_dat(nobs=100, beta0=4.64931, beta1=-6.00175, sigma=2.50842) m1 &lt;- gls(y ~ x, data=pseudo_datos, method=&quot;REML&quot;) m2 &lt;- lme(y ~ x, random = ~ 1| group, data=pseudo_datos, method=&quot;REML&quot;) lrts[i] &lt;- -2 * (logLik(m1) - logLik(m2)) } Dibujando la densidad de los lrt. plot(density(lrts), main=&#39;Densidad emp√≠rica de los lrts&#39;) Calculando el valor-P. acumulada &lt;- ecdf(x=lrts) # F(x) para los valores LRT 1 - acumulada(3.04712) # Valor-P ## [1] 0.04 De la salida anterior se tiene que \\(valor-P &lt; \\alpha\\) por lo tanto SI hay evidencias para rechazar \\(H_0: \\sigma^2_{b0} = 0\\). ¬øEs esto coherente ahora üôÇ? Los resultados anteriores se obtuvieron usando nrep &lt;- 50, en la pr√°ctica ese n√∫mero de repeticiones deber√≠a subir al menos a 1000. Repita el procedimiento anterior con nrep &lt;- 5000 y observe lo que sucede. El paquete RLRsim (Scheipl and Bolker 2016) tiene la funci√≥n exactRLRT que permite extraer el valor-P mediante simulaci√≥n. Abajo un ejemplo de como usarla en el presente ejemplo. library(RLRsim) exactRLRT(m=fit2, nsim=1000) ## Warning in model.matrix.default(~m$groups[[n.levels - i + 1]] - 1, ## contrasts.arg = c(&quot;contr.treatment&quot;, : non-list contrasts argument ignored ## ## simulated finite sample distribution of RLRT. ## ## (p-value based on 1000 simulated values) ## ## data: ## RLRT = 3.0471, p-value = 0.039 Consulte la ayuda de la funci√≥n exactRLRT para que conozca sus posibilidades y limitaciones. Ejercicios ¬øQu√© son modelos anidados? ¬øSon modelos que usan datos relacionados con aves? Considere la base de datos sleepstudy del paquete lme4. El objetivo es comparar los siguientes dos modelos. Modelo 1 \\[\\begin{align*} Reaction_{ij} &amp;\\sim N(\\mu_{ij}, \\sigma^2_{reaction}) \\\\ \\mu_{ij} &amp;= \\beta_0 + \\beta_1 days_{ij} + b_{0i} + b_{1i} days_{ij} \\\\ (b_0, b_1)^\\top &amp;\\sim N(\\boldsymbol{0}, \\boldsymbol{D}) \\end{align*}\\] Modelo 2 \\[\\begin{align*} Reaction_{ij} &amp;\\sim N(\\mu_{ij}, \\sigma^2_{reaction}) \\\\ \\mu_{ij} &amp;= \\beta_0 + \\beta_1 days_{ij} + \\beta_2 days_{ij}^2 + b_{0i} + b_{1i} days_{ij} \\\\ (b_0, b_1)^\\top &amp;\\sim N(\\boldsymbol{0}, \\boldsymbol{D}) \\end{align*}\\] Escriba las hip√≥tesis del problema en forma simb√≥lica y en lenguaje sencillo. Aplique la prueba raz√≥n de verosimilitud usando simulaci√≥n y concluya. Rta: el valor-P \\(\\approx\\) 0.136. Considere el ejemplo del cap√≠tulo 7 sobre el estudio de crecimiento de un grupo de j√≥venes. Aplique la prueba raz√≥n de verosimilitud para estudiar \\(H_0: \\sigma^2_{b0} = 0\\) versus \\(H_A: \\sigma^2_{b0} &gt; 0\\), es decir, ajuste un modelo lineal simple para explicar la estatura en funci√≥n de la edad y luego un modelo mixto con intercepto aleatorio. ¬øCu√°l de los dos modelos parece explicar mejor los datos? Use \\(\\alpha=0.06\\). En este enlace est√° la pregunta de un usuario de StackExange sobre prueba de hip√≥tesis (PH). ¬øFue la pregunta sobre PH sobre efectos fijos o PH sobre componentes de varianza? ¬øQuer√≠a el usuario un PH asint√≥tica o una PH basada en bootstrap (relacionado con simulaci√≥n)? Mire el ejemplo que di√≥ YaronZ, ¬øpor qu√© no defini√≥ el m√©todo REML dentro de las funciones lmer y lm? En este enlace est√° la extensa pregunta del usuario Patrick. En el primer caj√≥n de c√≥digo Patrick escribi√≥ un c√≥digo para simular observaciones de un modelo mixto. ¬øC√≥mo le parece esa forma de simular? ¬øCu√°ntos elementos tiene el vector de par√°metros del modelo de Patrick? ¬øCu√°les son los valores de los par√°metros? En este enlace est√° la pregunta del usuario biostat_newbie. ¬øQu√© nombre recibe el modelo que le interesa a biostat_newbie? ¬øQu√© es lo que necesita 0.7494974? ¬øCu√°l es el mensaje de primer p√°rrafo de que respondi√≥ Fabians? En la respuesta que Fabians di√≥ hay un c√≥digo de R. ¬øPara qu√© sirve ese c√≥digo tan extra√±o? ¬øQui√©n es Ben Bolker? ¬øEn cu√°les paquetes de R ha participado Ben Bolker? En este enlace est√° la pregunta del usuario user9171. ¬øCu√°l es el error que comete user9171 al usar el siguiente c√≥digo? &gt; anova(fit.fe, fit.me) Error: $ operator not defined for this S4 class ¬øQu√© le respondi√≥ Karl Ove Hufthammer? Karl le agrega en su respuesta ‚ÄúAnd really the choice of whether to include the random effects should be based on theory (e.g., the sampling plan), not on a statistical test‚Äù. ¬øQu√© quiere decir eso? Ben Bolker escribi√≥ unas notas sobre pruebas de hip√≥tesis, revise este enlace para consultarlas. En el ejemplo de Ben Bolker hay tres modelos: m2, m1 y m0. ¬øCu√°l es el ‚Äúfull model‚Äù y cu√°l es el ‚Äúreduced model‚Äù? ¬øPara qu√© sirve la funci√≥n update? ¬øUsted la ha usado alguna vez? ¬øNo? Pues √∫sela de aqu√≠ en adelante. Ben escribe ‚Äúwhich has a fast implementation of simulation-based tests of null hypotheses about zero variances, for simple tests.‚Äù ¬øA qu√© paquete se refiere con esa frase? References "],
["reg-diagnos.html", "6 Diagn√≥stico del modelo de regresi√≥n de efectos mixtos 6.1 Los residuos 6.2 El m√©todo gr√°fico", " 6 Diagn√≥stico del modelo de regresi√≥n de efectos mixtos El diagn√≥stico del modelo de regresi√≥n es un m√©todo que permite determinar si un modelo de regresi√≥n ajustado representa adecuadamente los datos. Dicho diagn√≥stico puede ser de dos tipos: mediante m√©todos gr√°ficos o m√©todos puramente num√©ricos (pruebas de hip√≥tesis). No obstante el diagn√≥stico gr√°fico permite al analista descubrir no solo cu√°ndo el modelo ajustado presenta problemas, sino que tambi√©n permite detectar cu√°l puede ser la causa del mismo, lo cual ser√≠a casi imposible a trav√©s de los m√©todos num√©ricos. El objetivo de este capitulo consiste en introducir al lector los distintos m√©todos de diagnostico del modelo, los cuales permitiran identificar aquel modelo que represente sus datos con una mayor precisi√≥n. 6.1 Los residuos Los residuos son la base de la mayor√≠a de los m√©todos de diagn√≥stico. Estos pueden ser de distinto tipo. El residuo m√°s b√°sico es el denominado residuo original, \\(\\hat{\\epsilon}_{i}\\), el cual se define como la diferencia entre el valor observado, \\(y_{i}\\), y su correspondiente valor estimado por el modelo, \\(\\hat{\\mu}_{i}\\), as√≠: \\[\\begin{align*} \\hat{\\epsilon}_{i} = y_{i} - \\hat{\\mu}_{i}, i = 1, 2, ..., n \\end{align*}\\] donde \\(\\hat{\\mu}_{i}\\) es igual a \\(x^{&#39;}_{i}\\hat{\\beta}\\). A continuaci√≥n, una representaci√≥n gr√°fica de \\(\\hat{\\epsilon}_{i}\\): Luego los residuos originales se escalan con el fin de que su interpretaci√≥n no dependa de las unidades de medida de la variable dependiente. El proceso de estandarizaci√≥n consiste en dividir al residuo original, \\(\\hat{\\epsilon}_{i}\\), su desviaci√≥n estandar, \\({\\sigma}\\), as√≠: \\(\\frac{\\hat{\\epsilon}_{i}}{\\sigma}\\). Los residuos obtenidos de esta manera se denominan como residuos estandarizados. Sin embargo la verdadera desviaci√≥n est√°ndar rara vez se conoce. Por lo tanto, el escalado se realiza utilizando un estimador del mismo, \\(\\hat{\\sigma}\\), y dependiendo del estimador utilizado se distinguen otros dos tipos de residuos: los residuos internamente estudentizados y los residuos externamente estudentizados. La tabla a continuaci√≥n, resume las formas b√°sicas de los residuos escalados: Formula matem√°tica Estandarizado por \\(\\sigma\\) \\(\\frac{\\hat\\epsilon_i}{\\sigma}\\) Internamente estudentizado \\(\\frac{\\hat\\epsilon_i}{\\hat\\sigma}\\) Externamente estudentizado \\(\\frac{\\hat\\epsilon_i}{\\hat\\sigma_{(-i)}}\\) * En el residuo internamente estudentizado, \\(\\hat\\sigma\\) denota una estimaci√≥n de \\(\\sigma\\) basada en todas las observaciones; ‚Ä† En el residuo externamente estudentizado, \\(\\hat\\sigma_{(-i)}\\) es una estimaci√≥n obtenida luego de excluir la i-√©sima observaci√≥n de los c√°lculos. 6.2 El m√©todo gr√°fico "],
["apli-nlme.html", "7 Aplicaci√≥n con nlme Ejercicios", " 7 Aplicaci√≥n con nlme En este cap√≠tulo se mostrar√° como usar el paquete nlme para la aplicaci√≥n de modelos mixtos con la base de datos Oxboys del mismo paquete. A continuaci√≥n la base de datos a utilizar. library(nlme) head(Oxboys) ## Grouped Data: height ~ age | Subject ## Subject age height Occasion ## 1 1 -1.0000 140.5 1 ## 2 1 -0.7479 143.4 2 ## 3 1 -0.4630 144.8 3 ## 4 1 -0.1643 147.1 4 ## 5 1 -0.0027 147.7 5 ## 6 1 0.2466 150.2 6 Esta base de datos sobre crecimiento contiene la informaci√≥n sobre altura (heigth), edad estandarizada (age) de un grupo de 26 j√≥venes. Como la base de datos Oxboys es de la clase groupedData, es posible aplicar un plot directamente y el resultado se muestra continuaci√≥n. plot(Oxboys) Es posible convertir un data.frame para que tenga la clase groupedData, consulte la ayuda de la funci√≥n groupedData del paquete nlme para m√°s detalles. De la figura anterior vemos que las curvas de crecimiento inician a diferente altura (intercepto) y que la pendiente del crecimiento no son todas iguales, por ejemplo, el individuo 21 creci√≥ m√°s r√°pido que el individuo 3. Esto nos hace pensar que un modelo con intercepto y pendiente aleatoria podr√≠an ser adecuados para modelar el crecimiento. En las siguientes ecuaciones se resume el modelo matem√°tico que interesa en esta situaci√≥n. \\[\\begin{align*} Height_{ij} &amp;\\sim N(\\mu_{ij}, \\sigma^2_{Heigth}) \\\\ \\mu_{ij} &amp;= \\beta_0 + \\beta_1 Age_{ij} + b_{0i} + b_{1i} Age_{ij} \\\\ \\left ( \\begin{matrix} b_{0} \\\\ b_{1} \\end{matrix} \\right ) &amp;\\sim N\\left ( \\left ( \\begin{matrix} 0 \\\\ 0 \\end{matrix} \\right ), \\left ( \\begin{matrix} \\sigma^2_{b0} &amp; \\sigma_{b01} \\\\ \\sigma_{b01} &amp; \\sigma^2_{b1} \\end{matrix} \\right ) \\right ) \\end{align*}\\] El vector de par√°metros para este modelo ser√≠a \\(\\boldsymbol{\\Theta}=(\\beta_0, \\beta_1, \\sigma_{height}, \\sigma_{b0}, \\sigma_{b1}, \\sigma_{b0b1})^\\top\\). Para ajustar este modelo a los datos con el paquete nlme podemos usar el siguiente c√≥digo. fit &lt;- lme(height ~ age, random= ~ 1 + age | Subject, data=Oxboys, method=&quot;REML&quot;) Para obtener la tabla de resumen usamos: summary(fit) ## Linear mixed-effects model fit by REML ## Data: Oxboys ## AIC BIC logLik ## 736.091 756.7714 -362.0455 ## ## Random effects: ## Formula: ~1 + age | Subject ## Structure: General positive-definite, Log-Cholesky parametrization ## StdDev Corr ## (Intercept) 8.081077 (Intr) ## age 1.680717 0.641 ## Residual 0.659889 ## ## Fixed effects: height ~ age ## Value Std.Error DF t-value p-value ## (Intercept) 149.37175 1.5854173 207 94.21605 0 ## age 6.52547 0.3363003 207 19.40370 0 ## Correlation: ## (Intr) ## age 0.628 ## ## Standardized Within-Group Residuals: ## Min Q1 Med Q3 Max ## -2.65092109 -0.57493341 -0.02842894 0.59604254 2.60496077 ## ## Number of Observations: 234 ## Number of Groups: 26 De la salida anterior se obtiene que \\(\\hat{\\boldsymbol{\\Theta}}=(\\hat{\\beta}_0=149.37, \\hat{\\beta}_1=6.53, \\hat{\\sigma}_{height}=0.66, \\hat{\\sigma}_{b0}=8.08, \\hat{\\sigma}_{b1}=1.68, \\hat{\\sigma}_{b0b1}=8.71)^\\top\\). La estimaci√≥n \\(\\hat{\\sigma}_{b0b1}\\) no aparece directamente en el summary pero se obtiene utilizando la ecuaci√≥n \\(Cor=Cov/(\\sigma_1 \\sigma_2)\\) que relaciona correlaci√≥n, covarianza y desviaciones de los efectos aleatorios. Usando la informaci√≥n anterior se puede escribir el modelo ajustado de la siguiente manera. \\[\\begin{align*} Height_{ij} &amp;\\sim N(\\hat{\\mu}_{ij}, 0.66^2) \\\\ \\hat{\\mu}_{ij} &amp;= 149.37 + 6.53 Age_{ij} + b_{0i} + b_{1i} Age_{ij} \\\\ \\left ( \\begin{matrix} b_{0} \\\\ b_{1} \\end{matrix} \\right ) &amp;\\sim N\\left ( \\left ( \\begin{matrix} 0 \\\\ 0 \\end{matrix} \\right ), \\left ( \\begin{matrix} 8.08^2 &amp; 8.71 \\\\ 8.71 &amp; 1.68^2 \\end{matrix} \\right ) \\right ). \\end{align*}\\] Los elementos \\(b_{0i}\\) y \\(b_{1i}\\) se deben substituir por sus respectivas predicciones \\(\\tilde{b}_{0i}\\) y \\(\\tilde{b}_{1i}\\) y se pueden obtener del modelo ajustado as√≠: ranef(fit) ## (Intercept) age ## 10 -19.0972476 -2.78657472 ## 26 -11.3675996 -0.97474075 ## 25 -10.1595528 -2.42702035 ## 9 -11.2213331 -0.58069044 ## 2 -6.5096277 -1.07136271 ## 6 -2.5902388 -2.41771656 ## 7 -3.2473132 -1.46379286 ## 17 -6.3744842 1.89443713 ## 16 -1.8344703 -1.86707015 ## 15 -5.0856366 0.51526141 ## 8 -1.0776201 -0.06615528 ## 20 2.0850836 -1.99239802 ## 1 -1.2464285 0.59919226 ## 18 1.8031920 -0.51486646 ## 5 2.0531168 -0.24308081 ## 23 1.6937341 0.63140824 ## 11 0.6839704 1.85733185 ## 21 1.1525543 0.91894343 ## 3 6.2613001 -1.58181075 ## 24 3.7645669 0.25652772 ## 22 5.1957592 1.50551719 ## 12 7.4308033 0.52297645 ## 13 6.7004368 1.89758007 ## 14 10.0986013 2.09367207 ## 19 15.1957040 2.50720025 ## 4 15.6927297 2.78723179 Los valores de los efectos fijos estimados se pueden obtener as√≠: fixef(fit) ## (Intercept) age ## 149.371753 6.525469 Usando la informaci√≥n de los efectos fijo y aleatorios obtenidos antes, es posible escribir la ecuaci√≥n del modelo para cada individuo. Los efectos fijos estimados fueron \\(\\hat{\\beta}_0 \\approx 149.37\\) y \\(\\hat{\\beta}_1\\approx 6.53\\). Para el sujeto # 10 se obtuvo \\(\\tilde{b}_{0, i=10} \\approx -19.10\\) y \\(\\tilde{b}_{1, i=10} \\approx -2.79\\), as√≠ la media del individuo # 10 se calcula as√≠: \\[\\begin{align*} \\hat{\\mu}_{i=10, j} &amp;= \\hat{\\beta}_0 + \\hat{\\beta}_0 \\, Age_{i=10, j} + \\tilde{b}_{0, i=10} + \\tilde{b}_{1, i=10} \\, Age_{i=10, j} \\\\ \\hat{\\mu}_{i=10, j} &amp;= 149.37 + 6.53 \\, Age_{i=10, j} - 19.10 - 2.79 \\, Age_{i=10, j} \\\\ \\hat{\\mu}_{i=10, j} &amp;= 130.27 + 3.74 \\, Age_{i=10, j} \\end{align*}\\] Lo anterior se puede resumir en el siguiente modelo. \\[\\begin{align*} Height_{i=10, j} &amp;\\sim N(\\hat{\\mu}_{i=10, j}, \\hat{\\sigma}^2_{Height}) \\\\ \\hat{\\mu}_{i=10, j} &amp;= 130.27 + 3.74 \\, Age_{i=10, j} \\\\ \\hat{\\sigma}_{Height} &amp;= 0.66 \\end{align*}\\] La expresi√≥n anterior para cada individuo con los efectos finales (fijos y aleatorios) se puede obtener con R as√≠: coef(fit) ## (Intercept) age ## 10 130.2745 3.738894 ## 26 138.0042 5.550728 ## 25 139.2122 4.098448 ## 9 138.1504 5.944778 ## 2 142.8621 5.454106 ## 6 146.7815 4.107752 ## 7 146.1244 5.061676 ## 17 142.9973 8.419906 ## 16 147.5373 4.658399 ## 15 144.2861 7.040730 ## 8 148.2941 6.459313 ## 20 151.4568 4.533071 ## 1 148.1253 7.124661 ## 18 151.1749 6.010602 ## 5 151.4249 6.282388 ## 23 151.0655 7.156877 ## 11 150.0557 8.382801 ## 21 150.5243 7.444412 ## 3 155.6331 4.943658 ## 24 153.1363 6.781996 ## 22 154.5675 8.030986 ## 12 156.8026 7.048445 ## 13 156.0722 8.423049 ## 14 159.4704 8.619141 ## 19 164.5675 9.032669 ## 4 165.0645 9.312700 En la presente aplicaci√≥n es posible incluir la recta de regresi√≥n para cada individuo al diagrama de dispersi√≥n original. El c√≥digo de R para obtener esto es el siguiente. library(lattice) xyplot(height ~ age | Subject, data=Oxboys, fit=fit, strip=strip.custom(bg=&quot;white&quot;), pch=16, cex=0.7, col=&#39;indianred1&#39;, panel = function(x, y, ..., fit, subscripts) { panel.xyplot(x, y, ...) ypred &lt;- fitted(fit)[subscripts] panel.lines(x, ypred, col=&quot;deepskyblue3&quot;, lwd=1) }, ylab=&quot;Height (cm)&quot;, xlab=&quot;Centered age&quot;) En la figura anterior se tienen las observaciones (crecimiento) representado por los puntos rojos, adicionalmente, aparece una recta de color azul que representa la recta de regresi√≥n para cada individuo. De la figura se observa que la linea logra explicar la evoluci√≥n del crecimiento para cada individuo. Ejercicios Repita el ejercicio anterior considerando un modelo s√≥lo con intercepto aleatorio. Dibuje las rectas de regresi√≥n para cada individuo. ¬øQu√© opina de este modelo? Repita el ejercicio anterior considerando un modelo s√≥lo con pendiente aleatoria. Dibuje las rectas de regresi√≥n para cada individuo. ¬øQu√© opina de este modelo? Estime la estatura para el individuo # 3 cuando su edad centrada sea de 1.1. Replique los ejemplo de este documento. "],
["apli-lme4.html", "8 Aplicaci√≥n con lme4 Ejercicios", " 8 Aplicaci√≥n con lme4 En este cap√≠tulo se mostrar√° como usar el paquete lme4 para la aplicaci√≥n de modelos mixtos con la base de datos sleepstudy del mismo paquete. A continuaci√≥n la base de datos a utilizar. library(lme4) head(sleepstudy) ## Reaction Days Subject ## 1 249.5600 0 308 ## 2 258.7047 1 308 ## 3 250.8006 2 308 ## 4 321.4398 3 308 ## 5 356.8519 4 308 ## 6 414.6901 5 308 Esta base de datos sobre el tiempo de reacci√≥n promedio por d√≠a para un conjunto de individuos, en un estudio de privaci√≥n del sue√±o, contiene la informaci√≥n sobre el tiempo de reacci√≥n promedio (Reaction), el n√∫mero de d√≠as de privaci√≥n del sue√±o (Days), donde el d√≠a 0 corresponde al d√≠a en el que los indiviuos ten√≠an su cantidad normal de sue√±o, y el n√∫mero del individuo (en total 18) sobre el que se realiz√≥ la observaci√≥n (Subject). A partir del d√≠a 0, hubo una restricci√≥n en cada individuo a 3 horas de sue√±o por noche. library(ggplot2) ggplot(data = sleepstudy, aes(x = Days, y = Reaction, color = Subject)) + geom_point() + theme_bw() + facet_wrap(~ Subject) + theme(legend.position = &quot;none&quot;) De la figura anterior vemos que el tiempo de reacci√≥n promedio, tanto en el d√≠a 0 como en los siguientes d√≠as de prueba (del d√≠a 1 al d√≠a 9), son distintos en cada uno de los individuos. Esta situaci√≥n conlleva a probar la hip√≥tesis de que el tiempo de reacci√≥n promedio en una serie de pruebas var√≠a seg√∫n los individuos. Esto es, ajustar un modelo donde el intercepto y la pendiente se consideran como efectos aleatorios. Un modelo lineal mixto que describe la anterior situaci√≥n se puede escribir como: \\[\\begin{align*} Reaction_{ij} &amp;\\sim N(\\mu_{ij}, \\sigma^2_{Reaction}) \\\\ \\mu_{ij} &amp;= \\beta_0 + \\beta_1 Days_{ij} + b_{0i} + b_{1i} Days_{ij} \\\\ \\left ( \\begin{matrix} b_{0} \\\\ b_{1} \\end{matrix} \\right ) &amp;\\sim N\\left ( \\left [ \\begin{matrix} 0 \\\\ 0 \\end{matrix} \\right ], \\left [ \\begin{matrix} \\sigma^2_{b0} &amp; \\sigma_{b01} \\\\ \\sigma_{b01} &amp; \\sigma^2_{b1} \\end{matrix} \\right ] \\right ) \\end{align*}\\] Aqu√≠, los individuos (\\(i\\)) var√≠an en el tiempo de reacci√≥n promedio tanto en su intercepto (\\(b_{0i}\\)) como en su pendiente (\\(b_{1i}\\)), que en conjunto componen la varianza total en dicho tiempo atribuible a la variaci√≥n entre individuos. Esta contribuci√≥n individual se cuantifica usando un modelo de intercepto y pendiente aleatoria con distribuci√≥n normal (\\(N\\)). La variaci√≥n entre individuos en intercepto y pendiente es \\(\\sigma^2_{b0}\\) y \\(\\sigma^2_{b1}\\), respectivamente. La covarianza entre el intercepto y la pendiente esta dada por \\(\\sigma_{b01}\\). El vector de par√°metros para este modelo ser√≠a \\(\\boldsymbol{\\Theta}=(\\beta_0, \\beta_1, \\sigma_{reaction}, \\sigma_{b0}, \\sigma_{b1}, \\sigma_{b0b1})^\\top\\). Para ajustar el modelo de intercepto y pendiente aleatoria planteado usando el paquete lme4 podemos usar el siguiente c√≥digo: fit &lt;- lmer(Reaction ~ Days + (Days | Subject), REML = TRUE, data = sleepstudy) Para obtener la tabla de resumen usamos: summary(fit) ## Linear mixed model fit by REML [&#39;lmerMod&#39;] ## Formula: Reaction ~ Days + (Days | Subject) ## Data: sleepstudy ## ## REML criterion at convergence: 1743.6 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -3.9536 -0.4634 0.0231 0.4633 5.1793 ## ## Random effects: ## Groups Name Variance Std.Dev. Corr ## Subject (Intercept) 611.90 24.737 ## Days 35.08 5.923 0.07 ## Residual 654.94 25.592 ## Number of obs: 180, groups: Subject, 18 ## ## Fixed effects: ## Estimate Std. Error t value ## (Intercept) 251.405 6.824 36.843 ## Days 10.467 1.546 6.771 ## ## Correlation of Fixed Effects: ## (Intr) ## Days -0.138 De la salida anterior se obtienen los siguientes par√°metros (\\(\\Theta\\)): \\(\\Theta\\) \\(\\beta_{0}\\) 251.40 \\(\\beta_{1}\\) 10.47 \\(\\sigma_{reaction}\\) 25.59 \\(\\sigma_{b0}\\) 24.74 \\(\\sigma_{b1}\\) 5.92 \\(\\sigma_{b0b1}\\) 10.25 * El √∫timo par√°metro estimado se obtiene utilizando la ecuaci√≥n de correlaci√≥n (\\(\\rho\\)) que relaciona la covarianza y desviaciones de los efectos aleatorios: \\(\\rho_{b0b1} = \\sigma_{b0b1}/(\\sigma_{b0} * \\sigma_{b1})\\). Usando la informaci√≥n anterior se puede escribir el modelo ajustado de la siguiente manera: \\[\\begin{align*} Reaction_{ij} &amp;\\sim N(\\hat{\\mu}_{ij}, 25.59^2) \\\\ \\hat{\\mu}_{ij} &amp;= 251.40 + 10.47 Days_{ij} + b_{0i} + b_{1i} Days_{ij} \\\\ \\left ( \\begin{matrix} b_{0} \\\\ b_{1} \\end{matrix} \\right ) &amp;\\sim N\\left ( \\left [ \\begin{matrix} 0 \\\\ 0 \\end{matrix} \\right ], \\left [ \\begin{matrix} 24.74^2 &amp; 10.25 \\\\ 10.25 &amp; 5.92^2 \\end{matrix} \\right ] \\right ) \\end{align*}\\] Los elementos \\(b_{0i}\\) y \\(b_{1i}\\) se deben substituir por sus respectivas predicciones \\(\\tilde{b}_{0i}\\) y \\(\\tilde{b}_{1i}\\) y se pueden obtener del modelo ajustado de esta forma: ranef(fit) ## $Subject ## (Intercept) Days ## 308 2.2575329 9.1992737 ## 309 -40.3942719 -8.6205161 ## 310 -38.9563542 -5.4495796 ## 330 23.6888704 -4.8141448 ## 331 22.2585409 -3.0696766 ## 332 9.0387625 -0.2720535 ## 333 16.8389833 -0.2233978 ## 334 -7.2320462 1.0745075 ## 335 -0.3326901 -10.7524799 ## 337 34.8865253 8.6290208 ## 349 -25.2080191 1.1730997 ## 350 -13.0694180 6.6142185 ## 351 4.5777099 -3.0152825 ## 352 20.8614523 3.5364062 ## 369 3.2750882 0.8722876 ## 370 -25.6110745 4.8222518 ## 371 0.8070591 -0.9881730 ## 372 12.3133491 1.2842380 ## ## with conditional variances for &quot;Subject&quot; Y los valores de los efectos fijos estimados se pueden obtener as√≠: fixef(fit) ## (Intercept) Days ## 251.40510 10.46729 Con base en la informaci√≥n anterior de efectos aleatorios y fijos, es posible escribir la ecuaci√≥n del modelo para cada individuo. Para esto, se debe considerar los efectos fijos estimados (\\(\\hat{\\beta}_0 \\approx 251.40\\) y \\(\\hat{\\beta}_1\\approx 10.47\\)) y los efectos aleatorios de cada uno de los individuos (por ejemplo para el individuo 308, \\(\\tilde{b}_{0, i=308} \\approx 2.26\\) y \\(\\tilde{b}_{1, i=308} \\approx 9.20\\)). As√≠, el valor medio del individuo 308 se calcula como: \\[\\begin{align*} \\hat{\\mu}_{i=308, j} &amp;= \\hat{\\beta}_0 + \\hat{\\beta}_0 \\, Days_{i=308, j} + \\tilde{b}_{0, i=308} + \\tilde{b}_{1, i=308} \\, Days_{i=308, j} \\\\ \\hat{\\mu}_{i=308, j} &amp;= 251.40 + 10.47 \\, Days_{i=308, j} 2.26 + 9.20 \\, Days_{i=308, j} \\\\ \\hat{\\mu}_{i=308, j} &amp;= 253.66 + 19.67 \\, Days_{i=308, j} \\end{align*}\\] Lo anterior se puede resumir en el siguiente modelo. \\[\\begin{align*} Reaction_{i=308, j} &amp;\\sim N(\\hat{\\mu}_{i=308, j}, \\hat{\\sigma}^2_{Reaction}) \\\\ \\hat{\\mu}_{i=308, j} &amp;= 253.66 + 19.67 \\, Days_{i=308, j} \\\\ \\hat{\\sigma}_{Reaction} &amp;= 25.59 \\end{align*}\\] Los efectos fijos y aleatorios de la expresi√≥n anterior para cada uno de los individuos se pueden obtener con R de la siguiente forma: coef(fit) ## $Subject ## (Intercept) Days ## 308 253.6626 19.6665597 ## 309 211.0108 1.8467699 ## 310 212.4488 5.0177063 ## 330 275.0940 5.6531411 ## 331 273.6636 7.3976093 ## 332 260.4439 10.1952325 ## 333 268.2441 10.2438881 ## 334 244.1731 11.5417935 ## 335 251.0724 -0.2851939 ## 337 286.2916 19.0963068 ## 349 226.1971 11.6403856 ## 350 238.3357 17.0815045 ## 351 255.9828 7.4520035 ## 352 272.2666 14.0036922 ## 369 254.6802 11.3395736 ## 370 225.7940 15.2895377 ## 371 252.2122 9.4791130 ## 372 263.7185 11.7515240 ## ## attr(,&quot;class&quot;) ## [1] &quot;coef.mer&quot; A continuaci√≥n podras observar el diagrama de dispersi√≥n mostrado al inicio de este capitulo, agregandole a la misma la recta de regresi√≥n para cada individuo. El c√≥digo de R para obtener esto se presenta a continuaci√≥n: fit &lt;- lmer(Reaction ~ Days + (Days | Subject), REML = TRUE, data = sleepstudy) sleepstudy$pred_inter_pend_aleatorio &lt;- predict(fit) ggplot(data = sleepstudy, aes(x = Days, y = pred_inter_pend_aleatorio, color = Subject)) + geom_line() + geom_point(aes(x = Days, y = Reaction, color = Subject)) + geom_abline(intercept = 251.40, slope = 10.47, color = &quot;black&quot;, linetype = &quot;dashed&quot;, size = 0.5) + theme_bw() + facet_wrap(~ Subject) + theme(legend.position = &quot;none&quot;) La figura anterior corresponde a un modelo de intercepto y pendiente aleatoria, en el que se permite que tanto los interceptos como las pendientes var√≠en seg√∫n los individuos. Las l√≠neas continuas corresponde a la recta de regresi√≥n ajustada a los datos. Los puntos representan las observaciones (tiempo de reacci√≥n promedio por d√≠a) medidas en cada uno de los individuos. La l√≠nea negra discontinua representa el valor medio global de la distribuci√≥n de los efectos aleatorios. A continuaci√≥n podra observar distintas figuras donde se ajustaron cuatro modelos distintos, entre ellos el modelo mixto con intercepto y pendiente aleatoria ya evaluado aqu√≠ (Figura 4). Con base en estas figuras, se plantean los ejercicios posteriores a las mismas figuras: Ejercicios Ajuste el modelo con intercepto aleatorio mostrado en la anterior Figura 2. ¬øQu√© opina de este modelo? Ajuste el modelo con pendiente aleatoria presentada en la anterior Figura 3. ¬øQu√© opina de este modelo? Ajustar solo un intercepto aleatorio permite que los individuos var√≠en asumiendo que los mismos tienen una pendiente com√∫n (Figura 2). Al ajustar solo una pendiente aleatoria (Figura 3) permite que la pendiente de un predictor var√≠e en funci√≥n de los individuos (la variable de agrupaci√≥n). Con base esto y teniendo en cuenta el modelo de intercepto y pendiente aleatoria (Figura 4), eval√∫e cual de estos estos modelos permite un mejor ajuste de los datos presentados en la base de datos sleepstudy del paquete lme4. "],
["references.html", "References", " References "]
]
