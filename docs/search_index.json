[
["index.html", "Modelos Mixtos con R Bienvenido Estructura del libro Software y convenciones Bloques informativos", " Modelos Mixtos con R Freddy Hern谩ndez Barajas Jorge Leonardo L贸pez Mart铆nez 2020-02-12 Bienvenido Este libro est谩 destinado para usuarios de R interesados en aplicar modelos mixtos. Freddy Hern谩ndez Barajas Jorge Leonardo L贸pez Mart铆nez Estructura del libro En el cap铆tulo 1 se hace un repaso b谩sico del modelo de regresi贸n lineal cl谩sico. En el cap铆tulo 2 se presentan los modelos mixtos. En el cap铆tulo 3 se presenta el paquete lme4 y sus principales funciones para modelaci贸n, mientras que en el cap铆tulo 4 se presenta el paquete nlme y sus principales funciones para modelaci贸n. Software y convenciones Para realizar este libro usamos los paquetes knitr (Xie 2015) y bookdown (Xie 2020) que permiten unir la ventajas de LaTeX y R en un mismo archivo. En todo el libro se presentar谩n c贸digos que el lector puede copiar y pegar en su consola de R para obtener los mismos resultados aqu铆 del libro. Los c贸digos se destacan en una caja de color similar a la mostrada a continuaci贸n. 4 + 6 a &lt;- c(1, 5, 6) 5 * a 1:10 Los resultados o salidas obtenidos de cualquier c贸digo se destacan con dos s铆mbolos de n煤meral (##) al inicio de cada l铆nea o rengl贸n, esto quiere decir que todo lo que inicie con ## son resultados obtenidos y NO los debe copiar. Abajo se muestran los resultados obtenidos luego de correr el c贸digo anterior. ## [1] 10 ## [1] 5 25 30 ## [1] 1 2 3 4 5 6 7 8 9 10 Bloques informativos En varias partes del libro usaremos bloques informativos para resaltar alg煤n aspecto importante. Abajo se encuentra un ejemplo de los bloques y su significado. Nota aclaratoria. Sugerencia. Advertencia. References "],
["reg-lin.html", "1 Regresi贸n lineal 1.1 Modelo estad铆stico 1.2 Verosimilitud del modelo", " 1 Regresi贸n lineal En este cap铆tulo se presenta el modelo de regresi贸n lineal cl谩sico. 1.1 Modelo estad铆stico El modelo estad铆stico en regresi贸n lineal cl谩sico permite modelar la media de una variable \\(Y\\) en funci贸n de \\(k\\) covariables. El modelo se puede expresar como sigue. \\[\\begin{align} \\label{mod2} y_i &amp;\\sim N(\\mu_i, \\sigma^2), \\\\ \\mu_i &amp;= \\beta_0 + \\beta_1 x_{1i} + \\beta_2 x_{2i} + \\cdots + \\beta_k x_{ki}, \\\\ \\sigma^2 &amp;= \\text{constante} \\end{align}\\] donde \\(i=1, 2, \\ldots, n\\) es el 铆ndice que identifica las \\(n\\) observaciones del conjunto de entrenamiento. El vector de par谩metros del modelo es \\(\\boldsymbol{\\theta}=(\\beta_0, \\beta_1, \\cdots, \\beta_k, \\sigma)^\\top\\). 1.2 Verosimilitud del modelo La funci贸n de verosimilitud \\(L\\) para el modelo es la siguiente: \\[ L(\\boldsymbol{\\theta}) = \\prod_i^n f(y_i \\vert \\beta_0, \\beta_1, \\cdots, \\beta_k, \\sigma), \\] donde \\(f\\) corresponde a la funci贸n de densidad de la normal. Para estimar el vector de par谩metros \\(\\boldsymbol{\\theta}\\) del modelo se usa el m茅todo de M谩xima Verosimilitud sobre la funci贸n \\(L\\) o sobre la funci贸n de log-verosimilitud siguiente: \\[ l(\\boldsymbol{\\theta}) = \\sum_i^n \\log(f(y_i \\vert \\beta_0, \\beta_1, \\cdots, \\beta_k, \\sigma)), \\] Ejemplo Como ilustraci贸n vamos a usar los datos del ejemplo 3.1 del libro de Montgomery, Peck and Vining (2003). En el ejemplo 3.1 los autores ajustaron un modelo de regresi贸n lineal m煤ltiple para explicar el Tiempo necesario para que un trabajador haga el mantenimiento y surta una m谩quina dispensadora de refrescos en funci贸n de las variables N煤mero de Cajas y Distancia. Los datos del ejemplo est谩n disponibles en el paquete MPV (por los apellidos de los autores). A continuaci贸n el c贸digo para cargar los datos y una muestra de las 6 primeras observaciones de la base de datos, en total se disponen de 20 observaciones. require(MPV) colnames(softdrink) &lt;- c(&#39;tiempo&#39;, &#39;cantidad&#39;, &#39;distancia&#39;) head(softdrink) ## tiempo cantidad distancia ## 1 16.68 7 560 ## 2 11.50 3 220 ## 3 12.03 3 340 ## 4 14.88 4 80 ## 5 13.75 6 150 ## 6 18.11 7 330 Un gr谩fico en 3d es obligratorio para explorar la relaci贸n entre las variables, este diagrama de puede obtener usando el paquete scatterplot3d. A continuaci贸n el c贸digo para construirlo. library(scatterplot3d) attach(softdrink) scatterplot3d(x=cantidad, y=distancia, z=tiempo, pch=16, cex.lab=1, highlight.3d=TRUE, type=&quot;h&quot;, xlab=&#39;Cantidad de cajas&#39;, ylab=&#39;Distancia (pies)&#39;, zlab=&#39;Tiempo (min)&#39;) De la figura anterior se ve claramente que a medida que aumenta el n煤mero de cajas y la distancia los tiempos tienden a ser mayores. A continuaci贸n se define la funci贸n de menos log-verosimilitud para el modelo anterior. A pesar de que nos interesa maximizar la funci贸n de log-verosimilitud hemos creado su negativo, esto porque la mayor铆a de las funciones de optimizaci贸n minimizan y no maximizan; maximizar \\(f(x)\\) es equivalente a minimizar \\(-f(x)\\). minusll &lt;- function(theta, y, x1, x2) { media &lt;- theta[1] + theta[2] * x1 + theta[3] * x2 # Se define la media desvi &lt;- theta[4] # Se define la desviaci贸n. - sum(dnorm(x=y, mean=media, sd=desvi, log=TRUE)) } Ahora vamos a usar la funci贸n optim para encontrar los valores que maximizan la funci贸n de log-verosimilitud, el c贸digo para hacer eso se muestra a continuaci贸n. En el par谩metro par se coloca un vector de posibles valores de \\(\\boldsymbol{\\Theta}\\) para iniciar la b煤squeda, en fn se coloca la funci贸n de inter茅s, en lower y upper se colocan vectores que indican los l铆mites de b煤squeda de cada par谩metro, los \\(\\beta_k\\) pueden variar entre \\(-\\infty\\) y \\(\\infty\\) mientras que el par谩metro \\(\\sigma\\) toma valores en el intervalo \\((0, \\infty)\\). Como la funci贸n minusll tiene argumentos adicionales y, x1 y x2, estos pasan a la funci贸n optim al final como se muestra en el c贸digo. mod1 &lt;- optim(par=c(0, 0, 0, 1), fn=minusll, method=&#39;L-BFGS-B&#39;, lower=c(-Inf, -Inf, -Inf, 0), upper=c(Inf, Inf, Inf, Inf), y=softdrink$tiempo, x1=softdrink$cantidad, x2=softdrink$distancia) En el objeto res1 est谩 el resultado de la optimizaci贸n, para explorar los resultados usamos mod1 ## $par ## [1] 2.34103296 1.61590757 0.01438512 3.05769678 ## ## $value ## [1] 63.41469 ## ## $counts ## function gradient ## 58 58 ## ## $convergence ## [1] 0 ## ## $message ## [1] &quot;CONVERGENCE: REL_REDUCTION_OF_F &lt;= FACTR*EPSMCH&quot; De esta forma el vector de par谩metros estimados del modelo es \\(\\hat{\\boldsymbol{\\theta}}=(2.34, 1.62, 0.01, 3.06)^\\top\\). Usualmente en la pr谩ctica se usa la funci贸n lm para estimar el vector de par谩metros, a continuaci贸n el c贸digo necesario para usar la funcion lm. mod2 &lt;- lm(tiempo ~ cantidad + distancia, data=softdrink) summary(mod2) ## ## Call: ## lm(formula = tiempo ~ cantidad + distancia, data = softdrink) ## ## Residuals: ## Min 1Q Median 3Q Max ## -5.7880 -0.6629 0.4364 1.1566 7.4197 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 2.341231 1.096730 2.135 0.044170 * ## cantidad 1.615907 0.170735 9.464 3.25e-09 *** ## distancia 0.014385 0.003613 3.981 0.000631 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 3.259 on 22 degrees of freedom ## Multiple R-squared: 0.9596, Adjusted R-squared: 0.9559 ## F-statistic: 261.2 on 2 and 22 DF, p-value: 4.687e-16 De la salida anterior vemos que el vector de par谩metros estimados del modelo es \\(\\hat{\\boldsymbol{\\theta}}=(2.34, 1.62, 0.01, 3.26)^\\top\\). Para profundizar en el modelo de regresion lineal se recomienda consultar libro Modelos de Regresi贸n con R "],
["mod-mix.html", "2 Modelos Mixtos", " 2 Modelos Mixtos Los modelos mixtos fueron propuestos por (Laird and Ware 1982) y en ellos se asume que existe una relaci贸n entre el vector de observaciones \\(\\boldsymbol{Y}_i\\) del sujeto o grupo \\(i\\) y las covariables por medio de la siguiente expresi贸n \\[\\begin{equation} \\begin{aligned} \\label{mixedmodel1} \\boldsymbol{Y}_i \\mid \\boldsymbol{b}_i &amp;\\sim \\mathcal{N}(\\boldsymbol{X}_i \\boldsymbol{\\beta} + \\boldsymbol{Z}_i \\boldsymbol{b}_i, \\boldsymbol{\\Sigma}_i), \\\\ \\boldsymbol{b}_i &amp;\\sim \\mathcal{N}(\\boldsymbol{0}, \\boldsymbol{D}), \\end{aligned} \\end{equation}\\] donde \\(\\boldsymbol{X}_i\\) y \\(\\boldsymbol{Z}_i\\) son matrices de dise帽o conocidas con la informaci贸n de las covariables, siendo \\(\\boldsymbol{X}_i\\) de dimensi贸n \\(n_i \\times p\\) y \\(\\boldsymbol{Z}_i\\) de dimensi贸n \\(n_i \\times q\\). El elemento \\(\\boldsymbol{\\beta}\\) representa el vector de efectos fijos general, \\(\\boldsymbol{b}_i\\) el vector de efectos aleatorios exclusivos para el grupo \\(i\\) y las matrices. El vector \\(\\boldsymbol{b}_i\\) en la expresi贸n es llamado efecto aleatorio porque 茅ste cambia la media de sujeto a sujeto y su funci贸n es la de mejorar el ajuste general dado por el elemento \\(\\boldsymbol{X}_i \\boldsymbol{\\beta}\\) al agregar la cantidad \\(\\boldsymbol{Z}_i \\boldsymbol{b}_i\\). El modelo dado en la expresi贸n es llamado tambi茅n modelo mixto porque involucra tanto efectos fijos (\\(\\boldsymbol{\\beta}\\)) como efectos aleatorios (\\(\\boldsymbol{b}_i\\)). La distribuci贸n marginal de \\(\\boldsymbol{Y}_i\\) est谩 dada por \\[\\begin{equation} f_i(\\boldsymbol{Y}_i) = \\int f(\\boldsymbol{Y}_i | \\boldsymbol{b}_i) f(\\boldsymbol{b}_i) \\, d \\boldsymbol{b}_i \\end{equation}\\] donde \\(f(\\boldsymbol{Y}_i | \\boldsymbol{b}_i)\\) y \\(f(\\boldsymbol{b}_i)\\) corresponden a las densidades normales mostradas en la expresi贸n . Esta distribuci贸n marginal tiene forma cerrada y se puede mostrar f谩cilmente que la distribuci贸n de \\(\\boldsymbol{Y}_i\\) es una normal multivariada con vector de medias y matriz de covarianzas como se muestra a continuaci贸n. \\[\\begin{equation} \\boldsymbol{Y}_i \\sim \\mathcal{N}(\\boldsymbol{X}_i \\boldsymbol{\\beta}, \\boldsymbol{V}_i), \\end{equation}\\] donde \\(\\boldsymbol{V}_i=\\boldsymbol{Z}_i \\boldsymbol{D} \\boldsymbol{Z}_i^\\top + \\boldsymbol{\\Sigma}_i\\). El vector de par谩metros en este caso es \\(\\boldsymbol{\\theta}=(\\boldsymbol{\\beta}, \\boldsymbol{\\alpha})^\\top\\) donde \\(\\boldsymbol{\\alpha}\\) consiste de los \\(q(q+1)/2\\) elementos diferentes de la matriz \\(\\boldsymbol{D}\\) y todos los elementos de la matriz \\(\\boldsymbol{\\Sigma}_i\\). References "],
["pac-lme4.html", "3 Paquete lme4 3.1 Funci贸n lmer Ejemplo: modelo con intercepto aleatorio", " 3 Paquete lme4 El paquete lme4 (Bates et al. 2019) es uno de los paquetes m谩s completos para modelos mixtos. Al visitar este enlace se encontrar谩 la p谩gina de apoyo del paquete, all铆 se puede consultar el manual de referencia y las vi帽etas. 3.1 Funci贸n lmer La funci贸n lmer es la principal funci贸n del paquete (Bates et al. 2019). Esta funci贸n sirve para ajustar un modelo mixto y su estructura es la siguiente: lmer(formula, data = NULL, REML = TRUE, control = lmerControl(), start = NULL, verbose = 0L, subset, weights, na.action, offset, contrasts = NULL, devFunOnly = FALSE, ...) Los principales argumentos de la funci贸n son: formula: es una f贸rmula similar a la usada en el modelo lineal cl谩sico. Un ejemplo de f贸rmula ser铆a y ~ 1 + x1 + x2 + (1 + x2) con la cual se indican los efectos fijos y los efectos aleatorios del modelo. M谩s abajo hay una tabla con m谩s detalles sobre la f贸rmula. data: marco de datos donde est谩n las variables. REML: valor l贸gico que sirve para indicar si queremos estimaciones maximizando la verosimilitud restringida o la verosimilitud usual. La siguiente imagen corresponde a la tabla 2 de la vi帽eta Fitting Linear Mixed-Effects Models using lme4. En esa tabla las dos primeras columnas muestran formas equivalentes de incluir las estructuras de modelos mixtos m谩s comunes. Ejemplo: modelo con intercepto aleatorio En este ejemplo vamos a simular observaciones \\(ni=50\\) observaciones para \\(G=10\\) grupos (en total 500 obs) que tengan la estructura mostrada abajo. El objetivo del ejemplo es ilustrar el uso de la funci贸n lmer para estimar los par谩metros del modelo. \\[\\begin{align*} y_{ij} &amp;\\sim N(\\mu_{ij}, \\sigma^2_y) \\\\ \\mu_{ij} &amp;= 4 - 6 x_{ij} + b_{0i} \\\\ \\sigma^2_y &amp;= 16 \\\\ b_{0} &amp;\\sim N(0, \\sigma^2_{b0}=625) \\\\ x_{ij} &amp;\\sim U(-5, 6) \\end{align*}\\] El vector de par谩metros de este modelo es \\(\\boldsymbol{\\Theta}=(\\beta_0=4, \\beta_1=-6, \\sigma_y=4, \\sigma_{bo}=25)^\\top\\). Soluci贸n El c贸digo para simular las 500 observaciones se muestra a continuaci贸n. Observe que se fij贸 la semilla en dos ocasiones para que el lector pueda replicar el ejemplo y obtener los mismos resultados. ni &lt;- 50 G &lt;- 10 nobs &lt;- ni * G grupo &lt;- factor(rep(x=1:G, each=ni)) obs &lt;- rep(x=1:ni, times=G) set.seed(1234567) x &lt;- runif(n=nobs, min=-5, max=6) b0 &lt;- rnorm(n=G, mean=0, sd=sqrt(625)) # Intercepto aleatorio b0 &lt;- rep(x=b0, each=ni) # El mismo intercepto aleatorio pero repetido media &lt;- 4 - 6 * x + b0 set.seed(123456) y &lt;- rnorm(n=nobs, mean=media, sd=sqrt(16)) datos &lt;- data.frame(grupo, obs, b0, x, media, y) El siguiente paso es dibujar los datos para explorar si ser铆a apropiado usar un modelo con intercepto aleatorio (obvio porque as铆 se simularon los datos). El c贸digo para dibujar los datos se muestra abajo. library(ggplot2) ggplot(datos, aes(x, y, color=grupo) ) + geom_point() + labs(colour=&quot;Grupo/Cluster&quot;) En la figura anterior se observa un patr贸n claro, todas las 10 nubes de puntos tienen la misma pendiente pero diferente intercepto con el eje vertical, eso se debe a que en la simulaci贸n se incluy贸 un \\(b_0\\). Para estimar los par谩metros del modelos se usa la funci贸n mler de la siguiente forma. library(lme4) fit &lt;- lmer(y ~ x + (1 | grupo), data=datos) La funci贸n summary se puede usar sobre el objeto fit para obtener una tabla de resumen, a continuaci贸n se ilustra el uso y la salida de summary. summary(fit) Seg煤n el resultado anterior \\(\\hat{\\boldsymbol{\\Theta}}=(\\hat{\\beta}_0=3.53363, \\hat{\\beta}_1=-5.97805, \\hat{\\sigma}_y=4.012, \\hat{\\sigma}_{bo}=21.507)^\\top\\) mientras que el vector real de par谩metros es \\(\\boldsymbol{\\Theta}=(\\beta_0=4, \\beta_1=-6, \\sigma_y=4, \\sigma_{bo}=25)^\\top\\). Compare los resultados de la tabla anterior obtenida con la funci贸n lmer anterior con los resultados obtenidos con la funci贸n lme de cap铆tulo 4. 驴Hay alguna similitud? References "],
["pac-nlme.html", "4 Paquete nlme 4.1 Funci贸n lme Ejemplo: modelo con intercepto aleatorio", " 4 Paquete nlme El paquete nlme (Pinheiro, Bates, and R-core 2019) es otro de los paquetes para modelos mixtos. Al visitar este enlace se encontrar谩 la p谩gina de apoyo del paquete, all铆 se puede consultar el manual de referencia. 4.1 Funci贸n lme La funci贸n lme es la principal funci贸n del paquete (Pinheiro, Bates, and R-core 2019). Esta funci贸n sirve para ajustar un modelo mixto y su estructura es la siguiente: lme(fixed, data, random, correlation, weights, subset, method, na.action, control, contrasts = NULL, keep.data = TRUE) Los principales argumentos de la funci贸n son: formula: es una f贸rmula similar a la usada en el modelo lineal cl谩sico. Un ejemplo de f贸rmula ser铆a y ~ 1 + x1 + x2 con la cual se indican los efectos fijos del modelo. data: marco de datos donde est谩n las variables. random: es una f贸rmula solo con lado derecho. Si queremos indicar intercepto aleatorio se escribe ~ 1 | group y si se desea intercepto y pendiente aleatoria se escribe ~ 1 + x2 | group. correlation: es un par谩metro opcional para indicar la estructura de correlaci贸n entre las observaciones de cada grupo. Para m谩s detalles consulte la ayuda de la funci贸n corClasses. method: valor l贸gico que sirve para indicar si queremos estimaciones maximizando la verosimilitud restringida o la verosimilitud usual, las dos opciones son ML o REML. Ejemplo: modelo con intercepto aleatorio En este ejemplo vamos a simular observaciones \\(ni=50\\) observaciones para \\(G=10\\) grupos (en total 500 obs) que tengan la estructura mostrada abajo. El objetivo del ejemplo es ilustrar el uso de la funci贸n lmer para estimar los par谩metros del modelo. \\[\\begin{align*} y_{ij} &amp;\\sim N(\\mu_{ij}, \\sigma^2_y) \\\\ \\mu_{ij} &amp;= 4 - 6 x_{ij} + b_{0i} \\\\ \\sigma^2_y &amp;= 16 \\\\ b_{0} &amp;\\sim N(0, \\sigma^2_{b0}=625) \\\\ x_{ij} &amp;\\sim U(-5, 6) \\end{align*}\\] El vector de par谩metros de este modelo es \\(\\boldsymbol{\\Theta}=(\\beta_0=4, \\beta_1=-6, \\sigma_y=4, \\sigma_{b0}=25)^\\top\\). Soluci贸n El c贸digo para simular las 500 observaciones se muestra a continuaci贸n. Observe que se fij贸 la semilla en dos ocasiones para que el lector pueda replicar el ejemplo y obtener los mismos resultados. ni &lt;- 50 G &lt;- 10 nobs &lt;- ni * G grupo &lt;- factor(rep(x=1:G, each=ni)) obs &lt;- rep(x=1:ni, times=G) set.seed(1234567) x &lt;- runif(n=nobs, min=-5, max=6) b0 &lt;- rnorm(n=G, mean=0, sd=sqrt(625)) # Intercepto aleatorio b0 &lt;- rep(x=b0, each=ni) # El mismo intercepto aleatorio pero repetido media &lt;- 4 - 6 * x + b0 set.seed(123456) y &lt;- rnorm(n=nobs, mean=media, sd=sqrt(16)) datos &lt;- data.frame(grupo, obs, b0, x, media, y) El siguiente paso es dibujar los datos para explorar si ser铆a apropiado usar un modelo con intercepto aleatorio (obvio porque as铆 se simularon los datos). El c贸digo para dibujar los datos se muestra abajo. library(ggplot2) ggplot(datos, aes(x, y, color=grupo) ) + geom_point() + labs(colour=&quot;Grupo/Cluster&quot;) En la figura anterior se observa un patr贸n claro, todas las 10 nubes de puntos tienen la misma pendiente pero diferente intercepto con el eje vertical, eso se debe a que en la simulaci贸n se incluy贸 un \\(b_0\\). Para estimar los par谩metros del modelos se usa la funci贸n mler de la siguiente forma. library(nlme) fit &lt;- lme(y ~ x, random = ~ 1 | grupo, data=datos) La funci贸n summary se puede usar sobre el objeto fit para obtener una tabla de resumen, a continuaci贸n se ilustra el uso y la salida de summary. summary(fit) Seg煤n el resultado anterior \\(\\hat{\\boldsymbol{\\Theta}}=(\\hat{\\beta}_0=3.533631, \\hat{\\beta}_1=-5.978053, \\hat{\\sigma}_y=4.01157, \\hat{\\sigma}_{b0}=21.50711)^\\top\\) mientras que el vector real de par谩metros es \\(\\boldsymbol{\\Theta}=(\\beta_0=4, \\beta_1=-6, \\sigma_y=4, \\sigma_{b0}=25)^\\top\\). Compare los resultados de la tabla anterior obtenida con la funci贸n lme anterior con los resultados obtenidos con la funci贸n lmer de cap铆tulo 3. 驴Hay alguna similitud? References "],
["ph.html", "5 Pruebas de hip贸tesis 5.1 Prueba de hip贸tesis sobre un par谩metro fijo \\(\\beta_k\\) 5.2 Prueba de hip贸tesis sobre un conjunto de par谩metros fijos (varios \\(\\beta_k\\)) 5.3 Prueba raz贸n de verosimilitud 5.4 Prueba de hip贸tesis sobre componentes de varianza Ejercicios", " 5 Pruebas de hip贸tesis En este cap铆tulo se muestran las pruebas de hip贸tesis para comparar modelo mixtos. 5.1 Prueba de hip贸tesis sobre un par谩metro fijo \\(\\beta_k\\) Si el inter茅s es estudiar \\(H_0: \\beta_k = \\beta_{k0}\\) contra \\(H_0: \\beta_k \\neq \\beta_{k0}\\) se puede usar la prueba de Wald que tiene el siguiente estad铆stico: \\[ t = \\frac{\\hat{\\beta}_k - \\beta_{k0}}{se(\\hat{\\beta}_k)}, \\] donde \\(se(\\hat{\\beta}_k)\\) corresponde al error est谩ndar de la estimaci贸n \\(\\hat{\\beta}_k\\), todo esto disponible en el summary del modelo ajustado. Si \\(H_0\\) es verdadera, \\(t \\sim t_{n-p}\\), siendo \\(n\\) el n煤mero de observaciones y \\(p\\) el n煤mero de efectos fijos estimados (no el n煤mero de variables) en el modelo. 5.2 Prueba de hip贸tesis sobre un conjunto de par谩metros fijos (varios \\(\\beta_k\\)) Luego un ejemplo. 5.3 Prueba raz贸n de verosimilitud Supongamos que queremos estudiar \\(H_0: \\theta \\in \\boldsymbol{\\Theta}_0\\) versus \\(H_A: \\theta \\in \\boldsymbol{\\Theta}\\). La prueba raz贸n de verosimilitud (\\(LR\\)) para \\(H_0\\) est谩 dada por: \\[ LR = -2 \\log \\left( \\frac{ sup_{\\theta \\in \\boldsymbol{\\Theta}_0} L(\\theta)}{ sup_{\\theta \\in \\boldsymbol{\\Theta}} L(\\theta)} \\right) \\] Usualmente la prueba de raz贸n de verosimilitud se expresa en funci贸n de los valores de log-verosimilitud del modelo asi: \\[ LR = -2 ( l(\\Theta_0) - l(\\hat{\\Theta}) ) \\] y el estad铆stico \\(LR \\sim \\chi^2_{k-k_0}\\), donde \\(k\\) es el n煤mero de par谩metros del modelo estimado y \\(k_0\\) el n煤mero de par谩metros del modelo asumiendo \\(H_0\\) verdadera. 5.4 Prueba de hip贸tesis sobre componentes de varianza Las componentes de varianza corresponden a las varianzas y covarianzas del vector de efectos aleatorios. Para hacer pruebas de hip贸tesis sobre las componentes de varianza se tienen dos casos que se explican en las siguientes subsecciones. 5.4.1 Componentes de varianza lejos del borde Luego un ejemplo. 5.4.2 Componentes de varianza en el borde Este caso se presenta cuando la hip贸tesis nula considera que uno o varios par谩metros est谩n justo en el borde del dominio del par谩metro en cuestion. Por ejemplo, si queremos estudiar la inclusi贸n del intercepto aleatorio \\(b_0\\) en un modelo de regresi贸n cl谩sico, tendr铆amos las siguientes hip贸tesis: \\(H_0: \\sigma^2_{b0} = 0\\) versus \\(H_A: \\sigma^2_{b0} &gt; 0\\). Debido a la condici贸n de \\(\\sigma^2_{b0}\\) en \\(H_0\\), se dice que esa componente de varianza est谩 en el borde de su dominio, ya que \\(\\sigma^2_{b0}\\) no puede ser negativa. En este ejemplo particular, rechazar \\(H_0\\) implicar铆a que es apropiado incluir \\(b_0\\) en el modelo. Ejemplo Simule 10 observaciones para cada uno de los 10 grupos siguiendo el siguiente modelo y luego aplique la prueba de raz贸n de verosimilitud para estudiar \\(H_0: \\sigma^2_{b0} = 0\\) versus \\(H_A: \\sigma^2_{b0} &gt; 0\\). \\[\\begin{align*} y_{ij} &amp;\\sim N(\\mu_{ij}, \\sigma^2) \\\\ \\mu_{ij} &amp;= 4 - 6 x_{ij} + b_{0i} \\\\ \\sigma^2_y &amp;= 4 \\\\ b_{0} &amp;\\sim N(0, \\sigma^2_{b0}=4) \\\\ x_{ij} &amp;\\sim U(0, 10) \\end{align*}\\] Soluci贸n La funci贸n gen_dat_b0 de abajo permite simular m observaciones de n grupos con intercepto aleatorio \\(b_0 \\sim N(0, \\sigma^2_{b0})\\). Adicionalmente, es posible elegir los efectos fijos beta0, beta_1 y la varianza sigma de la variable respuesta. gen_dat_b0 &lt;- function(n, m, beta0, beta1, sigmay, sigmab0, seed=NULL) { if(is.null(seed)) seed &lt;- as.integer(runif(1)*2e9) group &lt;- rep(1:n, each=m) set.seed(seed) b0 &lt;- rep(rnorm(n=n, mean=0, sd=sigmab0), each=m) set.seed(seed) x &lt;- runif(n=n*m, min=0, max=10) set.seed(seed) y &lt;- rnorm(n=n*m, mean=beta0 + beta1 * x + b0, sd=sigmay) data.frame(group=group, x=x, y=y) } Vamos ahora a generar 10 observaciones para 10 grupos con intercepto aleatorio con una varianza \\(\\sigma^2_{b0}=2^2=4\\). La semilla se va a fijar en un valor de 1220872376 por cuestiones did谩cticas. datos &lt;- gen_dat_b0(n=10, m=10, beta0=4, beta1=-6, sigmay=2, sigmab0=2, seed=1220872376) head(datos) ## group x y ## 1 1 3.817132 -20.106729 ## 2 1 8.951117 -49.950457 ## 3 1 5.710726 -33.154170 ## 4 1 7.451320 -39.583303 ## 5 1 1.263282 -1.070788 ## 6 1 6.114367 -33.423587 Vamos a ajustar dos modelos, el primero sin incluir \\(b_0\\) y el segundo incluyendo \\(b_0\\). library(nlme) fit1 &lt;- gls(y ~ x, data=datos, method=&quot;REML&quot;) # Igual resultado con lm fit2 &lt;- lme(y ~ x, random = ~ 1| group, data=datos, method=&quot;REML&quot;) Resultados del primer modelo. summary(fit1) ## Generalized least squares fit by REML ## Model: y ~ x ## Data: datos ## AIC BIC logLik ## 475.8248 483.5797 -234.9124 ## ## Coefficients: ## Value Std.Error t-value p-value ## (Intercept) 4.64931 0.5180190 8.97517 0 ## x -6.00175 0.0814173 -73.71588 0 ## ## Correlation: ## (Intr) ## x -0.875 ## ## Standardized residuals: ## Min Q1 Med Q3 Max ## -2.14346496 -0.64999607 -0.06461389 0.60660976 3.48238119 ## ## Residual standard error: 2.50842 ## Degrees of freedom: 100 total; 98 residual Resultados del segundo modelo. summary(fit2) ## Linear mixed-effects model fit by REML ## Data: datos ## AIC BIC logLik ## 474.7777 485.1175 -233.3888 ## ## Random effects: ## Formula: ~1 | group ## (Intercept) Residual ## StdDev: 0.8166724 2.383898 ## ## Fixed effects: y ~ x ## Value Std.Error DF t-value p-value ## (Intercept) 4.640053 0.5652943 89 8.20821 0 ## x -6.000087 0.0795348 89 -75.43973 0 ## Correlation: ## (Intr) ## x -0.783 ## ## Standardized Within-Group Residuals: ## Min Q1 Med Q3 Max ## -2.19536246 -0.56396957 0.05433633 0.61634184 3.29594400 ## ## Number of Observations: 100 ## Number of Groups: 10 Ahora vamos a calcular el estad铆stico y su valor-P. lrt &lt;- -2 * (logLik(fit1) - logLik(fit2)) lrt ## &#39;log Lik.&#39; 3.04712 (df=3) my_p.value &lt;- pchisq(q=3.04712, df=1, lower.tail=FALSE) my_p.value ## [1] 0.08088045 De la salida anterior se tiene que \\(valor-P = 0.0809\\) y como \\(\\alpha=0.05\\), por lo tanto NO hay evidencias para rechazar \\(H_0: \\sigma^2_{b0} = 0\\). 驴No es extra帽a esta conclusi贸n ? Los resultados anteriores se pueden obtener por medio de la funci贸n anova as铆. anova(fit1, fit2) ## Model df AIC BIC logLik Test L.Ratio p-value ## fit1 1 3 475.8248 483.5797 -234.9124 ## fit2 2 4 474.7777 485.1175 -233.3888 1 vs 2 3.04712 0.0809 Ahora vamos a simular 50 conjuntos de datos suponiendo \\(H_0\\) verdadera y luego calcularemos los lrt para as铆 tener la distribuci贸n emp铆rica de los lrt bajo la hip贸tesis nula \\(H_0: \\sigma^2_{b0} = 0\\) verdadera. En un aplicaci贸n se deber铆an generar m谩s conjuntos de pero aqu铆 vamos a usar s贸lo 50 por comodidad. pseudo_gen_dat &lt;- function(nobs, beta0, beta1, sigmay) { group &lt;- datos$group # Aqui la diferencia x &lt;- datos$x # Aqui la diferencia y &lt;- rnorm(n=nobs, mean=beta0 + beta1 * x, sd=sigmay) data.frame(group=group, x=x, y=y) } nrep &lt;- 50 lrts &lt;- numeric(nrep) for (i in 1:nrep) { pseudo_datos &lt;- pseudo_gen_dat(nobs=100, beta0=4.64931, beta1=-6.00175, sigma=2.50842) m1 &lt;- gls(y ~ x, data=pseudo_datos, method=&quot;REML&quot;) m2 &lt;- lme(y ~ x, random = ~ 1| group, data=pseudo_datos, method=&quot;REML&quot;) lrts[i] &lt;- -2 * (logLik(m1) - logLik(m2)) } Dibujando la densidad de los lrt. plot(density(lrts), main=&#39;Densidad emp铆rica de los lrts&#39;) Calculando el valor-P. acumulada &lt;- ecdf(x=lrts) # F(x) para los valores LRT 1 - acumulada(3.04712) # Valor-P ## [1] 0.04 De la salida anterior se tiene que \\(valor-P &lt; \\alpha\\) por lo tanto SI hay evidencias para rechazar \\(H_0: \\sigma^2_{b0} = 0\\). 驴Es esto coherente ahora ? Los resultados anteriores se obtuvieron usando nrep &lt;- 50, en la pr谩ctica ese n煤mero de repeticiones deber铆a subir al menos a 1000. Repita el procedimiento anterior con nrep &lt;- 5000 y observe lo que sucede. El paquete RLRsim (Scheipl and Bolker 2016) tiene la funci贸n exactRLRT que permite extraer el valor-P mediante simulaci贸n. Abajo un ejemplo de como usarla en el presente ejemplo. library(RLRsim) exactRLRT(m=fit2, nsim=1000) ## Warning in model.matrix.default(~m$groups[[n.levels - i + 1]] - 1, contrasts.arg ## = c(&quot;contr.treatment&quot;, : non-list contrasts argument ignored ## ## simulated finite sample distribution of RLRT. ## ## (p-value based on 1000 simulated values) ## ## data: ## RLRT = 3.0471, p-value = 0.039 Consulte la ayuda de la funci贸n exactRLRT para que conozca sus posibilidades y limitaciones. Ejercicios Considere el ejemplo del cap铆tulo 6 sobre el estudio de crecimiento de un grupo de j贸venes. Aplique la prueba raz贸n de verosimilitud para estudiar \\(H_0: \\sigma^2_{b0} = 0\\) versus \\(H_A: \\sigma^2_{b0} &gt; 0\\), es decir, ajuste un modelo lineal simple para explicar la estatura en funci贸n de la edad y luego un modelo mixto con intercepto aleatorio. 驴Cu谩l de los dos modelos parece explicar mejor los datos? Use \\(\\alpha=0.06\\). References "],
["apli-nlme.html", "6 Aplicaci贸n con nlme Ejercicios", " 6 Aplicaci贸n con nlme En este cap铆tulo se mostrar谩 como usar el paquete nlme para la aplicaci贸n de modelos mixtos con la base de datos Oxboys del mismo paquete. A continuaci贸n la base de datos a utilizar. library(nlme) head(Oxboys) ## Grouped Data: height ~ age | Subject ## Subject age height Occasion ## 1 1 -1.0000 140.5 1 ## 2 1 -0.7479 143.4 2 ## 3 1 -0.4630 144.8 3 ## 4 1 -0.1643 147.1 4 ## 5 1 -0.0027 147.7 5 ## 6 1 0.2466 150.2 6 Esta base de datos sobre crecimiento contiene la informaci贸n sobre altura (heigth), edad estandarizada (age) de un grupo de 26 j贸venes. Como la base de datos Oxboys es de la clase groupedData, es posible aplicar un plot directamente y el resultado se muestra continuaci贸n. plot(Oxboys) Es posible convertir un data.frame para que tenga la clase groupedData, consulte la ayuda de la funci贸n groupedData del paquete nlme para m谩s detalles. De la figura anterior vemos que las curvas de crecimiento inician a diferente altura (intercepto) y que la pendiente del crecimiento no son todas iguales, por ejemplo, el individuo 21 creci贸 m谩s r谩pido que el individuo 3. Esto nos hace pensar que un modelo con intercepto y pendiente aleatoria podr铆an ser adecuados para modelar el crecimiento. En las siguientes ecuaciones se resume el modelo matem谩tico que interesa en esta situaci贸n. \\[\\begin{align*} Height_{ij} &amp;\\sim N(\\mu_{ij}, \\sigma^2_{Heigth}) \\\\ \\mu_{ij} &amp;= \\beta_0 + \\beta_1 Age_{ij} + b_{0i} + b_{1i} Age_{ij} \\\\ \\left ( \\begin{matrix} b_{0} \\\\ b_{1} \\end{matrix} \\right ) &amp;\\sim N\\left ( \\left ( \\begin{matrix} 0 \\\\ 0 \\end{matrix} \\right ), \\left ( \\begin{matrix} \\sigma^2_{b0} &amp; \\sigma_{b01} \\\\ \\sigma_{b01} &amp; \\sigma^2_{b1} \\end{matrix} \\right ) \\right ) \\end{align*}\\] El vector de par谩metros para este modelo ser铆a \\(\\boldsymbol{\\Theta}=(\\beta_0, \\beta_1, \\sigma_y, \\sigma_{b0}, \\sigma_{b1}, \\sigma_{b0b1})^\\top\\). Para ajustar este modelo a los datos con el paquete nlme podemos usar el siguiente c贸digo. fit &lt;- lme(height ~ age, random= ~ 1 + age | Subject, data=Oxboys, method=&quot;REML&quot;) Para obtener la tabla de resumen usamos: summary(fit) ## Linear mixed-effects model fit by REML ## Data: Oxboys ## AIC BIC logLik ## 736.091 756.7714 -362.0455 ## ## Random effects: ## Formula: ~1 + age | Subject ## Structure: General positive-definite, Log-Cholesky parametrization ## StdDev Corr ## (Intercept) 8.081077 (Intr) ## age 1.680717 0.641 ## Residual 0.659889 ## ## Fixed effects: height ~ age ## Value Std.Error DF t-value p-value ## (Intercept) 149.37175 1.5854173 207 94.21605 0 ## age 6.52547 0.3363003 207 19.40370 0 ## Correlation: ## (Intr) ## age 0.628 ## ## Standardized Within-Group Residuals: ## Min Q1 Med Q3 Max ## -2.65092109 -0.57493341 -0.02842894 0.59604254 2.60496077 ## ## Number of Observations: 234 ## Number of Groups: 26 De la salida anterior se obtiene que \\(\\hat{\\boldsymbol{\\Theta}}=(\\hat{\\beta}_0=149.37, \\hat{\\beta}_1=6.53, \\hat{\\sigma}_y=0.66, \\hat{\\sigma}_{b0}=8.08, \\hat{\\sigma}_{b1}=1.68, \\hat{\\sigma}_{b0b1}=8.71)^\\top\\). La estimaci贸n \\(\\hat{\\sigma}_{b0b1}\\) no aparece directamente en el summary pero se obtiene utilizando la ecuaci贸n \\(Cor=Cov/(\\sigma_1 \\sigma_2)\\) que relaciona correlaci贸n, covarianza y desviaciones de los efectos aleatorios. Usando la informaci贸n anterior se puede escribir el modelo ajustado de la siguiente manera. \\[\\begin{align*} Height_{ij} &amp;\\sim N(\\hat{\\mu}_{ij}, 0.66^2) \\\\ \\hat{\\mu}_{ij} &amp;= 149.37 + 6.53 Age_{ij} + b_{0i} + b_{1i} Age_{ij} \\\\ \\left ( \\begin{matrix} b_{0} \\\\ b_{1} \\end{matrix} \\right ) &amp;\\sim N\\left ( \\left ( \\begin{matrix} 0 \\\\ 0 \\end{matrix} \\right ), \\left ( \\begin{matrix} 8.08^2 &amp; 8.71 \\\\ 8.71 &amp; 1.68^2 \\end{matrix} \\right ) \\right ). \\end{align*}\\] Los elementos \\(b_{0i}\\) y \\(b_{1i}\\) se deben substituir por sus respectivas predicciones \\(\\tilde{b}_{0i}\\) y \\(\\tilde{b}_{1i}\\) y se pueden obtener del modelo ajustado as铆: ranef(fit) ## (Intercept) age ## 10 -19.0972476 -2.78657472 ## 26 -11.3675996 -0.97474075 ## 25 -10.1595528 -2.42702035 ## 9 -11.2213331 -0.58069044 ## 2 -6.5096277 -1.07136271 ## 6 -2.5902388 -2.41771656 ## 7 -3.2473132 -1.46379286 ## 17 -6.3744842 1.89443713 ## 16 -1.8344703 -1.86707015 ## 15 -5.0856366 0.51526141 ## 8 -1.0776201 -0.06615528 ## 20 2.0850836 -1.99239802 ## 1 -1.2464285 0.59919226 ## 18 1.8031920 -0.51486646 ## 5 2.0531168 -0.24308081 ## 23 1.6937341 0.63140824 ## 11 0.6839704 1.85733185 ## 21 1.1525543 0.91894343 ## 3 6.2613001 -1.58181075 ## 24 3.7645669 0.25652772 ## 22 5.1957592 1.50551719 ## 12 7.4308033 0.52297645 ## 13 6.7004368 1.89758007 ## 14 10.0986013 2.09367207 ## 19 15.1957040 2.50720025 ## 4 15.6927297 2.78723179 Los valores de los efectos fijos estimados se pueden obtener as铆: fixef(fit) ## (Intercept) age ## 149.371753 6.525469 Usando la informaci贸n de los efectos fijo y aleatorios obtenidos antes, es posible escribir la ecuaci贸n del modelo para cada individuo. Los efectos fijos estimados fueron \\(\\hat{\\beta}_0 \\approx 149.37\\) y \\(\\hat{\\beta}_1\\approx 6.53\\). Para el sujeto # 10 se obtuvo \\(\\tilde{b}_{0, i=10} \\approx -19.10\\) y \\(\\tilde{b}_{1, i=10} \\approx -2.79\\), as铆 la media del individuo # 10 se calcula as铆: \\[\\begin{align*} \\hat{\\mu}_{i=10, j} &amp;= \\hat{\\beta}_0 + \\hat{\\beta}_0 \\, Age_{i=10, j} + \\tilde{b}_{0, i=10} + \\tilde{b}_{1, i=10} \\, Age_{i=10, j} \\\\ \\hat{\\mu}_{i=10, j} &amp;= 149.37 + 6.53 \\, Age_{i=10, j} - 19.10 - 2.79 \\, Age_{i=10, j} \\\\ \\hat{\\mu}_{i=10, j} &amp;= 130.27 + 3.74 \\, Age_{i=10, j} \\end{align*}\\] Lo anterior se puede resumir en el siguiente modelo. \\[\\begin{align*} Height_{i=10, j} &amp;\\sim N(\\hat{\\mu}_{i=10, j}, \\hat{\\sigma}^2_{Height}) \\\\ \\hat{\\mu}_{i=10, j} &amp;= 130.27 + 3.74 \\, Age_{i=10, j} \\\\ \\hat{\\sigma}_{Height} &amp;= 0.66 \\end{align*}\\] La expresi贸n anterior para cada individuo con los efectos finales (fijos y aleatorios) se puede obtener con R as铆: coef(fit) ## (Intercept) age ## 10 130.2745 3.738894 ## 26 138.0042 5.550728 ## 25 139.2122 4.098448 ## 9 138.1504 5.944778 ## 2 142.8621 5.454106 ## 6 146.7815 4.107752 ## 7 146.1244 5.061676 ## 17 142.9973 8.419906 ## 16 147.5373 4.658399 ## 15 144.2861 7.040730 ## 8 148.2941 6.459313 ## 20 151.4568 4.533071 ## 1 148.1253 7.124661 ## 18 151.1749 6.010602 ## 5 151.4249 6.282388 ## 23 151.0655 7.156877 ## 11 150.0557 8.382801 ## 21 150.5243 7.444412 ## 3 155.6331 4.943658 ## 24 153.1363 6.781996 ## 22 154.5675 8.030986 ## 12 156.8026 7.048445 ## 13 156.0722 8.423049 ## 14 159.4704 8.619141 ## 19 164.5675 9.032669 ## 4 165.0645 9.312700 En la presente aplicaci贸n es posible incluir la recta de regresi贸n para cada individuo al diagrama de dispersi贸n original. El c贸digo de R para obtener esto es el siguiente. library(lattice) xyplot(height ~ age | Subject, data=Oxboys, fit=fit, strip=strip.custom(bg=&quot;white&quot;), pch=16, cex=0.7, col=&#39;indianred1&#39;, panel = function(x, y, ..., fit, subscripts) { panel.xyplot(x, y, ...) ypred &lt;- fitted(fit)[subscripts] panel.lines(x, ypred, col=&quot;deepskyblue3&quot;, lwd=1) }, ylab=&quot;Height (cm)&quot;, xlab=&quot;Centered age&quot;) En la figura anterior se tienen las observaciones (crecimiento) representado por los puntos rojos, adicionalmente, aparece una recta de color azul que representa la recta de regresi贸n para cada individuo. De la figura se observa que la linea logra explicar la evoluci贸n del crecimiento para cada individuo. Ejercicios Repita el ejercicio anterior considerando un modelo s贸lo con intercepto aleatorio. Dibuje las rectas de regresi贸n para cada individuo. 驴Qu茅 opina de este modelo? Repita el ejercicio anterior considerando un modelo s贸lo con pendiente aleatoria. Dibuje las rectas de regresi贸n para cada individuo. 驴Qu茅 opina de este modelo? Estime la estatura para el individuo # 3 cuando su edad centrada sea de 1.1. Replique los ejemplo de este documento. "],
["apli-lme4.html", "7 Aplicaci贸n con lme4 Ejercicios", " 7 Aplicaci贸n con lme4 En este cap铆tulo se mostrar谩 como usar el paquete lme4 para la aplicaci贸n de modelos mixtos con la base de datos sleepstudy del mismo paquete. A continuaci贸n la base de datos a utilizar. library(lme4) head(sleepstudy) ## Reaction Days Subject ## 1 249.5600 0 308 ## 2 258.7047 1 308 ## 3 250.8006 2 308 ## 4 321.4398 3 308 ## 5 356.8519 4 308 ## 6 414.6901 5 308 Esta base de datos sobre el tiempo de reacci贸n promedio por d铆a para un conjunto de individuos, en un estudio de privaci贸n del sue帽o, contiene la informaci贸n sobre el tiempo de reacci贸n promedio (Reaction), el n煤mero de d铆as de privaci贸n del sue帽o (Days), donde el d铆a 0 corresponde al d铆a en el que los indiviuos ten铆an su cantidad normal de sue帽o, y el n煤mero del individuo (en total 18) sobre el que se realiz贸 la observaci贸n (Subject). A partir del d铆a 0, hubo una restricci贸n en cada individuo a 3 horas de sue帽o por noche. library(ggplot2) ggplot(data = sleepstudy, aes(x = Days, y = Reaction, color = Subject)) + geom_point() + theme_bw() + facet_wrap(~ Subject) + theme(legend.position = &quot;none&quot;) De la figura anterior vemos que el tiempo de reacci贸n promedio, tanto en el d铆a 0 como en los siguientes d铆as de prueba (del d铆a 1 al d铆a 9), son distintos en cada uno de los individuos. Esta situaci贸n conlleva a probar la hip贸tesis de que el tiempo de reacci贸n promedio en una serie de pruebas var铆a seg煤n los individuos. Esto es, ajustar un modelo donde el intercepto y la pendiente se consideran como efectos aleatorios. Un modelo lineal mixto que describe la anterior situaci贸n se puede escribir como: \\[\\begin{align*} Reaction_{ij} &amp;\\sim N(\\mu_{ij}, \\sigma^2_{Reaction}) \\\\ \\mu_{ij} &amp;= \\beta_0 + \\beta_1 Days_{ij} + b_{0i} + b_{1i} Days_{ij} \\\\ \\left ( \\begin{matrix} b_{0} \\\\ b_{1} \\end{matrix} \\right ) &amp;\\sim N\\left ( \\left [ \\begin{matrix} 0 \\\\ 0 \\end{matrix} \\right ], \\left [ \\begin{matrix} \\sigma^2_{b0} &amp; \\sigma_{b01} \\\\ \\sigma_{b01} &amp; \\sigma^2_{b1} \\end{matrix} \\right ] \\right ) \\end{align*}\\] Aqu铆, los individuos (\\(i\\)) var铆an en el tiempo de reacci贸n promedio tanto en su intercepto (\\(b_{0i}\\)) como en su pendiente (\\(b_{1i}\\)), que en conjunto componen la varianza total en dicho tiempo atribuible a la variaci贸n entre individuos. Esta contribuci贸n individual se cuantifica usando un modelo de intercepto y pendiente aleatoria con distribuci贸n normal (\\(N\\)). La variaci贸n entre individuos en intercepto y pendiente es \\(\\sigma^2_{b0}\\) y \\(\\sigma虏_{b1}\\), respectivamente. La covarianza entre el intercepto y la pendiente esta dada por \\(\\sigma_{b01}\\). El vector de par谩metros para este modelo ser铆a \\(\\boldsymbol{\\Theta}=(\\beta_0, \\beta_1, \\sigma_y, \\sigma_{b0}, \\sigma_{b1}, \\sigma_{b0b1})^\\top\\). Para ajustar el modelo de intercepto y pendiente aleatoria planteado usando el paquete lme4 podemos usar el siguiente c贸digo: fit &lt;- lmer(Reaction ~ Days + (Days | Subject), REML = TRUE, data = sleepstudy) Para obtener la tabla de resumen usamos: summary(fit) ## Linear mixed model fit by REML [&#39;lmerMod&#39;] ## Formula: Reaction ~ Days + (Days | Subject) ## Data: sleepstudy ## ## REML criterion at convergence: 1743.6 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -3.9536 -0.4634 0.0231 0.4633 5.1793 ## ## Random effects: ## Groups Name Variance Std.Dev. Corr ## Subject (Intercept) 611.90 24.737 ## Days 35.08 5.923 0.07 ## Residual 654.94 25.592 ## Number of obs: 180, groups: Subject, 18 ## ## Fixed effects: ## Estimate Std. Error t value ## (Intercept) 251.405 6.824 36.843 ## Days 10.467 1.546 6.771 ## ## Correlation of Fixed Effects: ## (Intr) ## Days -0.138 De la salida anterior se obtienen los siguientes par谩metros (\\(\\Theta\\)): \\(\\Theta\\) \\(\\beta_{0}\\) 251.40 \\(\\beta_{1}\\) 10.47 \\(\\sigma_{y}\\) 25.59 \\(\\sigma_{b0}\\) 24.74 \\(\\sigma_{b1}\\) 5.92 \\(\\sigma_{b0b1}\\) 10.25 * El 煤timo par谩metro estimado se obtiene utilizando la ecuaci贸n de correlaci贸n (\\(\\rho\\)) que relaciona la covarianza y desviaciones de los efectos aleatorios: \\(\\rho_{b0b1} = \\sigma_{b0b1}/(\\sigma_{b0} * \\sigma_{b1})\\). Usando la informaci贸n anterior se puede escribir el modelo ajustado de la siguiente manera: \\[\\begin{align*} Reaction_{ij} &amp;\\sim N(\\hat{\\mu}_{ij}, 25.59^2) \\\\ \\hat{\\mu}_{ij} &amp;= 251.40 + 10.47 Days_{ij} + b_{0i} + b_{1i} Days_{ij} \\\\ \\left ( \\begin{matrix} b_{0} \\\\ b_{1} \\end{matrix} \\right ) &amp;\\sim N\\left ( \\left [ \\begin{matrix} 0 \\\\ 0 \\end{matrix} \\right ], \\left [ \\begin{matrix} 24.74^2 &amp; 10.25 \\\\ 10.25 &amp; 5.92^2 \\end{matrix} \\right ] \\right ) \\end{align*}\\] Los elementos \\(b_{0i}\\) y \\(b_{1i}\\) se deben substituir por sus respectivas predicciones \\(\\tilde{b}_{0i}\\) y \\(\\tilde{b}_{1i}\\) y se pueden obtener del modelo ajustado de esta forma: ranef(fit) ## $Subject ## (Intercept) Days ## 308 2.2575329 9.1992737 ## 309 -40.3942719 -8.6205161 ## 310 -38.9563542 -5.4495796 ## 330 23.6888704 -4.8141448 ## 331 22.2585409 -3.0696766 ## 332 9.0387625 -0.2720535 ## 333 16.8389833 -0.2233978 ## 334 -7.2320462 1.0745075 ## 335 -0.3326901 -10.7524799 ## 337 34.8865253 8.6290208 ## 349 -25.2080191 1.1730997 ## 350 -13.0694180 6.6142185 ## 351 4.5777099 -3.0152825 ## 352 20.8614523 3.5364062 ## 369 3.2750882 0.8722876 ## 370 -25.6110745 4.8222518 ## 371 0.8070591 -0.9881730 ## 372 12.3133491 1.2842380 ## ## with conditional variances for &quot;Subject&quot; Y los valores de los efectos fijos estimados se pueden obtener as铆: fixef(fit) ## (Intercept) Days ## 251.40510 10.46729 Con base en la informaci贸n anterior de efectos aleatorios y fijos, es posible escribir la ecuaci贸n del modelo para cada individuo. Para esto, se debe considerar los efectos fijos estimados (\\(\\hat{\\beta}_0 \\approx 251.40\\) y \\(\\hat{\\beta}_1\\approx 10.47\\)) y los efectos aleatorios de cada uno de los individuos (por ejemplo para el individuo 308, \\(\\tilde{b}_{0, i=308} \\approx 2.26\\) y \\(\\tilde{b}_{1, i=308} \\approx 9.20\\)). As铆, el valor medio del individuo 308 se calcula como: \\[\\begin{align*} \\hat{\\mu}_{i=308, j} &amp;= \\hat{\\beta}_0 + \\hat{\\beta}_0 \\, Days_{i=308, j} + \\tilde{b}_{0, i=308} + \\tilde{b}_{1, i=308} \\, Days_{i=308, j} \\\\ \\hat{\\mu}_{i=308, j} &amp;= 251.40 + 10.47 \\, Days_{i=308, j} 2.26 + 9.20 \\, Days_{i=308, j} \\\\ \\hat{\\mu}_{i=308, j} &amp;= 253.66 + 19.67 \\, Days_{i=308, j} \\end{align*}\\] Lo anterior se puede resumir en el siguiente modelo. \\[\\begin{align*} Reaction_{i=308, j} &amp;\\sim N(\\hat{\\mu}_{i=308, j}, \\hat{\\sigma}^2_{Reaction}) \\\\ \\hat{\\mu}_{i=308, j} &amp;= 253.66 + 19.67 \\, Days_{i=308, j} \\\\ \\hat{\\sigma}_{Reaction} &amp;= 25.59 \\end{align*}\\] Los efectos fijos y aleatorios de la expresi贸n anterior para cada uno de los individuos se pueden obtener con R de la siguiente forma: coef(fit) ## $Subject ## (Intercept) Days ## 308 253.6626 19.6665597 ## 309 211.0108 1.8467699 ## 310 212.4488 5.0177063 ## 330 275.0940 5.6531411 ## 331 273.6636 7.3976093 ## 332 260.4439 10.1952325 ## 333 268.2441 10.2438881 ## 334 244.1731 11.5417935 ## 335 251.0724 -0.2851939 ## 337 286.2916 19.0963068 ## 349 226.1971 11.6403856 ## 350 238.3357 17.0815045 ## 351 255.9828 7.4520035 ## 352 272.2666 14.0036922 ## 369 254.6802 11.3395736 ## 370 225.7940 15.2895377 ## 371 252.2122 9.4791130 ## 372 263.7185 11.7515240 ## ## attr(,&quot;class&quot;) ## [1] &quot;coef.mer&quot; A continuaci贸n podras observar el diagrama de dispersi贸n mostrado al inicio de este capitulo, agregandole a la misma la recta de regresi贸n para cada individuo. El c贸digo de R para obtener esto se presenta a continuaci贸n: fit &lt;- lmer(Reaction ~ Days + (Days | Subject), REML = TRUE, data = sleepstudy) sleepstudy$pred_inter_pend_aleatorio &lt;- predict(fit) ggplot(data = sleepstudy, aes(x = Days, y = pred_inter_pend_aleatorio, color = Subject)) + geom_line() + geom_point(aes(x = Days, y = Reaction, color = Subject)) + geom_abline(intercept = 251.40, slope = 10.47, color = &quot;black&quot;, linetype = &quot;dashed&quot;, size = 0.5) + theme_bw() + facet_wrap(~ Subject) + theme(legend.position = &quot;none&quot;) La figura anterior corresponde a un modelo de intercepto y pendiente aleatoria, en el que se permite que tanto los interceptos como las pendientes var铆en seg煤n los individuos. Las l铆neas continuas corresponde a la recta de regresi贸n ajustada a los datos. Los puntos representan las observaciones (tiempo de reacci贸n promedio por d铆a) medidas en cada uno de los individuos. La l铆nea negra discontinua representa el valor medio global de la distribuci贸n de los efectos aleatorios. A continuaci贸n podra observar distintas figuras donde se ajustaron cuatro modelos distintos, entre ellos el modelo mixto con intercepto y pendiente aleatoria ya evaluado aqu铆 (Figura 4). Con base en estas figuras, se plantean los ejercicios posteriores a las mismas figuras: Ejercicios Ajuste el modelo con intercepto aleatorio mostrado en la anterior Figura 2. 驴Qu茅 opina de este modelo? Ajuste el modelo con pendiente aleatoria presentada en la anterior Figura 3. 驴Qu茅 opina de este modelo? Ajustar solo un intercepto aleatorio permite que los individuos var铆en asumiendo que los mismos tienen una pendiente com煤n (Figura 2). Al ajustar solo una pendiente aleatoria (Figura 3) permite que la pendiente de un predictor var铆e en funci贸n de los individuos (la variable de agrupaci贸n). Con base esto y teniendo en cuenta el modelo de intercepto y pendiente aleatoria (Figura 4), eval煤e cual de estos estos modelos permite un mejor ajuste de los datos presentados en la base de datos sleepstudy del paquete lme4. "],
["references.html", "References", " References "]
]
