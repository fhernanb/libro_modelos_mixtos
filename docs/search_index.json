[
["ph.html", "5 Pruebas de hip√≥tesis 5.1 Prueba raz√≥n de verosimilitud 5.2 Prueba de Wald 5.3 Prueba de hip√≥tesis sobre los efectos fijos 5.4 Prueba de hip√≥tesis sobre componentes de varianza Ejercicios", " 5 Pruebas de hip√≥tesis En este cap√≠tulo se muestran las pruebas de hip√≥tesis para comparar modelo mixtos. 5.1 Prueba raz√≥n de verosimilitud Supongamos que queremos estudiar \\(H_0: \\theta \\in \\boldsymbol{\\Theta}_0\\) versus \\(H_A: \\theta \\in \\boldsymbol{\\Theta}\\). La prueba raz√≥n de verosimilitud (\\(LR\\)) para \\(H_0\\) est√° dada por: \\[ LR = -2 \\log \\left( \\frac{ sup_{\\theta \\in \\boldsymbol{\\Theta}_0} L(\\theta)}{ sup_{\\theta \\in \\boldsymbol{\\Theta}} L(\\theta)} \\right) \\] Usualmente la prueba de raz√≥n de verosimilitud se expresa en funci√≥n de los valores de log-verosimilitud del modelo asi: \\[ LR = -2 ( l(\\Theta_0) - l(\\hat{\\Theta}) ) \\] y el estad√≠stico \\(LR \\sim \\chi^2_{k-k_0}\\), donde \\(k\\) es el n√∫mero de par√°metros del modelo estimado y \\(k_0\\) el n√∫mero de par√°metros del modelo asumiendo \\(H_0\\) verdadera. 5.2 Prueba de Wald Si el inter√©s es estudiar \\(H_0: \\beta_k = \\beta_{k0}\\) contra \\(H_A: \\beta_k \\neq \\beta_{k0}\\) se puede usar la prueba de Wald que tiene el siguiente estad√≠stico: \\[ t = \\frac{\\hat{\\beta}_k - \\beta_{k0}}{se(\\hat{\\beta}_k)}, \\] donde \\(se(\\hat{\\beta}_k)\\) corresponde al error est√°ndar de la estimaci√≥n \\(\\hat{\\beta}_k\\), todo esto disponible en el summary del modelo ajustado. Si \\(H_0\\) es verdadera, \\(t \\sim t_{n-p}\\), siendo \\(n\\) el n√∫mero de observaciones y \\(p\\) el n√∫mero de efectos fijos estimados (no el n√∫mero de variables) en el modelo. 5.3 Prueba de hip√≥tesis sobre los efectos fijos La prueba raz√≥n de verosimilitud puede ser usada para comparar modelos ajustados por el m√©todo ML y que difieran en su estructura de efectos fijos, pero con la mismas componentes de varianza. Los valores-P de la prueba pueden ser anticonservativos, es decir, m√°s peque√±os de lo normal y por lo tanto se podr√≠a rechazar \\(H_0\\) m√°s f√°cilmente (Pinheiro and Bates 2000). En lugar de usar la distribuci√≥n \\(\\chi^2\\) para el estad√≠stico de la prueba raz√≥n de verosimilitud, se recomienda usar la distribuci√≥n emp√≠rica del estad√≠stico, obtenida al ajustar los modelos nulo y alternativo con m√∫ltiples conjuntos de datos simulados (Galecki and Burzykowski 2012). Ejemplo La base de datos ChickWeight contiene informaci√≥n sobre el peso de un grupo de pollos versus el tiempo bajo diferentes dietas. Abajo una ilustraci√≥n de los datos. library(ggplot2) ggplot(data = ChickWeight, aes(x = Time, y = weight, color = Diet)) + geom_point() + theme_bw() + facet_wrap(~ Chick) El objetivo es comparar los siguientes dos modelos. Modelo 1 \\[\\begin{align*} Weight_{ij} &amp;\\sim N(\\mu_{ij}, \\sigma^2_{weight}) \\\\ \\mu_{ij} &amp;= \\beta_0 + \\beta_1 tiempo_{ij} + b_{0i} \\\\ b_{0} &amp;\\sim N(0, \\sigma^2_{b0}) \\end{align*}\\] Modelo 2 \\[\\begin{align*} Weight_{ij} &amp;\\sim N(\\mu_{ij}, \\sigma^2_{weight}) \\\\ \\mu_{ij} &amp;= \\beta_0 + \\beta_1 tiempo_{ij} + \\beta_2 dieta2_{i} + \\beta_3 dieta3_{i} + \\beta_4 dieta4_{i} + b_{0i} \\\\ b_{0} &amp;\\sim N(0, \\sigma^2_{b0}) \\end{align*}\\] Soluci√≥n El problema de este ejercicio se puede resumir con \\(H_0:\\) la variable Dieta no aporta al modelo, versus, \\(H_A:\\) la variable Dieta si aporta al modelo. Para ajustar ambos modelos se usa el siguiente c√≥digo. library(nlme) mod1 &lt;- lme(weight ~ Time, data = ChickWeight, random = ~ 1 | Chick, method=&#39;ML&#39;) mod2 &lt;- lme(weight ~ Time + Diet, data = ChickWeight, random = ~ 1 | Chick, method=&#39;ML&#39;) Para calcular la prueba raz√≥n de verosimilitud se usa el siguiente c√≥digo. lrt &lt;- -2 * (logLik(mod1) - logLik(mod2)) lrt ## &#39;log Lik.&#39; 17.14349 (df=4) pchisq(q=lrt, df=7-4, lower.tail=FALSE) ## &#39;log Lik.&#39; 0.000660304 (df=4) De la salida anterior se tiene que el valor-P = 0.000660304 y menor que cualquier \\(\\alpha\\). Sin embargo, como este valor-P puede ser ‚Äúanticonservativo‚Äù (m√°s peque√±o de lo que deber√≠a ser), es mejor no sacar conclusiones apresuradas y rechazar \\(H_0\\). La prueba de verosimilitud se puede obtener tambi√©n as√≠: anova(mod1, mod2) ## Model df AIC BIC logLik Test L.Ratio p-value ## mod1 1 4 5630.344 5647.782 -2811.172 ## mod2 2 7 5619.201 5649.718 -2802.600 1 vs 2 17.14349 7e-04 Para obtener un valor-P m√°s acorde al problema podemos usar simulaci√≥n. La funci√≥n simulate.lme simula datos de modelos especificados por medio de los argumentos object y m2, ajusta los modelos, y entrega los valores de log-verosimilitud, con los se puede obtener el estad√≠stico de la prueba de raz√≥n de verosimilitud. A continuaci√≥n el c√≥digo para obtener el valor-P con simulaci√≥n. simul &lt;- simulate.lme(object=mod1, m2=mod2, method = &#39;ML&#39;, nsim=1000) lrts_nlme &lt;- -2 * (simul$null$ML[, 2] - simul$alt$ML[, 2]) acumulada1 &lt;- ecdf(x=lrts_nlme) # F(x) para los valores LRT 1 - acumulada1(17.14349) ## [1] 0.001 De la salida anterior se tiene que el valor-P = 0.001 y ya no es tan peque√±o como el valor-P anterior. Por esta raz√≥n hay evidencias rechazar \\(H_0\\) y por lo tanto la variable Dieta si aporta al modelo. Ejemplo La base de datos Orthodont contiene informaci√≥n sobre una medida de distancia intrafacial para j√≥venes sometidos a ortodoncia. data(Orthodont, package=&quot;nlme&quot;) library(ggplot2) ggplot(data = Orthodont, aes(x = age, y = distance, color = Sex)) + geom_point() + theme_bw() + facet_wrap(~ Subject) El objetivo es comparar los siguientes dos modelos. Modelo 1 \\[\\begin{align*} Distance_{ij} &amp;\\sim N(\\mu_{ij}, \\sigma^2_{distance}) \\\\ \\mu_{ij} &amp;= \\beta_0 + \\beta_1 age_{ij} + b_{0i} \\\\ b_{0} &amp;\\sim N(0, \\sigma^2_{b0}) \\end{align*}\\] Modelo 2 \\[\\begin{align*} Distance_{ij} &amp;\\sim N(\\mu_{ij}, \\sigma^2_{distance}) \\\\ \\mu_{ij} &amp;= \\beta_0 + \\beta_1 age_{ij} + \\beta_2 SexFemale_i + b_{0i} \\\\ b_{0} &amp;\\sim N(0, \\sigma^2_{b0}) \\end{align*}\\] Soluci√≥n El problema de este ejercicio se puede resumir con \\(H_0:\\) la variable Sexo no aporta al modelo, versus, \\(H_A:\\) la variable Sexo si aporta al modelo. Para ajustar ambos modelos se usa el siguiente c√≥digo. library(lme4) ## Loading required package: Matrix ## ## Attaching package: &#39;lme4&#39; ## The following object is masked from &#39;package:nlme&#39;: ## ## lmList mod1 &lt;- lmer(distance ~ age + (1|Subject), data=Orthodont, REML=FALSE) mod2 &lt;- lmer(distance ~ age + Sex + (1|Subject), data=Orthodont, REML=FALSE) Para calcular la prueba raz√≥n de verosimilitud se usa el siguiente c√≥digo. lrt &lt;- -2 * (logLik(mod1) - logLik(mod2)) lrt ## &#39;log Lik.&#39; 8.533057 (df=4) pchisq(q=lrt, df=5-4, lower.tail=FALSE) ## &#39;log Lik.&#39; 0.003487534 (df=4) De la salida anterior se tiene que el valor-P = 0.003487534 y menor que cualquier \\(\\alpha\\). Sin embargo, como este valor-P puede ser ‚Äúanticonservativo‚Äù (m√°s peque√±o de lo que deber√≠a ser), es mejor no sacar conclusiones apresuradas y rechazar \\(H_0\\). La prueba de verosimilitud se puede obtener tambi√©n as√≠: anova(mod1, mod2) ## Data: Orthodont ## Models: ## mod1: distance ~ age + (1 | Subject) ## mod2: distance ~ age + Sex + (1 | Subject) ## Df AIC BIC logLik deviance Chisq Chi Df Pr(&gt;Chisq) ## mod1 4 451.39 462.12 -221.69 443.39 ## mod2 5 444.86 458.27 -217.43 434.86 8.5331 1 0.003488 ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Para obtener un valor-P m√°s acorde al problema podemos usar simulaci√≥n. La funci√≥n simulate.lme simula respuestas \\(y_{ij}\\) del modelo dado. A continuaci√≥n el c√≥digo para obtener el valor-P con simulaci√≥n (¬°tarda varios minutos!). nrep &lt;- 5000 lrts_lme4 &lt;- numeric(nrep) for (i in 1:nrep) { new_y_h0 &lt;- simulate(mod1) # Asumiendo H0 verdadera Orthodont$new_y_h0 &lt;- new_y_h0$sim_1 aux0 &lt;- lmer(new_y_h0 ~ age + (1|Subject), data=Orthodont, REML=FALSE) aux1 &lt;- lmer(new_y_h0 ~ age + Sex + (1|Subject), data=Orthodont, REML=FALSE) lrts_lme4[i] &lt;- -2 * (logLik(aux0) - logLik(aux1)) } acumulada2 &lt;- ecdf(x=lrts_lme4) # F(x) para los valores LRT 1 - acumulada1(8.533057) ## [1] 0.005 De la salida anterior se tiene que el valor-P = 0.005 y ya no es tan peque√±o como el valor-P anterior. Por esta raz√≥n hay evidencias rechazar \\(H_0\\) y por lo tanto la variable Sexo si aporta al modelo. 5.4 Prueba de hip√≥tesis sobre componentes de varianza Las componentes de varianza corresponden a las varianzas y covarianzas del vector de efectos aleatorios. La prueba raz√≥n de verosimilitud puede ser usada para comparar modelos ajustados por el m√©todo REML y que difieran en sus componentes de varianza, pero que tenga igual estructura de efectos fijos. Para hacer pruebas de hip√≥tesis sobre las componentes de varianza se tienen dos casos que se explican en las siguientes subsecciones. 5.4.1 Componentes de varianza lejos del borde Luego un ejemplo. 5.4.2 Componentes de varianza en el borde Este caso se presenta cuando la hip√≥tesis nula considera que uno o varios par√°metros est√°n justo en el borde del dominio del par√°metro en cuestion. Por ejemplo, si queremos estudiar la inclusi√≥n del intercepto aleatorio \\(b_0\\) en un modelo de regresi√≥n cl√°sico, tendr√≠amos las siguientes hip√≥tesis: \\(H_0: \\sigma^2_{b0} = 0\\) versus \\(H_A: \\sigma^2_{b0} &gt; 0\\). Debido a la condici√≥n de \\(\\sigma^2_{b0}\\) en \\(H_0\\), se dice que esa componente de varianza est√° en el borde de su dominio, ya que \\(\\sigma^2_{b0}\\) no puede ser negativa. En este ejemplo particular, rechazar \\(H_0\\) implicar√≠a que es apropiado incluir \\(b_0\\) en el modelo. En el caso de componentes de varianza cerca de la frontera la distribuci√≥n del estad√≠stico raz√≥n de verosimilitud no es una \\(\\chi^2\\) (Galecki and Burzykowski 2012). En la secci√≥n 6.3.4 de (Verbeke and Molenberghs 2000) se listan 4 casos en los cuales se tienen mezclas de distribuciones para calcular el valor-P de la prueba raz√≥n de verosimilitud. Los 4 casos son los siguientes: Sin efecto aleatorio versus 1 efecto aleatorio: en este caso lo que interesa es \\(H_0: \\sigma^2_{b} = 0\\) versus \\(H_0: \\sigma^2_{b} &gt; 0\\), la distribuci√≥n asint√≥tica del estad√≠stico de razon de verosimilitud es una mezcla de \\(\\chi^2_1\\) y \\(\\chi^2_0\\) con pesos iguales a 0.5. 1 efecto aleatorio versus 2 efectos aleatorios: en este caso lo que interesa es \\(H_0: \\boldsymbol{D} = \\begin{pmatrix} d_{11} &amp; 0 \\\\ 0 &amp; 0 \\end{pmatrix}\\) versus \\(H_0: \\boldsymbol{D} \\neq \\boldsymbol{0}\\) para un \\(d_{11}&gt;0\\), en este caso la distrubuci√≥n asint√≥tica del estad√≠stico raz√≥n de verosimilitud es una mezcla de \\(\\chi^2_2\\) y \\(\\chi^2_1\\) con pesos iguales a 0.5. \\(q\\) efectos aleatorios versus \\(q+1\\) efectos aleatorios: en este caso lo que interesa es \\(H_0: \\boldsymbol{D} = \\begin{pmatrix} \\boldsymbol{D_{11}} &amp; \\boldsymbol{0}\\\\ \\boldsymbol{0}^\\top &amp; 0 \\end{pmatrix}\\) donde \\(\\boldsymbol{D_{11}}\\) es una matriz de covarianzas (positiva definida) de dimensi√≥n \\(q \\times q\\) versus que \\(\\boldsymbol{D}\\) es una matriz general de dimensi√≥n \\(q+1 \\times q+1\\). En este caso la distribuci√≥n asint√≥tica del estad√≠stica raz√≥n de verosimilitud es una mezcla de \\(\\chi^2_{q+1}\\) y \\(\\chi^2_q\\) con pesos iguales a 0.5. \\(q\\) efectos aleatorios versus \\(q+k\\) efectos aleatorios: en este caso lo que interesa es \\(H_0: \\boldsymbol{D} = \\begin{pmatrix} \\boldsymbol{D_{11}} &amp; \\boldsymbol{0}\\\\ \\boldsymbol{0}^\\top &amp; \\boldsymbol{0} \\end{pmatrix}\\) donde \\(\\boldsymbol{D}\\) es una matriz de covarianzas (positiva definida) de dimensi√≥n \\(q+k \\times q+k\\) versus que \\(H_A: \\boldsymbol{D} = \\begin{pmatrix} \\boldsymbol{D_{11}} &amp; \\boldsymbol{D_{12}}\\\\ \\boldsymbol{D_{12}}^\\top &amp; \\boldsymbol{D_{22}} \\end{pmatrix}\\) es una matriz general de dimensi√≥n \\(q+k \\times q+k\\). En este caso la distribuci√≥n asint√≥tica del estad√≠stica raz√≥n de verosimilitud es una mezcla de \\(\\chi^2_{q+k}\\) y \\(\\chi^2_q\\) con pesos iguales a 0.5. Si la distribuci√≥n nula del estad√≠stico raz√≥n de verosimilitud no puede ser obtenida anal√≠ticamente, una posible soluci√≥n es usar la distribuci√≥n emp√≠rica del estad√≠stico obtenida al ajustar m√∫ltiples modelos nulos y alternativos (Galecki and Burzykowski 2012). Ejemplo Simule 10 observaciones para cada uno de los 10 grupos siguiendo el siguiente modelo y luego aplique la prueba de raz√≥n de verosimilitud para estudiar \\(H_0: \\sigma^2_{b0} = 0\\) versus \\(H_A: \\sigma^2_{b0} &gt; 0\\). \\[\\begin{align*} y_{ij} &amp;\\sim N(\\mu_{ij}, \\sigma^2_y) \\\\ \\mu_{ij} &amp;= 4 - 6 x_{ij} + b_{0i} \\\\ \\sigma^2_y &amp;= 4 \\\\ b_{0} &amp;\\sim N(0, \\sigma^2_{b0}=4) \\\\ x_{ij} &amp;\\sim U(0, 10) \\end{align*}\\] Soluci√≥n La funci√≥n gen_dat_b0 de abajo permite simular m observaciones de n grupos con intercepto aleatorio \\(b_0 \\sim N(0, \\sigma^2_{b0})\\). Adicionalmente, es posible elegir los efectos fijos beta0, beta_1 y la varianza sigma de la variable respuesta. gen_dat_b0 &lt;- function(n, m, beta0, beta1, sigmay, sigmab0, seed=NULL) { if(is.null(seed)) seed &lt;- as.integer(runif(1)*2e9) group &lt;- rep(1:n, each=m) set.seed(seed) b0 &lt;- rep(rnorm(n=n, mean=0, sd=sigmab0), each=m) set.seed(seed) x &lt;- runif(n=n*m, min=0, max=10) set.seed(seed) y &lt;- rnorm(n=n*m, mean=beta0 + beta1 * x + b0, sd=sigmay) data.frame(group=group, x=x, y=y) } Vamos ahora a generar 10 observaciones para 10 grupos con intercepto aleatorio con una varianza \\(\\sigma^2_{b0}=2^2=4\\). La semilla se va a fijar en un valor de 1220872376 por cuestiones did√°cticas. datos &lt;- gen_dat_b0(n=10, m=10, beta0=4, beta1=-6, sigmay=2, sigmab0=2, seed=1220872376) head(datos) ## group x y ## 1 1 3.817132 -20.106729 ## 2 1 8.951117 -49.950457 ## 3 1 5.710726 -33.154170 ## 4 1 7.451320 -39.583303 ## 5 1 1.263282 -1.070788 ## 6 1 6.114367 -33.423587 Vamos a ajustar dos modelos, el primero sin incluir \\(b_0\\) y el segundo incluyendo \\(b_0\\). library(nlme) fit1 &lt;- gls(y ~ x, data=datos, method=&quot;REML&quot;) # Igual resultado con lm fit2 &lt;- lme(y ~ x, random = ~ 1| group, data=datos, method=&quot;REML&quot;) Resultados del primer modelo. summary(fit1) ## Generalized least squares fit by REML ## Model: y ~ x ## Data: datos ## AIC BIC logLik ## 475.8248 483.5797 -234.9124 ## ## Coefficients: ## Value Std.Error t-value p-value ## (Intercept) 4.64931 0.5180190 8.97517 0 ## x -6.00175 0.0814173 -73.71588 0 ## ## Correlation: ## (Intr) ## x -0.875 ## ## Standardized residuals: ## Min Q1 Med Q3 Max ## -2.14346496 -0.64999607 -0.06461389 0.60660976 3.48238119 ## ## Residual standard error: 2.50842 ## Degrees of freedom: 100 total; 98 residual Resultados del segundo modelo. summary(fit2) ## Linear mixed-effects model fit by REML ## Data: datos ## AIC BIC logLik ## 474.7777 485.1175 -233.3888 ## ## Random effects: ## Formula: ~1 | group ## (Intercept) Residual ## StdDev: 0.8166724 2.383898 ## ## Fixed effects: y ~ x ## Value Std.Error DF t-value p-value ## (Intercept) 4.640053 0.5652943 89 8.20821 0 ## x -6.000087 0.0795348 89 -75.43973 0 ## Correlation: ## (Intr) ## x -0.783 ## ## Standardized Within-Group Residuals: ## Min Q1 Med Q3 Max ## -2.19536246 -0.56396957 0.05433633 0.61634184 3.29594400 ## ## Number of Observations: 100 ## Number of Groups: 10 Ahora vamos a calcular el estad√≠stico y su valor-P. lrt &lt;- -2 * (logLik(fit1) - logLik(fit2)) lrt ## &#39;log Lik.&#39; 3.04712 (df=3) my_p.value &lt;- pchisq(q=3.04712, df=1, lower.tail=FALSE) my_p.value ## [1] 0.08088045 De la salida anterior se tiene que \\(valor-P = 0.0809\\) y como \\(\\alpha=0.05\\), por lo tanto NO hay evidencias para rechazar \\(H_0: \\sigma^2_{b0} = 0\\). ¬øNo es extra√±a esta conclusi√≥n ü§î? Los resultados anteriores se pueden obtener por medio de la funci√≥n anova as√≠. anova(fit1, fit2) ## Model df AIC BIC logLik Test L.Ratio p-value ## fit1 1 3 475.8248 483.5797 -234.9124 ## fit2 2 4 474.7777 485.1175 -233.3888 1 vs 2 3.04712 0.0809 Ahora vamos a simular 50 conjuntos de datos suponiendo \\(H_0\\) verdadera y luego calcularemos los lrt para as√≠ tener la distribuci√≥n emp√≠rica de los lrt bajo la hip√≥tesis nula \\(H_0: \\sigma^2_{b0} = 0\\) verdadera. En un aplicaci√≥n se deber√≠an generar m√°s conjuntos de pero aqu√≠ vamos a usar s√≥lo 50 por comodidad. pseudo_gen_dat &lt;- function(nobs, beta0, beta1, sigmay) { group &lt;- datos$group # Aqui la diferencia x &lt;- datos$x # Aqui la diferencia y &lt;- rnorm(n=nobs, mean=beta0 + beta1 * x, sd=sigmay) data.frame(group=group, x=x, y=y) } nrep &lt;- 50 lrts &lt;- numeric(nrep) for (i in 1:nrep) { pseudo_datos &lt;- pseudo_gen_dat(nobs=100, beta0=4.64931, beta1=-6.00175, sigma=2.50842) m1 &lt;- gls(y ~ x, data=pseudo_datos, method=&quot;REML&quot;) m2 &lt;- lme(y ~ x, random = ~ 1| group, data=pseudo_datos, method=&quot;REML&quot;) lrts[i] &lt;- -2 * (logLik(m1) - logLik(m2)) } Dibujando la densidad de los lrt. plot(density(lrts), main=&#39;Densidad emp√≠rica de los lrts&#39;) Calculando el valor-P. acumulada &lt;- ecdf(x=lrts) # F(x) para los valores LRT 1 - acumulada(3.04712) # Valor-P ## [1] 0.04 De la salida anterior se tiene que \\(valor-P &lt; \\alpha\\) por lo tanto SI hay evidencias para rechazar \\(H_0: \\sigma^2_{b0} = 0\\). ¬øEs esto coherente ahora üôÇ? Los resultados anteriores se obtuvieron usando nrep &lt;- 50, en la pr√°ctica ese n√∫mero de repeticiones deber√≠a subir al menos a 1000. Repita el procedimiento anterior con nrep &lt;- 5000 y observe lo que sucede. El paquete RLRsim (Scheipl and Bolker 2016) tiene la funci√≥n exactRLRT que permite extraer el valor-P mediante simulaci√≥n. Abajo un ejemplo de como usarla en el presente ejemplo. library(RLRsim) exactRLRT(m=fit2, nsim=1000) ## Warning in model.matrix.default(~m$groups[[n.levels - i + 1]] - 1, ## contrasts.arg = c(&quot;contr.treatment&quot;, : non-list contrasts argument ignored ## ## simulated finite sample distribution of RLRT. ## ## (p-value based on 1000 simulated values) ## ## data: ## RLRT = 3.0471, p-value = 0.039 Consulte la ayuda de la funci√≥n exactRLRT para que conozca sus posibilidades y limitaciones. Ejercicios ¬øQu√© son modelos anidados? ¬øSon modelos que usan datos relacionados con aves? Considere la base de datos sleepstudy del paquete lme4. El objetivo es comparar los siguientes dos modelos. Modelo 1 \\[\\begin{align*} Reaction_{ij} &amp;\\sim N(\\mu_{ij}, \\sigma^2_{reaction}) \\\\ \\mu_{ij} &amp;= \\beta_0 + \\beta_1 days_{ij} + b_{0i} + b_{1i} days_{ij} \\\\ (b_0, b_1)^\\top &amp;\\sim N(\\boldsymbol{0}, \\boldsymbol{D}) \\end{align*}\\] Modelo 2 \\[\\begin{align*} Reaction_{ij} &amp;\\sim N(\\mu_{ij}, \\sigma^2_{reaction}) \\\\ \\mu_{ij} &amp;= \\beta_0 + \\beta_1 days_{ij} + \\beta_2 days_{ij}^2 + b_{0i} + b_{1i} days_{ij} \\\\ (b_0, b_1)^\\top &amp;\\sim N(\\boldsymbol{0}, \\boldsymbol{D}) \\end{align*}\\] Escriba las hip√≥tesis del problema en forma simb√≥lica y en lenguaje sencillo. Aplique la prueba raz√≥n de verosimilitud usando simulaci√≥n y concluya. Rta: el valor-P \\(\\approx\\) 0.136. Considere el ejemplo del cap√≠tulo 7 sobre el estudio de crecimiento de un grupo de j√≥venes. Aplique la prueba raz√≥n de verosimilitud para estudiar \\(H_0: \\sigma^2_{b0} = 0\\) versus \\(H_A: \\sigma^2_{b0} &gt; 0\\), es decir, ajuste un modelo lineal simple para explicar la estatura en funci√≥n de la edad y luego un modelo mixto con intercepto aleatorio. ¬øCu√°l de los dos modelos parece explicar mejor los datos? Use \\(\\alpha=0.06\\). En este enlace est√° la pregunta de un usuario de StackExange sobre prueba de hip√≥tesis (PH). ¬øFue la pregunta sobre PH sobre efectos fijos o PH sobre componentes de varianza? ¬øQuer√≠a el usuario un PH asint√≥tica o una PH basada en bootstrap (relacionado con simulaci√≥n)? Mire el ejemplo que di√≥ YaronZ, ¬øpor qu√© no defini√≥ el m√©todo REML dentro de las funciones lmer y lm? En este enlace est√° la extensa pregunta del usuario Patrick. En el primer caj√≥n de c√≥digo Patrick escribi√≥ un c√≥digo para simular observaciones de un modelo mixto. ¬øC√≥mo le parece esa forma de simular? ¬øCu√°ntos elementos tiene el vector de par√°metros del modelo de Patrick? ¬øCu√°les son los valores de los par√°metros? En este enlace est√° la pregunta del usuario biostat_newbie. ¬øQu√© nombre recibe el modelo que le interesa a biostat_newbie? ¬øQu√© es lo que necesita 0.7494974? ¬øCu√°l es el mensaje de primer p√°rrafo de que respondi√≥ Fabians? En la respuesta que Fabians di√≥ hay un c√≥digo de R. ¬øPara qu√© sirve ese c√≥digo tan extra√±o? ¬øQui√©n es Ben Bolker? ¬øEn cu√°les paquetes de R ha participado Ben Bolker? En este enlace est√° la pregunta del usuario user9171. ¬øCu√°l es el error que comete user9171 al usar el siguiente c√≥digo? &gt; anova(fit.fe, fit.me) Error: $ operator not defined for this S4 class ¬øQu√© le respondi√≥ Karl Ove Hufthammer? Karl le agrega en su respuesta ‚ÄúAnd really the choice of whether to include the random effects should be based on theory (e.g., the sampling plan), not on a statistical test‚Äù. ¬øQu√© quiere decir eso? Ben Bolker escribi√≥ unas notas sobre pruebas de hip√≥tesis, revise este enlace para consultarlas. En el ejemplo de Ben Bolker hay tres modelos: m2, m1 y m0. ¬øCu√°l es el ‚Äúfull model‚Äù y cu√°l es el ‚Äúreduced model‚Äù? ¬øPara qu√© sirve la funci√≥n update? ¬øUsted la ha usado alguna vez? ¬øNo? Pues √∫sela de aqu√≠ en adelante. Ben escribe ‚Äúwhich has a fast implementation of simulation-based tests of null hypotheses about zero variances, for simple tests.‚Äù ¬øA qu√© paquete se refiere con esa frase? References "]
]
