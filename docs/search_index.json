[
["ph.html", "5 Pruebas de hip√≥tesis 5.1 Prueba raz√≥n de verosimilitud 5.2 Prueba de hip√≥tesis sobre un par√°metro fijo \\(\\beta_k\\) 5.3 Prueba de hip√≥tesis sobre un conjunto de par√°metros fijos (varios \\(\\beta_k\\)) 5.4 Prueba de hip√≥tesis sobre componentes de varianza Ejercicios", " 5 Pruebas de hip√≥tesis En este cap√≠tulo se muestran las pruebas de hip√≥tesis para comparar modelo mixtos. 5.1 Prueba raz√≥n de verosimilitud Supongamos que queremos estudiar \\(H_0: \\theta \\in \\boldsymbol{\\Theta}_0\\) versus \\(H_A: \\theta \\in \\boldsymbol{\\Theta}\\). La prueba raz√≥n de verosimilitud (\\(LR\\)) para \\(H_0\\) est√° dada por: \\[ LR = -2 \\log \\left( \\frac{ sup_{\\theta \\in \\boldsymbol{\\Theta}_0} L(\\theta)}{ sup_{\\theta \\in \\boldsymbol{\\Theta}} L(\\theta)} \\right) \\] Usualmente la prueba de raz√≥n de verosimilitud se expresa en funci√≥n de los valores de log-verosimilitud del modelo asi: \\[ LR = -2 ( l(\\Theta_0) - l(\\hat{\\Theta}) ) \\] y el estad√≠stico \\(LR \\sim \\chi^2_{k-k_0}\\), donde \\(k\\) es el n√∫mero de par√°metros del modelo estimado y \\(k_0\\) el n√∫mero de par√°metros del modelo asumiendo \\(H_0\\) verdadera. 5.2 Prueba de hip√≥tesis sobre un par√°metro fijo \\(\\beta_k\\) Si el inter√©s es estudiar \\(H_0: \\beta_k = \\beta_{k0}\\) contra \\(H_0: \\beta_k \\neq \\beta_{k0}\\) se puede usar la prueba de Wald que tiene el siguiente estad√≠stico: \\[ t = \\frac{\\hat{\\beta}_k - \\beta_{k0}}{se(\\hat{\\beta}_k)}, \\] donde \\(se(\\hat{\\beta}_k)\\) corresponde al error est√°ndar de la estimaci√≥n \\(\\hat{\\beta}_k\\), todo esto disponible en el summary del modelo ajustado. Si \\(H_0\\) es verdadera, \\(t \\sim t_{n-p}\\), siendo \\(n\\) el n√∫mero de observaciones y \\(p\\) el n√∫mero de efectos fijos estimados (no el n√∫mero de variables) en el modelo. Ejemplo La base de datos ChickWeight contiene informaci√≥n sobre el peso de un grupo de pollos versus el tiempo con diferentes dietas. Abajo una ilustraci√≥n de los datos. library(ggplot2) ggplot(data = ChickWeight, aes(x = Time, y = weight, color = Diet)) + geom_point() + theme_bw() + facet_wrap(~ Chick) El objetivo es comparar los siguientes dos modelos. Modelo 1 \\[\\begin{align*} Weight_{ij} &amp;\\sim N(\\mu_{ij}, \\sigma^2_{weight}) \\\\ \\mu_{ij} &amp;= \\beta_0 + \\beta_1 tiempo_{ij} + b_{0i} \\\\ b_{0} &amp;\\sim N(0, \\sigma^2_{b0}) \\end{align*}\\] Modelo 2 \\[\\begin{align*} Weight_{ij} &amp;\\sim N(\\mu_{ij}, \\sigma^2_{weight}) \\\\ \\mu_{ij} &amp;= \\beta_0 + \\beta_1 tiempo_{ij} + \\beta_2 dieta2_{i} + \\beta_3 dieta3_{i} + \\beta_4 dieta4_{i} + b_{0i} \\\\ b_{0} &amp;\\sim N(0, \\sigma^2_{b0}) \\end{align*}\\] Soluci√≥n El problema de este ejercicio se puede resumir con \\(H_0:\\) la variable Dieta no aporta al modelo, versus, \\(H_A:\\) la variable Dieta si aporta al modelo. Para ajustar ambos modelos se usa el siguiente c√≥digo. library(nlme) mod1 &lt;- lme(weight ~ Time, data = ChickWeight, random = ~ 1 | Chick, method=&#39;ML&#39;) mod2 &lt;- lme(weight ~ Time + Diet, data = ChickWeight, random = ~ 1 | Chick, method=&#39;ML&#39;) Para calcular la prueba raz√≥n de verosimilitud se usa el siguiente c√≥digo. lrt &lt;- -2 * (logLik(mod1) - logLik(mod2)) lrt ## &#39;log Lik.&#39; 17.14349 (df=4) pchisq(q=lrt, df=7-4, lower.tail=FALSE) ## &#39;log Lik.&#39; 0.000660304 (df=4) De la salida anterior se tiene que el valor-P = 0.000660304 y menor que cualquier \\(\\alpha\\). Sin embargo, como este valor-P puede ser ‚Äúanticonservativo‚Äù (m√°s peque√±o de lo que deber√≠a ser), es mejor no sacar conclusiones apresuradas y rechazar \\(H_0\\) üòï. La prueba de verosimilitud se puede obtener tambi√©n as√≠: anova(mod1, mod2) ## Model df AIC BIC logLik Test L.Ratio p-value ## mod1 1 4 5630.344 5647.782 -2811.172 ## mod2 2 7 5619.201 5649.718 -2802.600 1 vs 2 17.14349 7e-04 Para obtener un valor-P m√°s acorde al problema podemos usar simulaci√≥n. La funci√≥n simulate.lme simula datos de modelos especificados por medio de los argumentos object y m2, ajusta los modelos, y entrega los valores de log-verosimilitud, con los se puede obtener el estad√≠stico de la prueba de raz√≥n de verosimilitud. A continuaci√≥n el c√≥digo para obtener el valor-P con simulaci√≥n. simul &lt;- simulate.lme(object=mod1, m2=mod2, method = &#39;ML&#39;, nsim=1000) lrts_nlme &lt;- -2 * (simul$null$ML[, 2] - simul$alt$ML[, 2]) acumulada1 &lt;- ecdf(x=lrts_nlme) # F(x) para los valores LRT 1 - acumulada1(17.14349) ## [1] 0.001 De la salida anterior se tiene que el valor-P = 0.001 y ya no es tan peque√±o como el valor-P anterior. Por esta raz√≥n hay evidencias rechazar \\(H_0\\) y por lo tanto la variable Dieta si aporta al modelo üòê. 5.3 Prueba de hip√≥tesis sobre un conjunto de par√°metros fijos (varios \\(\\beta_k\\)) Luego un ejemplo. 5.4 Prueba de hip√≥tesis sobre componentes de varianza Las componentes de varianza corresponden a las varianzas y covarianzas del vector de efectos aleatorios. Para hacer pruebas de hip√≥tesis sobre las componentes de varianza se tienen dos casos que se explican en las siguientes subsecciones. 5.4.1 Componentes de varianza lejos del borde Luego un ejemplo. 5.4.2 Componentes de varianza en el borde Este caso se presenta cuando la hip√≥tesis nula considera que uno o varios par√°metros est√°n justo en el borde del dominio del par√°metro en cuestion. Por ejemplo, si queremos estudiar la inclusi√≥n del intercepto aleatorio \\(b_0\\) en un modelo de regresi√≥n cl√°sico, tendr√≠amos las siguientes hip√≥tesis: \\(H_0: \\sigma^2_{b0} = 0\\) versus \\(H_A: \\sigma^2_{b0} &gt; 0\\). Debido a la condici√≥n de \\(\\sigma^2_{b0}\\) en \\(H_0\\), se dice que esa componente de varianza est√° en el borde de su dominio, ya que \\(\\sigma^2_{b0}\\) no puede ser negativa. En este ejemplo particular, rechazar \\(H_0\\) implicar√≠a que es apropiado incluir \\(b_0\\) en el modelo. Ejemplo Simule 10 observaciones para cada uno de los 10 grupos siguiendo el siguiente modelo y luego aplique la prueba de raz√≥n de verosimilitud para estudiar \\(H_0: \\sigma^2_{b0} = 0\\) versus \\(H_A: \\sigma^2_{b0} &gt; 0\\). \\[\\begin{align*} y_{ij} &amp;\\sim N(\\mu_{ij}, \\sigma^2) \\\\ \\mu_{ij} &amp;= 4 - 6 x_{ij} + b_{0i} \\\\ \\sigma^2_y &amp;= 4 \\\\ b_{0} &amp;\\sim N(0, \\sigma^2_{b0}=4) \\\\ x_{ij} &amp;\\sim U(0, 10) \\end{align*}\\] Soluci√≥n La funci√≥n gen_dat_b0 de abajo permite simular m observaciones de n grupos con intercepto aleatorio \\(b_0 \\sim N(0, \\sigma^2_{b0})\\). Adicionalmente, es posible elegir los efectos fijos beta0, beta_1 y la varianza sigma de la variable respuesta. gen_dat_b0 &lt;- function(n, m, beta0, beta1, sigmay, sigmab0, seed=NULL) { if(is.null(seed)) seed &lt;- as.integer(runif(1)*2e9) group &lt;- rep(1:n, each=m) set.seed(seed) b0 &lt;- rep(rnorm(n=n, mean=0, sd=sigmab0), each=m) set.seed(seed) x &lt;- runif(n=n*m, min=0, max=10) set.seed(seed) y &lt;- rnorm(n=n*m, mean=beta0 + beta1 * x + b0, sd=sigmay) data.frame(group=group, x=x, y=y) } Vamos ahora a generar 10 observaciones para 10 grupos con intercepto aleatorio con una varianza \\(\\sigma^2_{b0}=2^2=4\\). La semilla se va a fijar en un valor de 1220872376 por cuestiones did√°cticas. datos &lt;- gen_dat_b0(n=10, m=10, beta0=4, beta1=-6, sigmay=2, sigmab0=2, seed=1220872376) head(datos) ## group x y ## 1 1 3.817132 -20.106729 ## 2 1 8.951117 -49.950457 ## 3 1 5.710726 -33.154170 ## 4 1 7.451320 -39.583303 ## 5 1 1.263282 -1.070788 ## 6 1 6.114367 -33.423587 Vamos a ajustar dos modelos, el primero sin incluir \\(b_0\\) y el segundo incluyendo \\(b_0\\). library(nlme) fit1 &lt;- gls(y ~ x, data=datos, method=&quot;REML&quot;) # Igual resultado con lm fit2 &lt;- lme(y ~ x, random = ~ 1| group, data=datos, method=&quot;REML&quot;) Resultados del primer modelo. summary(fit1) ## Generalized least squares fit by REML ## Model: y ~ x ## Data: datos ## AIC BIC logLik ## 475.8248 483.5797 -234.9124 ## ## Coefficients: ## Value Std.Error t-value p-value ## (Intercept) 4.64931 0.5180190 8.97517 0 ## x -6.00175 0.0814173 -73.71588 0 ## ## Correlation: ## (Intr) ## x -0.875 ## ## Standardized residuals: ## Min Q1 Med Q3 Max ## -2.14346496 -0.64999607 -0.06461389 0.60660976 3.48238119 ## ## Residual standard error: 2.50842 ## Degrees of freedom: 100 total; 98 residual Resultados del segundo modelo. summary(fit2) ## Linear mixed-effects model fit by REML ## Data: datos ## AIC BIC logLik ## 474.7777 485.1175 -233.3888 ## ## Random effects: ## Formula: ~1 | group ## (Intercept) Residual ## StdDev: 0.8166724 2.383898 ## ## Fixed effects: y ~ x ## Value Std.Error DF t-value p-value ## (Intercept) 4.640053 0.5652943 89 8.20821 0 ## x -6.000087 0.0795348 89 -75.43973 0 ## Correlation: ## (Intr) ## x -0.783 ## ## Standardized Within-Group Residuals: ## Min Q1 Med Q3 Max ## -2.19536246 -0.56396957 0.05433633 0.61634184 3.29594400 ## ## Number of Observations: 100 ## Number of Groups: 10 Ahora vamos a calcular el estad√≠stico y su valor-P. lrt &lt;- -2 * (logLik(fit1) - logLik(fit2)) lrt ## &#39;log Lik.&#39; 3.04712 (df=3) my_p.value &lt;- pchisq(q=3.04712, df=1, lower.tail=FALSE) my_p.value ## [1] 0.08088045 De la salida anterior se tiene que \\(valor-P = 0.0809\\) y como \\(\\alpha=0.05\\), por lo tanto NO hay evidencias para rechazar \\(H_0: \\sigma^2_{b0} = 0\\). ¬øNo es extra√±a esta conclusi√≥n ü§î? Los resultados anteriores se pueden obtener por medio de la funci√≥n anova as√≠. anova(fit1, fit2) ## Model df AIC BIC logLik Test L.Ratio p-value ## fit1 1 3 475.8248 483.5797 -234.9124 ## fit2 2 4 474.7777 485.1175 -233.3888 1 vs 2 3.04712 0.0809 Ahora vamos a simular 50 conjuntos de datos suponiendo \\(H_0\\) verdadera y luego calcularemos los lrt para as√≠ tener la distribuci√≥n emp√≠rica de los lrt bajo la hip√≥tesis nula \\(H_0: \\sigma^2_{b0} = 0\\) verdadera. En un aplicaci√≥n se deber√≠an generar m√°s conjuntos de pero aqu√≠ vamos a usar s√≥lo 50 por comodidad. pseudo_gen_dat &lt;- function(nobs, beta0, beta1, sigmay) { group &lt;- datos$group # Aqui la diferencia x &lt;- datos$x # Aqui la diferencia y &lt;- rnorm(n=nobs, mean=beta0 + beta1 * x, sd=sigmay) data.frame(group=group, x=x, y=y) } nrep &lt;- 50 lrts &lt;- numeric(nrep) for (i in 1:nrep) { pseudo_datos &lt;- pseudo_gen_dat(nobs=100, beta0=4.64931, beta1=-6.00175, sigma=2.50842) m1 &lt;- gls(y ~ x, data=pseudo_datos, method=&quot;REML&quot;) m2 &lt;- lme(y ~ x, random = ~ 1| group, data=pseudo_datos, method=&quot;REML&quot;) lrts[i] &lt;- -2 * (logLik(m1) - logLik(m2)) } Dibujando la densidad de los lrt. plot(density(lrts), main=&#39;Densidad emp√≠rica de los lrts&#39;) Calculando el valor-P. acumulada &lt;- ecdf(x=lrts) # F(x) para los valores LRT 1 - acumulada(3.04712) # Valor-P ## [1] 0.04 De la salida anterior se tiene que \\(valor-P &lt; \\alpha\\) por lo tanto SI hay evidencias para rechazar \\(H_0: \\sigma^2_{b0} = 0\\). ¬øEs esto coherente ahora üôÇ? Los resultados anteriores se obtuvieron usando nrep &lt;- 50, en la pr√°ctica ese n√∫mero de repeticiones deber√≠a subir al menos a 1000. Repita el procedimiento anterior con nrep &lt;- 5000 y observe lo que sucede. El paquete RLRsim (???) tiene la funci√≥n exactRLRT que permite extraer el valor-P mediante simulaci√≥n. Abajo un ejemplo de como usarla en el presente ejemplo. library(RLRsim) exactRLRT(m=fit2, nsim=1000) ## Warning in model.matrix.default(~m$groups[[n.levels - i + 1]] - 1, contrasts.arg ## = c(&quot;contr.treatment&quot;, : non-list contrasts argument ignored ## ## simulated finite sample distribution of RLRT. ## ## (p-value based on 1000 simulated values) ## ## data: ## RLRT = 3.0471, p-value = 0.039 Consulte la ayuda de la funci√≥n exactRLRT para que conozca sus posibilidades y limitaciones. Ejercicios Considere el ejemplo del cap√≠tulo 7 sobre el estudio de crecimiento de un grupo de j√≥venes. Aplique la prueba raz√≥n de verosimilitud para estudiar \\(H_0: \\sigma^2_{b0} = 0\\) versus \\(H_A: \\sigma^2_{b0} &gt; 0\\), es decir, ajuste un modelo lineal simple para explicar la estatura en funci√≥n de la edad y luego un modelo mixto con intercepto aleatorio. ¬øCu√°l de los dos modelos parece explicar mejor los datos? Use \\(\\alpha=0.06\\). "]
]
