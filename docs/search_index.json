[["index.html", "Modelos Mixtos con R Bienvenido Estructura del libro Software y convenciones Bloques informativos", " Modelos Mixtos con R Freddy Hernández Barajas Jorge Leonardo López Martínez 2022-01-26 Bienvenido Este libro está destinado para usuarios de R interesados en aplicar modelos mixtos. Freddy Hernández Barajas Jorge Leonardo López Martínez Estructura del libro En el capítulo 1 se hace un repaso básico del modelo de regresión lineal clásico. En el capítulo 2 se presentan los modelos mixtos y en el capítulo 13 se presentan los modelos lineales generalizados mixtos. En el capítulo 4 se presenta el paquete lme4 y sus principales funciones para modelación, mientras que en el capítulo 6 se presenta el paquete nlme y sus principales funciones para modelación. Software y convenciones Para realizar este libro usamos los paquetes knitr (Xie 2015) y bookdown (Xie 2021) que permiten unir la ventajas de LaTeX y R en un mismo archivo. En todo el libro se presentarán códigos que el lector puede copiar y pegar en su consola de R para obtener los mismos resultados aquí del libro. Los códigos se destacan en una caja de color similar a la mostrada a continuación. 4 + 6 a &lt;- c(1, 5, 6) 5 * a 1:10 Los resultados o salidas obtenidos de cualquier código se destacan con dos símbolos de númeral (##) al inicio de cada línea o renglón, esto quiere decir que todo lo que inicie con ## son resultados obtenidos y NO los debe copiar. Abajo se muestran los resultados obtenidos luego de correr el código anterior. ## [1] 10 ## [1] 5 25 30 ## [1] 1 2 3 4 5 6 7 8 9 10 Bloques informativos En varias partes del libro usaremos bloques informativos para resaltar algún aspecto importante. Abajo se encuentra un ejemplo de los bloques y su significado. Nota aclaratoria. Sugerencia. Advertencia. Solución a ejemplos. References "],["reg-lin.html", "1 Regresión lineal 1.1 Modelo estadístico 1.2 Verosimilitud del modelo", " 1 Regresión lineal En este capítulo se presenta el modelo de regresión lineal clásico. 1.1 Modelo estadístico El modelo estadístico en regresión lineal clásico permite modelar la media de una variable \\(Y\\) en función de \\(k\\) covariables. El modelo se puede expresar como sigue. \\[\\begin{align} \\label{mod2} y_i &amp;\\sim N(\\mu_i, \\sigma^2), \\\\ \\mu_i &amp;= \\beta_0 + \\beta_1 x_{1i} + \\beta_2 x_{2i} + \\cdots + \\beta_k x_{ki}, \\\\ \\sigma^2 &amp;= \\text{constante} \\end{align}\\] donde \\(i=1, 2, \\ldots, n\\) es el índice que identifica las \\(n\\) observaciones del conjunto de entrenamiento. El vector de parámetros del modelo es \\(\\boldsymbol{\\theta}=(\\beta_0, \\beta_1, \\cdots, \\beta_k, \\sigma)^\\top\\). 1.2 Verosimilitud del modelo La función de verosimilitud \\(L\\) para el modelo es la siguiente: \\[ L(\\boldsymbol{\\theta}) = \\prod_i^n f(y_i \\vert \\beta_0, \\beta_1, \\cdots, \\beta_k, \\sigma), \\] donde \\(f\\) corresponde a la función de densidad de la normal. Para estimar el vector de parámetros \\(\\boldsymbol{\\theta}\\) del modelo se usa el método de Máxima Verosimilitud sobre la función \\(L\\) o sobre la función de log-verosimilitud siguiente: \\[ l(\\boldsymbol{\\theta}) = \\sum_i^n \\log(f(y_i \\vert \\beta_0, \\beta_1, \\cdots, \\beta_k, \\sigma)), \\] Ejemplo Como ilustración vamos a usar los datos del ejemplo 3.1 del libro de Montgomery, Peck and Vining (2003). En el ejemplo 3.1 los autores ajustaron un modelo de regresión lineal múltiple para explicar el Tiempo necesario para que un trabajador haga el mantenimiento y surta una máquina dispensadora de refrescos en función de las variables Número de Cajas y Distancia. Los datos del ejemplo están disponibles en el paquete MPV (por los apellidos de los autores). A continuación el código para cargar los datos y una muestra de las 6 primeras observaciones de la base de datos, en total se disponen de 20 observaciones. require(MPV) colnames(softdrink) &lt;- c(&#39;tiempo&#39;, &#39;cantidad&#39;, &#39;distancia&#39;) head(softdrink) ## tiempo cantidad distancia ## 1 16.68 7 560 ## 2 11.50 3 220 ## 3 12.03 3 340 ## 4 14.88 4 80 ## 5 13.75 6 150 ## 6 18.11 7 330 Un gráfico en 3d es obligratorio para explorar la relación entre las variables, este diagrama de puede obtener usando el paquete scatterplot3d. A continuación el código para construirlo. library(scatterplot3d) attach(softdrink) scatterplot3d(x=cantidad, y=distancia, z=tiempo, pch=16, cex.lab=1, highlight.3d=TRUE, type=&quot;h&quot;, xlab=&#39;Cantidad de cajas&#39;, ylab=&#39;Distancia (pies)&#39;, zlab=&#39;Tiempo (min)&#39;) De la figura anterior se ve claramente que a medida que aumenta el número de cajas y la distancia los tiempos tienden a ser mayores. A continuación se define la función de menos log-verosimilitud para el modelo anterior. A pesar de que nos interesa maximizar la función de log-verosimilitud hemos creado su negativo, esto porque la mayoría de las funciones de optimización minimizan y no maximizan; maximizar \\(f(x)\\) es equivalente a minimizar \\(-f(x)\\). minusll &lt;- function(theta, y, x1, x2) { media &lt;- theta[1] + theta[2] * x1 + theta[3] * x2 # Se define la media desvi &lt;- theta[4] # Se define la desviación. - sum(dnorm(x=y, mean=media, sd=desvi, log=TRUE)) } Ahora vamos a usar la función optim para encontrar los valores que maximizan la función de log-verosimilitud, el código para hacer eso se muestra a continuación. En el parámetro par se coloca un vector de posibles valores de \\(\\boldsymbol{\\Theta}\\) para iniciar la búsqueda, en fn se coloca la función de interés, en lower y upper se colocan vectores que indican los límites de búsqueda de cada parámetro, los \\(\\beta_k\\) pueden variar entre \\(-\\infty\\) y \\(\\infty\\) mientras que el parámetro \\(\\sigma\\) toma valores en el intervalo \\((0, \\infty)\\). Como la función minusll tiene argumentos adicionales y, x1 y x2, estos pasan a la función optim al final como se muestra en el código. mod1 &lt;- optim(par=c(0, 0, 0, 1), fn=minusll, method=&#39;L-BFGS-B&#39;, lower=c(-Inf, -Inf, -Inf, 0), upper=c(Inf, Inf, Inf, Inf), y=softdrink$tiempo, x1=softdrink$cantidad, x2=softdrink$distancia) En el objeto res1 está el resultado de la optimización, para explorar los resultados usamos mod1 ## $par ## [1] 2.34103296 1.61590757 0.01438512 3.05769678 ## ## $value ## [1] 63.41469 ## ## $counts ## function gradient ## 58 58 ## ## $convergence ## [1] 0 ## ## $message ## [1] &quot;CONVERGENCE: REL_REDUCTION_OF_F &lt;= FACTR*EPSMCH&quot; De esta forma el vector de parámetros estimados del modelo es \\(\\hat{\\boldsymbol{\\theta}}=(2.34, 1.62, 0.01, 3.06)^\\top\\). Usualmente en la práctica se usa la función lm para estimar el vector de parámetros, a continuación el código necesario para usar la funcion lm. mod2 &lt;- lm(tiempo ~ cantidad + distancia, data=softdrink) summary(mod2) ## ## Call: ## lm(formula = tiempo ~ cantidad + distancia, data = softdrink) ## ## Residuals: ## Min 1Q Median 3Q Max ## -5.7880 -0.6629 0.4364 1.1566 7.4197 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 2.341231 1.096730 2.135 0.044170 * ## cantidad 1.615907 0.170735 9.464 3.25e-09 *** ## distancia 0.014385 0.003613 3.981 0.000631 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 3.259 on 22 degrees of freedom ## Multiple R-squared: 0.9596, Adjusted R-squared: 0.9559 ## F-statistic: 261.2 on 2 and 22 DF, p-value: 4.687e-16 De la salida anterior vemos que el vector de parámetros estimados del modelo es \\(\\hat{\\boldsymbol{\\theta}}=(2.34, 1.62, 0.01, 3.26)^\\top\\). Para profundizar en el modelo de regresion lineal se recomienda consultar libro Modelos de Regresión con R "],["lmm.html", "2 Modelos Lineales Mixtos 2.1 Entrevista con Jim Ware y Nan Laird", " 2 Modelos Lineales Mixtos Los modelos lineales mixtos fueron propuestos por (Laird and Ware 1982) y en ellos se asume que existe una relación entre el vector de observaciones \\(\\boldsymbol{Y}_i\\) del sujeto o grupo \\(i\\) y las covariables por medio de la siguiente expresión \\[\\begin{equation} \\begin{aligned} \\boldsymbol{Y}_i \\mid \\boldsymbol{b}_i &amp;\\sim \\mathcal{N}(\\boldsymbol{X}_i \\boldsymbol{\\beta} + \\boldsymbol{Z}_i \\boldsymbol{b}_i, \\boldsymbol{\\Sigma}_i), \\\\ \\boldsymbol{b}_i &amp;\\sim \\mathcal{N}(\\boldsymbol{0}, \\boldsymbol{D}), \\end{aligned} \\tag{2.1} \\end{equation}\\] donde \\(\\boldsymbol{X}_i\\) y \\(\\boldsymbol{Z}_i\\) son matrices de diseño conocidas con la información de las covariables, siendo \\(\\boldsymbol{X}_i\\) de dimensión \\(n_i \\times p\\) y \\(\\boldsymbol{Z}_i\\) de dimensión \\(n_i \\times q\\). El elemento \\(\\boldsymbol{\\beta}\\) representa el vector de efectos fijos general, \\(\\boldsymbol{b}_i\\) el vector de efectos aleatorios exclusivo para el grupo \\(i\\). El vector \\(\\boldsymbol{b}_i\\) en la expresión (2.1) es llamado efecto aleatorio porque éste cambia la media de sujeto a sujeto y su función es la de mejorar el ajuste general dado por el elemento \\(\\boldsymbol{X}_i \\boldsymbol{\\beta}\\) al agregar la cantidad \\(\\boldsymbol{Z}_i \\boldsymbol{b}_i\\). El modelo dado en la expresión (2.1) es llamado también modelo mixto porque involucra tanto efectos fijos (\\(\\boldsymbol{\\beta}\\)) como efectos aleatorios (\\(\\boldsymbol{b}_i\\)). La distribución marginal de \\(\\boldsymbol{Y}_i\\) está dada por \\[\\begin{equation} f_i(\\boldsymbol{Y}_i) = \\int f(\\boldsymbol{Y}_i | \\boldsymbol{b}_i) f(\\boldsymbol{b}_i) \\, d \\boldsymbol{b}_i \\end{equation}\\] donde \\(f(\\boldsymbol{Y}_i | \\boldsymbol{b}_i)\\) y \\(f(\\boldsymbol{b}_i)\\) corresponden a las densidades normales mostradas en la expresión (2.1). Esta distribución marginal tiene forma cerrada y se puede mostrar fácilmente que la distribución de \\(\\boldsymbol{Y}_i\\) es una normal multivariada con vector de medias y matriz de covarianzas como se muestra a continuación. \\[\\begin{equation} \\boldsymbol{Y}_i \\sim \\mathcal{N}(\\boldsymbol{X}_i \\boldsymbol{\\beta}, \\boldsymbol{V}_i), \\end{equation}\\] donde \\(\\boldsymbol{V}_i=\\boldsymbol{Z}_i \\boldsymbol{D} \\boldsymbol{Z}_i^\\top + \\boldsymbol{\\Sigma}_i\\). El vector de parámetros en este caso es \\(\\boldsymbol{\\theta}=(\\boldsymbol{\\beta}, \\boldsymbol{\\alpha})^\\top\\) donde \\(\\boldsymbol{\\alpha}\\) consiste de los \\(q(q+1)/2\\) elementos diferentes de la matriz \\(\\boldsymbol{D}\\) y todos los elementos de la matriz \\(\\boldsymbol{\\Sigma}_i\\). 2.1 Entrevista con Jim Ware y Nan Laird References "],["shiny.html", "3 Aplicaciones shiny", " 3 Aplicaciones shiny En este capítulo se presentan aplicaciones shiny para ilustrar modelos con efectos aleatorios. Aplicación lmm con intercepto aleatorio. Aplicación lmm con intercepto y pendiente aleatorias. "],["pac-lme4.html", "4 Paquete lme4 4.1 Función lmer Ejemplo: modelo normal con intercepto aleatorio Ejemplo: recuperando los interceptos aleatorios 4.2 Función glmer Ejemplo: modelo gamma con intercepto aleatorio Ejemplo: modelo inversa gaussiana con intercepto y pendiente aleatoria", " 4 Paquete lme4 El paquete lme4 de Bates et al. (2021) es uno de los paquetes más completos para modelos mixtos. Al visitar este enlace se encontrará la página de apoyo del paquete, allí se puede consultar el manual de referencia y las viñetas. 4.1 Función lmer La función lmer es la principal función del paquete lme4. Esta función sirve para ajustar un modelo mixto y su estructura es la siguiente: lmer(formula, data = NULL, REML = TRUE, control = lmerControl(), start = NULL, verbose = 0L, subset, weights, na.action, offset, contrasts = NULL, devFunOnly = FALSE, ...) Los principales argumentos de la función son: formula: es una fórmula similar a la usada en el modelo lineal clásico. Un ejemplo de fórmula sería y ~ 1 + x1 + x2 + (1 + x2 | grupo) con la cual se indican los efectos fijos y los efectos aleatorios del modelo. Más abajo hay una tabla con más detalles sobre la fórmula. data: marco de datos donde están las variables. REML: valor lógico que sirve para indicar si queremos estimaciones maximizando la verosimilitud restringida o la verosimilitud usual. La siguiente imagen corresponde a la tabla 2 de la viñeta Fitting Linear Mixed-Effects Models using lme4. En la tabla las dos primeras columnas muestran formas equivalentes de incluir las estructuras de modelos mixtos más comunes. Ejemplo: modelo normal con intercepto aleatorio En este ejemplo vamos a simular observaciones \\(n_i=50\\) observaciones para \\(G=10\\) grupos (en total 500 obs) que tengan la estructura mostrada abajo. El objetivo del ejemplo es ilustrar el uso de la función lmer para estimar los parámetros del modelo. \\[\\begin{align*} y_{ij} | b_0 &amp;\\sim N(\\mu_{ij}, \\sigma^2_y) \\\\ \\mu_{ij} &amp;= 4 - 6 x_{ij} + b_{0i} \\\\ \\sigma^2_y &amp;= 16 \\\\ b_{0} &amp;\\sim N(0, \\sigma^2_{b0}=625) \\\\ x_{ij} &amp;\\sim U(-5, 6) \\end{align*}\\] El vector de parámetros de este modelo es \\(\\boldsymbol{\\Theta}=(\\beta_0=4, \\beta_1=-6, \\sigma_y=4, \\sigma_{b0}=25)^\\top\\). Solución. El código para simular las 500 observaciones se muestra a continuación. Observe que se fijó la semilla en dos ocasiones para que el lector pueda replicar el ejemplo y obtener los mismos resultados. ni &lt;- 50 G &lt;- 10 nobs &lt;- ni * G grupo &lt;- factor(rep(x=1:G, each=ni)) obs &lt;- rep(x=1:ni, times=G) set.seed(1234567) x &lt;- runif(n=nobs, min=-5, max=6) set.seed(1234567) b0 &lt;- rnorm(n=G, mean=0, sd=sqrt(625)) # Intercepto aleatorio b0 &lt;- rep(x=b0, each=ni) # El mismo intercepto aleatorio pero repetido media &lt;- 4 - 6 * x + b0 set.seed(1234567) y &lt;- rnorm(n=nobs, mean=media, sd=sqrt(16)) datos &lt;- data.frame(obs, grupo, b0, x, media, y) Vamos a explorar los datos simulados. library(rmarkdown) paged_table(datos, options = list(rows.print = 6)) El siguiente paso es dibujar los datos para explorar si sería apropiado usar un modelo con intercepto aleatorio (obvio porque así se simularon los datos). El código para dibujar los datos se muestra abajo. library(ggplot2) ggplot(datos, aes(x, y, color=grupo) ) + geom_point() + labs(colour=&quot;Grupo/Cluster&quot;) En la figura anterior se observa un patrón claro, todas las 10 nubes de puntos tienen la misma pendiente pero diferente intercepto con el eje vertical, eso se debe a que en la simulación se incluyó un \\(b_0\\). Para estimar los parámetros del modelos se usa la función mler de la siguiente forma. library(lme4) fit1 &lt;- lmer(y ~ x + (1 | grupo), data = datos) La función summary se puede usar sobre el objeto fit1 para obtener una tabla de resumen, a continuación se ilustra el uso y la salida de summary. summary(fit1) Según el resultado anterior \\(\\hat{\\boldsymbol{\\Theta}}=(\\hat{\\beta}_0=2.2378, \\hat{\\beta}_1=-6.0264, \\hat{\\sigma}_y=3.9352, \\hat{\\sigma}_{b0}=25.369)^\\top\\) mientras que el vector real de parámetros es \\(\\boldsymbol{\\Theta}=(\\beta_0=4, \\beta_1=-6, \\sigma_y=4, \\sigma_{b0}=25)^\\top\\). Compare los resultados de la tabla anterior obtenida con la función lmer anterior con los resultados obtenidos con la función lme de capítulo 6. ¿Hay alguna similitud? Ejemplo: recuperando los interceptos aleatorios ¿Cómo se pueden obtener los interceptos aleatorios a partir del modelo ajustado en la sección anterior? Solución. Para obtener los interceptos aleatorios se usa la función ranef del paquete lme4 de Bates et al. (2021). A continuación vamos a obtener los interceptos aleatorios y los vamos a comparar con los \\(b_0\\) simulados. interceptos_aleatorios &lt;- ranef(fit1) cbind(interceptos_aleatorios$grupo, b0=unique(b0)) ## (Intercept) b0 ## 1 5.388795 3.917594 ## 2 35.790443 34.345280 ## 3 19.885504 18.266756 ## 4 -31.893039 -33.770023 ## 5 1.074942 -0.212874 ## 6 10.680482 8.024547 ## 7 -43.320003 -44.453710 ## 8 25.363102 22.737596 ## 9 -20.648195 -22.985108 ## 10 -2.322031 -3.942871 De la salida anterior vemos que los \\(\\tilde{b}_0\\) son cercanos a los valores reales de \\(b_0\\). La comparación anterior solo es posible cuando usamos datos simulados. Cuando se usan datos de un fenómeno real no se tienen los valores de \\(b_0\\). 4.2 Función glmer La función glmer es la función del paquete lme4 para ajustar modelo lineales generalizados mixtos y su estructura es la siguiente: glmer(formula, data = NULL, family = gaussian, control = glmerControl(), start = NULL, verbose = 0L, nAGQ = 1L, subset, weights, na.action, offset, contrasts = NULL, mustart, etastart, devFunOnly = FALSE) Los principales argumentos de la función son: formula: es una fórmula similar a la usada en el modelo lineal clásico. Un ejemplo de fórmula sería y ~ 1 + x1 + x2 + (1 + x2) con la cual se indican los efectos fijos y los efectos aleatorios del modelo. Más abajo hay una tabla con más detalles sobre la fórmula. data: marco de datos donde están las variables. family: argumento para seleccionar la distribución de la variable respuesta. Para más detalles de las distribuciones y funciones de enlace se recomienda ver la ayuda de la función family escribiendo esto en la consola ?family. Ejemplo: modelo gamma con intercepto aleatorio En este ejemplo vamos a simular observaciones \\(n_i=20\\) observaciones para \\(G=10\\) grupos (en total 200 obs) que tengan la estructura mostrada abajo. El objetivo del ejemplo es ilustrar el uso de la función glmer para estimar los parámetros del modelo. \\[\\begin{align*} y_{ij} | b_0 &amp;\\sim Gamma(\\mu_{ij}, \\phi) \\\\ \\log(\\mu_{ij}) &amp;= 2 - 8 x_{ij} + b_{0i} \\\\ \\phi &amp;= 0.5 \\\\ b_{0} &amp;\\sim N(0, \\sigma^2_{b0}=9) \\\\ x_{ij} &amp;\\sim U(0, 1) \\end{align*}\\] El vector de parámetros de este modelo es \\(\\boldsymbol{\\Theta}=(\\beta_0=2, \\beta_1=-8, \\phi=0.5, \\sigma_{b0}=3)^\\top\\). Solución. La función rgamma_glm que se muestra a continuación es una modificación de la función rgamma para tener la parametrización usada en los glm. rgamma_glm &lt;- function(n, mu, phi) { x &lt;- rgamma(n=n, shape=1/phi, scale=mu*phi) return(x) } A continuación el código para simular datos del modelo de interés. ni &lt;- 20 G &lt;- 10 nobs &lt;- ni * G grupo &lt;- factor(rep(x=1:G, each=ni)) obs &lt;- rep(x=1:ni, times=G) set.seed(123456) x &lt;- runif(n=nobs, min=0, max=1) set.seed(123456) b0 &lt;- rnorm(n=G, mean=0, sd=sqrt(9)) # Intercepto aleatorio b0 &lt;- rep(x=b0, each=ni) # El mismo intercepto aleatorio pero repetido media &lt;- exp(2 - 8 * x + b0) set.seed(123456) y &lt;- rgamma_glm(n=nobs, mu=media, phi=0.5) datos &lt;- data.frame(obs, grupo, b0, x, media, y) Vamos a explorar los datos simulados. library(rmarkdown) paged_table(datos, options = list(rows.print = 6, cols.print=6)) El siguiente paso es explorar los datos simulados. El código para dibujar los datos se muestra abajo. library(ggplot2) ggplot(datos, aes(x, y, color=grupo) ) + geom_point() + labs(colour=&quot;Grupo/Cluster&quot;) Para estimar los parámetros del modelos se usa la función glmer de la siguiente forma. library(lme4) fit2 &lt;- glmer(y ~ x + (1 | grupo), family=Gamma(link=&quot;log&quot;), data = datos) La función summary se puede usar sobre el objeto fit2 para obtener una tabla de resumen, a continuación se muestra la salida de summary. summary(fit2) ## Generalized linear mixed model fit by maximum likelihood (Laplace ## Approximation) [glmerMod] ## Family: Gamma ( log ) ## Formula: y ~ x + (1 | grupo) ## Data: datos ## ## AIC BIC logLik deviance df.resid ## 591.6 604.8 -291.8 583.6 196 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -1.4164 -0.7151 -0.2155 0.5631 3.0609 ## ## Random effects: ## Groups Name Variance Std.Dev. ## grupo (Intercept) 4.3265 2.0800 ## Residual 0.4728 0.6876 ## Number of obs: 200, groups: grupo, 10 ## ## Fixed effects: ## Estimate Std. Error t value Pr(&gt;|z|) ## (Intercept) 4.3965 0.9566 4.596 4.31e-06 *** ## x -8.0784 0.0411 -196.549 &lt; 2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Correlation of Fixed Effects: ## (Intr) ## x -0.021 Según el resultado anterior \\(\\hat{\\boldsymbol{\\Theta}}=(\\hat{\\beta}_0=4.3965, \\hat{\\beta}_1=-8.0784, \\hat{\\phi}=0.4728, \\hat{\\sigma}_{bo}=4.3265)^\\top\\) mientras que el vector real de parámetros es \\(\\boldsymbol{\\Theta}=(\\beta_0=2, \\beta_1=-8, \\phi=0.50, \\sigma_{b0}=3)^\\top\\). El valor de \\(\\hat{\\phi}\\) se encuentra en la línea Residual y columna Variance del bloque Random effects que está en el summary. Ejemplo: modelo inversa gaussiana con intercepto y pendiente aleatoria En este ejemplo vamos a simular observaciones \\(n_i=20\\) observaciones para \\(G=10\\) grupos (en total 200 obs) que tengan la estructura mostrada abajo. El objetivo del ejemplo es ilustrar el uso de la función glmer para estimar los parámetros del modelo. \\[\\begin{align*} y_{ij} | b_0, b_1 &amp;\\sim InvGauss(\\mu_{ij}, \\phi) \\\\ \\log(\\mu_{ij}) &amp;= 2 - 8 x_{ij} + b_{0i} + b_{1i} x_{ij} \\\\ \\phi &amp;= 0.5 \\\\ \\left ( \\begin{matrix} b_{0} \\\\ b_{1} \\end{matrix} \\right ) &amp;\\sim N\\left ( \\left [ \\begin{matrix} 0 \\\\ 0 \\end{matrix} \\right ], \\left [ \\begin{matrix} \\sigma^2_{b0}=1 &amp; \\sigma_{b01}=0.5 \\\\ \\sigma_{b01} &amp; \\sigma^2_{b1}=1 \\end{matrix} \\right ] \\right ) \\\\ x_{ij} &amp;\\sim U(0, 1) \\end{align*}\\] El vector de parámetros de este modelo es \\(\\boldsymbol{\\Theta}=(\\beta_0=2, \\beta_1=-8, \\phi=0.5, \\sigma_{b0}^2=1, \\sigma_{b1}^2=1, \\sigma_{b01}=0.5)^\\top\\). Solución. Para simular valores de una distribución inversa gaussiana vamos a usar la función rinvgauss del paquete statmod de Smyth et al. (2021). A continuación el código para simular datos del modelo de interés. ni &lt;- 20 G &lt;- 10 nobs &lt;- ni * G grupo &lt;- factor(rep(x=1:G, each=ni)) obs &lt;- rep(x=1:ni, times=G) set.seed(12345) x &lt;- runif(n=nobs, min=0, max=1) set.seed(12345) Sigma &lt;- matrix(c(1, 0.5, # Matriz de var-cov 0.5, 1), ncol=2, nrow=2) b &lt;- MASS::mvrnorm(n=G, mu=rep(0, 2), Sigma=Sigma) # Simulando b0 y b1 b &lt;- apply(b, MARGIN=2, function(c) rep(c, each=ni)) # Replicando b0 &lt;- as.vector(b[, 1]) # Separando los b0 b1 &lt;- as.vector(b[, 2]) # Separando los b1 media &lt;- exp(2 - 8 * x + b0 + b1 * x) phi &lt;- 0.5 set.seed(12345) y &lt;- statmod::rinvgauss(n=nobs, mean=media, dispersion=phi) datos &lt;- data.frame(obs, grupo, b0, x, media, y) Vamos a explorar los datos simulados. library(rmarkdown) paged_table(datos, options = list(rows.print = 6, cols.print=6)) El siguiente paso es explorar los datos simulados. El código para dibujar los datos se muestra abajo. library(ggplot2) ggplot(datos, aes(x, y, color=grupo) ) + geom_point() + labs(colour=&quot;Grupo/Cluster&quot;) Para estimar los parámetros del modelos se usa la función glmer de la siguiente forma. library(lme4) fit3 &lt;- glmer(y ~ x + (1 + x | grupo), family=inverse.gaussian(link=&quot;log&quot;), data = datos) La función summary se puede usar sobre el objeto fit3 para obtener una tabla de resumen, a continuación se muestra la salida de summary. summary(fit3) ## Generalized linear mixed model fit by maximum likelihood (Laplace ## Approximation) [glmerMod] ## Family: inverse.gaussian ( log ) ## Formula: y ~ x + (1 + x | grupo) ## Data: datos ## ## AIC BIC logLik deviance df.resid ## -1060.0 -1040.2 536.0 -1072.0 194 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -1.7657 -0.5806 -0.1294 0.4044 6.5944 ## ## Random effects: ## Groups Name Variance Std.Dev. Corr ## grupo (Intercept) 0.6118 0.7822 ## x 0.3740 0.6116 0.33 ## Residual 0.7266 0.8524 ## Number of obs: 200, groups: grupo, 10 ## ## Fixed effects: ## Estimate Std. Error t value Pr(&gt;|z|) ## (Intercept) 1.7907 0.2947 6.077 1.22e-09 *** ## x -8.0237 0.2345 -34.218 &lt; 2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Correlation of Fixed Effects: ## (Intr) ## x 0.268 Según el resultado anterior \\(\\hat{\\boldsymbol{\\Theta}}=(\\hat{\\beta}_0=1.7907, \\hat{\\beta}_1=-8.0237, \\hat{\\phi}=0.7266, \\hat{\\sigma}_{b0}^2=0.6118, \\hat{\\sigma}_{b1}^2=0.3740, \\hat{\\sigma}_{b01}=0.1579)^\\top\\) mientras que el vector real de parámetros es \\(\\boldsymbol{\\Theta}=(\\beta_0=2, \\beta_1=-8, \\phi=0.5, \\sigma_{b0}^2=1, \\sigma_{b1}^2=1, \\sigma_{b01}=0.5)^\\top\\). El parámetro estimado \\(\\hat{\\sigma}_{b01}\\) se obtiene utilizando la ecuación de correlación (\\(\\rho\\)) que relaciona la covarianza y desviaciones de los efectos aleatorios: \\(\\rho_{b0b1} = \\sigma_{b0b1}/(\\sigma_{b0} \\times \\sigma_{b1})\\). El valor de \\(\\hat{\\phi}\\) se encuentra en la línea Residual y columna Variance del bloque Random effects que está en el summary. References "],["apli-lme4.html", "5 Aplicación con lme4 Ejercicios", " 5 Aplicación con lme4 En este capítulo se mostrará como usar el paquete lme4 para la aplicación de modelos mixtos con la base de datos sleepstudy del mismo paquete. A continuación la base de datos a utilizar. library(lme4) head(sleepstudy) ## Reaction Days Subject ## 1 249.5600 0 308 ## 2 258.7047 1 308 ## 3 250.8006 2 308 ## 4 321.4398 3 308 ## 5 356.8519 4 308 ## 6 414.6901 5 308 Esta base de datos sobre el tiempo de reacción promedio por día para un conjunto de individuos, en un estudio de privación del sueño, contiene la información sobre el tiempo de reacción promedio (Reaction), el número de días de privación del sueño (Days), donde el día 0 corresponde al día en el que los indiviuos tenían su cantidad normal de sueño, y el número del individuo (en total 18) sobre el que se realizó la observación (Subject). A partir del día 0, hubo una restricción en cada individuo a 3 horas de sueño por noche. library(ggplot2) ggplot(data = sleepstudy, aes(x = Days, y = Reaction, color = Subject)) + geom_point() + theme_bw() + facet_wrap(~ Subject) + theme(legend.position = &quot;none&quot;) De la figura anterior vemos que el tiempo de reacción promedio, tanto en el día 0 como en los siguientes días de prueba (del día 1 al día 9), son distintos en cada uno de los individuos. Esta situación conlleva a probar la hipótesis de que el tiempo de reacción promedio en una serie de pruebas varía según los individuos. Esto es, ajustar un modelo donde el intercepto y la pendiente se consideran como efectos aleatorios. Un modelo lineal mixto que describe la anterior situación se puede escribir como: \\[\\begin{align*} Reaction_{ij} | b_0, b_1 &amp;\\sim N(\\mu_{ij}, \\sigma^2_{Reaction}) \\\\ \\mu_{ij} &amp;= \\beta_0 + \\beta_1 Days_{ij} + b_{0i} + b_{1i} Days_{ij} \\\\ \\left ( \\begin{matrix} b_{0} \\\\ b_{1} \\end{matrix} \\right ) &amp;\\sim N\\left ( \\left [ \\begin{matrix} 0 \\\\ 0 \\end{matrix} \\right ], \\left [ \\begin{matrix} \\sigma^2_{b0} &amp; \\sigma_{b01} \\\\ \\sigma_{b01} &amp; \\sigma^2_{b1} \\end{matrix} \\right ] \\right ) \\end{align*}\\] Aquí, los individuos (\\(i\\)) varían en el tiempo de reacción promedio tanto en su intercepto (\\(b_{0i}\\)) como en su pendiente (\\(b_{1i}\\)), que en conjunto componen la varianza total en dicho tiempo atribuible a la variación entre individuos. Esta contribución individual se cuantifica usando un modelo de intercepto y pendiente aleatoria con distribución normal (\\(N\\)). La variación entre individuos en intercepto y pendiente es \\(\\sigma^2_{b0}\\) y \\(\\sigma^2_{b1}\\), respectivamente. La covarianza entre el intercepto y la pendiente esta dada por \\(\\sigma_{b01}\\). El vector de parámetros para este modelo sería \\(\\boldsymbol{\\Theta}=(\\beta_0, \\beta_1, \\sigma_{reaction}, \\sigma_{b0}, \\sigma_{b1}, \\sigma_{b0b1})^\\top\\). Para ajustar el modelo de intercepto y pendiente aleatoria planteado usando el paquete lme4 podemos usar el siguiente código: fit &lt;- lmer(Reaction ~ Days + (Days | Subject), REML = TRUE, data = sleepstudy) Para obtener la tabla de resumen usamos: summary(fit) ## Linear mixed model fit by REML [&#39;lmerMod&#39;] ## Formula: Reaction ~ Days + (Days | Subject) ## Data: sleepstudy ## ## REML criterion at convergence: 1743.6 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -3.9536 -0.4634 0.0231 0.4634 5.1793 ## ## Random effects: ## Groups Name Variance Std.Dev. Corr ## Subject (Intercept) 612.10 24.741 ## Days 35.07 5.922 0.07 ## Residual 654.94 25.592 ## Number of obs: 180, groups: Subject, 18 ## ## Fixed effects: ## Estimate Std. Error t value ## (Intercept) 251.405 6.825 36.838 ## Days 10.467 1.546 6.771 ## ## Correlation of Fixed Effects: ## (Intr) ## Days -0.138 De la salida anterior se obtienen los siguientes parámetros (\\(\\Theta\\)): \\(\\Theta\\) \\(\\beta_{0}\\) 251.40 \\(\\beta_{1}\\) 10.47 \\(\\sigma_{reaction}\\) 25.59 \\(\\sigma_{b0}\\) 24.74 \\(\\sigma_{b1}\\) 5.92 \\(\\sigma_{b0b1}\\) 10.25 * El útimo parámetro estimado se obtiene utilizando la ecuación de correlación (\\(\\rho\\)) que relaciona la covarianza y desviaciones de los efectos aleatorios: \\(\\rho_{b0b1} = \\sigma_{b0b1}/(\\sigma_{b0} imes \\sigma_{b1})\\). Usando la información anterior se puede escribir el modelo ajustado de la siguiente manera: \\[\\begin{align*} Reaction_{ij} &amp;\\sim N(\\hat{\\mu}_{ij}, 25.59^2) \\\\ \\hat{\\mu}_{ij} &amp;= 251.40 + 10.47 Days_{ij} + \\tilde{b}_{0i} + \\tilde{b}_{1i} Days_{ij} \\\\ \\left ( \\begin{matrix} b_{0} \\\\ b_{1} \\end{matrix} \\right ) &amp;\\sim N\\left ( \\left [ \\begin{matrix} 0 \\\\ 0 \\end{matrix} \\right ], \\left [ \\begin{matrix} 24.74^2 &amp; 10.25 \\\\ 10.25 &amp; 5.92^2 \\end{matrix} \\right ] \\right ) \\end{align*}\\] Los elementos \\(b_{0i}\\) y \\(b_{1i}\\) se deben substituir por sus respectivas predicciones \\(\\tilde{b}_{0i}\\) y \\(\\tilde{b}_{1i}\\) y se pueden obtener del modelo ajustado de esta forma: ranef(fit) ## $Subject ## (Intercept) Days ## 308 2.2585509 9.1989758 ## 309 -40.3987381 -8.6196806 ## 310 -38.9604090 -5.4488565 ## 330 23.6906196 -4.8143503 ## 331 22.2603126 -3.0699116 ## 332 9.0395679 -0.2721770 ## 333 16.8405086 -0.2236361 ## 334 -7.2326151 1.0745816 ## 335 -0.3336684 -10.7521652 ## 337 34.8904868 8.6282652 ## 349 -25.2102286 1.1734322 ## 350 -13.0700342 6.6142178 ## 351 4.5778642 -3.0152621 ## 352 20.8636782 3.5360011 ## 369 3.2754656 0.8722149 ## 370 -25.6129993 4.8224850 ## 371 0.8070461 -0.9881562 ## 372 12.3145921 1.2840221 ## ## with conditional variances for &quot;Subject&quot; Y los valores de los efectos fijos estimados se pueden obtener así: fixef(fit) ## (Intercept) Days ## 251.40510 10.46729 Con base en la información anterior de efectos aleatorios y fijos, es posible escribir la ecuación del modelo para cada individuo. Para esto, se debe considerar los efectos fijos estimados (\\(\\hat{\\beta}_0 \\approx 251.40\\) y \\(\\hat{\\beta}_1\\approx 10.47\\)) y los efectos aleatorios de cada uno de los individuos (por ejemplo para el individuo 308, \\(\\tilde{b}_{0, i=308} \\approx 2.26\\) y \\(\\tilde{b}_{1, i=308} \\approx 9.20\\)). Así, el valor medio del individuo 308 se calcula como: \\[\\begin{align*} \\hat{\\mu}_{i=308, j} &amp;= \\hat{\\beta}_0 + \\hat{\\beta}_0 \\, Days_{i=308, j} + \\tilde{b}_{0, i=308} + \\tilde{b}_{1, i=308} \\, Days_{i=308, j} \\\\ \\hat{\\mu}_{i=308, j} &amp;= 251.40 + 10.47 \\, Days_{i=308, j} 2.26 + 9.20 \\, Days_{i=308, j} \\\\ \\hat{\\mu}_{i=308, j} &amp;= 253.66 + 19.67 \\, Days_{i=308, j} \\end{align*}\\] Lo anterior se puede resumir en el siguiente modelo. \\[\\begin{align*} Reaction_{i=308, j} &amp;\\sim N(\\hat{\\mu}_{i=308, j}, \\hat{\\sigma}^2_{Reaction}) \\\\ \\hat{\\mu}_{i=308, j} &amp;= 253.66 + 19.67 \\, Days_{i=308, j} \\\\ \\hat{\\sigma}_{Reaction} &amp;= 25.59 \\end{align*}\\] Los efectos fijos y aleatorios de la expresión anterior para cada uno de los individuos se pueden obtener con R de la siguiente forma: coef(fit) ## $Subject ## (Intercept) Days ## 308 253.6637 19.6662617 ## 309 211.0064 1.8476053 ## 310 212.4447 5.0184295 ## 330 275.0957 5.6529356 ## 331 273.6654 7.3973743 ## 332 260.4447 10.1951090 ## 333 268.2456 10.2436499 ## 334 244.1725 11.5418676 ## 335 251.0714 -0.2848792 ## 337 286.2956 19.0955511 ## 349 226.1949 11.6407181 ## 350 238.3351 17.0815038 ## 351 255.9830 7.4520239 ## 352 272.2688 14.0032871 ## 369 254.6806 11.3395008 ## 370 225.7921 15.2897709 ## 371 252.2122 9.4791297 ## 372 263.7197 11.7513080 ## ## attr(,&quot;class&quot;) ## [1] &quot;coef.mer&quot; A continuación podras observar el diagrama de dispersión mostrado al inicio de este capitulo, agregandole a la misma la recta de regresión para cada individuo. El código de R para obtener esto se presenta a continuación: fit &lt;- lmer(Reaction ~ Days + (Days | Subject), REML = TRUE, data = sleepstudy) sleepstudy$pred_inter_pend_aleatorio &lt;- predict(fit) ggplot(data = sleepstudy, aes(x = Days, y = pred_inter_pend_aleatorio, color = Subject)) + geom_line() + geom_point(aes(x = Days, y = Reaction, color = Subject)) + geom_abline(intercept = 251.40, slope = 10.47, color = &quot;black&quot;, linetype = &quot;dashed&quot;, size = 0.5) + theme_bw() + facet_wrap(~ Subject) + theme(legend.position = &quot;none&quot;) La figura anterior corresponde a un modelo de intercepto y pendiente aleatoria, en el que se permite que tanto los interceptos como las pendientes varíen según los individuos. Las líneas continuas corresponde a la recta de regresión ajustada a los datos. Los puntos representan las observaciones (tiempo de reacción promedio por día) medidas en cada uno de los individuos. La línea negra discontinua representa el valor medio global de la distribución de los efectos aleatorios. A continuación podra observar distintas figuras donde se ajustaron cuatro modelos distintos, entre ellos el modelo mixto con intercepto y pendiente aleatoria ya evaluado aquí (Figura 4). Con base en estas figuras, se plantean los ejercicios posteriores a las mismas figuras: Ejercicios Ajuste el modelo con intercepto aleatorio mostrado en la anterior Figura 2. ¿Qué opina de este modelo? Ajuste el modelo con pendiente aleatoria presentada en la anterior Figura 3. ¿Qué opina de este modelo? Ajustar solo un intercepto aleatorio permite que los individuos varíen asumiendo que los mismos tienen una pendiente común (Figura 2). Al ajustar solo una pendiente aleatoria (Figura 3) permite que la pendiente de un predictor varíe en función de los individuos (la variable de agrupación). Con base esto y teniendo en cuenta el modelo de intercepto y pendiente aleatoria (Figura 4), evalúe cual de estos estos modelos permite un mejor ajuste de los datos presentados en la base de datos sleepstudy del paquete lme4. "],["pac-nlme.html", "6 Paquete nlme 6.1 Función lme Ejemplo: modelo normal con intercepto aleatorio", " 6 Paquete nlme El paquete nlme de José Pinheiro, Bates, and R-core (2021) es otro de los paquetes para modelos mixtos. Al visitar este enlace se encontrará la página de apoyo del paquete, allí se puede consultar el manual de referencia. 6.1 Función lme La función lme es la principal función del paquete nlme. Esta función sirve para ajustar un modelo mixto y su estructura es la siguiente: lme(fixed, data, random, correlation, weights, subset, method, na.action, control, contrasts = NULL, keep.data = TRUE) Los principales argumentos de la función son: formula: es una fórmula similar a la usada en el modelo lineal clásico. Un ejemplo de fórmula sería y ~ 1 + x1 + x2 con la cual se indican los efectos fijos del modelo. - data: marco de datos donde están las variables. random: es una fórmula solo con lado derecho. Si queremos indicar intercepto aleatorio se escribe ~ 1 | group y si se desea intercepto y pendiente aleatoria se escribe ~ 1 + x2 | group. correlation: es un parámetro opcional para indicar la estructura de correlación entre las observaciones de cada grupo. Para más detalles consulte la ayuda de la función corClasses. method: valor lógico que sirve para indicar si queremos estimaciones maximizando la verosimilitud restringida o la verosimilitud usual, las dos opciones son ML o REML. Ejemplo: modelo normal con intercepto aleatorio En este ejemplo vamos a simular observaciones \\(n_i=50\\) observaciones para \\(G=10\\) grupos (en total 500 obs) que tengan la estructura mostrada abajo. El objetivo del ejemplo es ilustrar el uso de la función lmer para estimar los parámetros del modelo. \\[\\begin{align*} y_{ij} | b_0 &amp;\\sim N(\\mu_{ij}, \\sigma^2_y) \\\\ \\mu_{ij} &amp;= 4 - 6 x_{ij} + b_{0i} \\\\ \\sigma^2_y &amp;= 16 \\\\ b_{0} &amp;\\sim N(0, \\sigma^2_{b0}=625) \\\\ x_{ij} &amp;\\sim U(-5, 6) \\end{align*}\\] El vector de parámetros de este modelo es \\(\\boldsymbol{\\Theta}=(\\beta_0=4, \\beta_1=-6, \\sigma_y=4, \\sigma_{b0}=25)^\\top\\). Solución. El código para simular las 500 observaciones se muestra a continuación. Observe que se fijó la semilla en dos ocasiones para que el lector pueda replicar el ejemplo y obtener los mismos resultados. ni &lt;- 50 G &lt;- 10 nobs &lt;- ni * G grupo &lt;- factor(rep(x=1:G, each=ni)) obs &lt;- rep(x=1:ni, times=G) set.seed(1234567) x &lt;- runif(n=nobs, min=-5, max=6) set.seed(1234567) b0 &lt;- rnorm(n=G, mean=0, sd=sqrt(625)) # Intercepto aleatorio b0 &lt;- rep(x=b0, each=ni) # El mismo intercepto aleatorio pero repetido media &lt;- 4 - 6 * x + b0 set.seed(1234567) y &lt;- rnorm(n=nobs, mean=media, sd=sqrt(16)) datos &lt;- data.frame(obs, grupo, b0, x, media, y) Vamos a explorar los datos simulados. library(rmarkdown) paged_table(datos, options = list(rows.print = 6)) El siguiente paso es dibujar los datos para explorar si sería apropiado usar un modelo con intercepto aleatorio (obvio porque así se simularon los datos). El código para dibujar los datos se muestra abajo. library(ggplot2) ggplot(datos, aes(x, y, color=grupo) ) + geom_point() + labs(colour=&quot;Grupo/Cluster&quot;) En la figura anterior se observa un patrón claro, todas las 10 nubes de puntos tienen la misma pendiente pero diferente intercepto con el eje vertical, eso se debe a que en la simulación se incluyó un \\(b_0\\). Para estimar los parámetros del modelos se usa la función mler de la siguiente forma. library(nlme) fit1 &lt;- lme(y ~ x, random = ~ 1 | grupo, data=datos) La función summary se puede usar sobre el objeto fit para obtener una tabla de resumen, a continuación se ilustra el uso y la salida de summary. summary(fit1) Según el resultado anterior \\(\\hat{\\boldsymbol{\\Theta}}=(\\hat{\\beta}_0=2.2378, \\hat{\\beta}_1=-6.0264, \\hat{\\sigma}_y=3.9354, \\hat{\\sigma}_{b0}=25.3690)^\\top\\) mientras que el vector real de parámetros es \\(\\boldsymbol{\\Theta}=(\\beta_0=4, \\beta_1=-6, \\sigma_y=4, \\sigma_{b0}=25)^\\top\\). Compare los resultados de la tabla anterior obtenida con la función lme anterior con los resultados obtenidos con la función lmer de capítulo 4. ¿Hay alguna similitud? References "],["apli-nlme.html", "7 Aplicación con nlme Ejercicios", " 7 Aplicación con nlme En este capítulo se mostrará como usar el paquete nlme para la aplicación de modelos mixtos con la base de datos Oxboys del mismo paquete. A continuación la base de datos a utilizar. library(nlme) head(Oxboys) ## Grouped Data: height ~ age | Subject ## Subject age height Occasion ## 1 1 -1.0000 140.5 1 ## 2 1 -0.7479 143.4 2 ## 3 1 -0.4630 144.8 3 ## 4 1 -0.1643 147.1 4 ## 5 1 -0.0027 147.7 5 ## 6 1 0.2466 150.2 6 Esta base de datos sobre crecimiento contiene la información sobre altura (heigth), edad estandarizada (age) de un grupo de 26 jóvenes. Como la base de datos Oxboys es de la clase groupedData, es posible aplicar un plot directamente y el resultado se muestra continuación. plot(Oxboys) Es posible convertir un data.frame para que tenga la clase groupedData, consulte la ayuda de la función groupedData del paquete nlme para más detalles. De la figura anterior vemos que las curvas de crecimiento inician a diferente altura (intercepto) y que la pendiente del crecimiento no son todas iguales, por ejemplo, el individuo 21 creció más rápido que el individuo 3. Esto nos hace pensar que un modelo con intercepto y pendiente aleatoria podrían ser adecuados para modelar el crecimiento. En las siguientes ecuaciones se resume el modelo matemático que interesa en esta situación. \\[\\begin{align*} Height_{ij} | b_0, b_1 &amp;\\sim N(\\mu_{ij}, \\sigma^2_{Heigth}) \\\\ \\mu_{ij} &amp;= \\beta_0 + \\beta_1 Age_{ij} + b_{0i} + b_{1i} Age_{ij} \\\\ \\left ( \\begin{matrix} b_{0} \\\\ b_{1} \\end{matrix} \\right ) &amp;\\sim N\\left ( \\left ( \\begin{matrix} 0 \\\\ 0 \\end{matrix} \\right ), \\left ( \\begin{matrix} \\sigma^2_{b0} &amp; \\sigma_{b01} \\\\ \\sigma_{b01} &amp; \\sigma^2_{b1} \\end{matrix} \\right ) \\right ) \\end{align*}\\] El vector de parámetros para este modelo sería \\(\\boldsymbol{\\Theta}=(\\beta_0, \\beta_1, \\sigma_{height}, \\sigma_{b0}, \\sigma_{b1}, \\sigma_{b0b1})^\\top\\). Para ajustar este modelo a los datos con el paquete nlme podemos usar el siguiente código. fit &lt;- lme(height ~ age, random= ~ 1 + age | Subject, data=Oxboys, method=&quot;REML&quot;) Para obtener la tabla de resumen usamos: summary(fit) ## Linear mixed-effects model fit by REML ## Data: Oxboys ## AIC BIC logLik ## 736.091 756.7714 -362.0455 ## ## Random effects: ## Formula: ~1 + age | Subject ## Structure: General positive-definite, Log-Cholesky parametrization ## StdDev Corr ## (Intercept) 8.081077 (Intr) ## age 1.680717 0.641 ## Residual 0.659889 ## ## Fixed effects: height ~ age ## Value Std.Error DF t-value p-value ## (Intercept) 149.37175 1.5854173 207 94.21605 0 ## age 6.52547 0.3363003 207 19.40370 0 ## Correlation: ## (Intr) ## age 0.628 ## ## Standardized Within-Group Residuals: ## Min Q1 Med Q3 Max ## -2.65092109 -0.57493341 -0.02842894 0.59604254 2.60496077 ## ## Number of Observations: 234 ## Number of Groups: 26 De la salida anterior se obtiene que \\(\\hat{\\boldsymbol{\\Theta}}=(\\hat{\\beta}_0=149.37, \\hat{\\beta}_1=6.53, \\hat{\\sigma}_{height}=0.66, \\hat{\\sigma}_{b0}=8.08, \\hat{\\sigma}_{b1}=1.68, \\hat{\\sigma}_{b0b1}=8.71)^\\top\\). La estimación \\(\\hat{\\sigma}_{b0b1}\\) no aparece directamente en el summary pero se obtiene utilizando la ecuación \\(Cor=Cov/(\\sigma_1 \\sigma_2)\\) que relaciona correlación, covarianza y desviaciones de los efectos aleatorios. Usando la información anterior se puede escribir el modelo ajustado de la siguiente manera. \\[\\begin{align*} Height_{ij} &amp;\\sim N(\\hat{\\mu}_{ij}, 0.66^2) \\\\ \\hat{\\mu}_{ij} &amp;= 149.37 + 6.53 Age_{ij} + b_{0i} + b_{1i} Age_{ij} \\\\ \\left ( \\begin{matrix} b_{0} \\\\ b_{1} \\end{matrix} \\right ) &amp;\\sim N\\left ( \\left ( \\begin{matrix} 0 \\\\ 0 \\end{matrix} \\right ), \\left ( \\begin{matrix} 8.08^2 &amp; 8.71 \\\\ 8.71 &amp; 1.68^2 \\end{matrix} \\right ) \\right ). \\end{align*}\\] Los elementos \\(b_{0i}\\) y \\(b_{1i}\\) se deben substituir por sus respectivas predicciones \\(\\tilde{b}_{0i}\\) y \\(\\tilde{b}_{1i}\\) y se pueden obtener del modelo ajustado así: ranef(fit) ## (Intercept) age ## 10 -19.0972476 -2.78657472 ## 26 -11.3675996 -0.97474075 ## 25 -10.1595528 -2.42702035 ## 9 -11.2213331 -0.58069044 ## 2 -6.5096277 -1.07136271 ## 6 -2.5902388 -2.41771656 ## 7 -3.2473132 -1.46379286 ## 17 -6.3744842 1.89443713 ## 16 -1.8344703 -1.86707015 ## 15 -5.0856366 0.51526141 ## 8 -1.0776201 -0.06615528 ## 20 2.0850836 -1.99239802 ## 1 -1.2464285 0.59919226 ## 18 1.8031920 -0.51486646 ## 5 2.0531168 -0.24308081 ## 23 1.6937341 0.63140824 ## 11 0.6839704 1.85733185 ## 21 1.1525543 0.91894343 ## 3 6.2613001 -1.58181075 ## 24 3.7645669 0.25652772 ## 22 5.1957592 1.50551719 ## 12 7.4308033 0.52297645 ## 13 6.7004368 1.89758007 ## 14 10.0986013 2.09367207 ## 19 15.1957040 2.50720025 ## 4 15.6927297 2.78723179 Los valores de los efectos fijos estimados se pueden obtener así: fixef(fit) ## (Intercept) age ## 149.371753 6.525469 Usando la información de los efectos fijo y aleatorios obtenidos antes, es posible escribir la ecuación del modelo para cada individuo. Los efectos fijos estimados fueron \\(\\hat{\\beta}_0 \\approx 149.37\\) y \\(\\hat{\\beta}_1\\approx 6.53\\). Para el sujeto # 10 se obtuvo \\(\\tilde{b}_{0, i=10} \\approx -19.10\\) y \\(\\tilde{b}_{1, i=10} \\approx -2.79\\), así la media del individuo # 10 se calcula así: \\[\\begin{align*} \\hat{\\mu}_{i=10, j} &amp;= \\hat{\\beta}_0 + \\hat{\\beta}_0 \\, Age_{i=10, j} + \\tilde{b}_{0, i=10} + \\tilde{b}_{1, i=10} \\, Age_{i=10, j} \\\\ \\hat{\\mu}_{i=10, j} &amp;= 149.37 + 6.53 \\, Age_{i=10, j} - 19.10 - 2.79 \\, Age_{i=10, j} \\\\ \\hat{\\mu}_{i=10, j} &amp;= 130.27 + 3.74 \\, Age_{i=10, j} \\end{align*}\\] Lo anterior se puede resumir en el siguiente modelo. \\[\\begin{align*} Height_{i=10, j} &amp;\\sim N(\\hat{\\mu}_{i=10, j}, \\hat{\\sigma}^2_{Height}) \\\\ \\hat{\\mu}_{i=10, j} &amp;= 130.27 + 3.74 \\, Age_{i=10, j} \\\\ \\hat{\\sigma}_{Height} &amp;= 0.66 \\end{align*}\\] La expresión anterior para cada individuo con los efectos finales (fijos y aleatorios) se puede obtener con R así: coef(fit) ## (Intercept) age ## 10 130.2745 3.738894 ## 26 138.0042 5.550728 ## 25 139.2122 4.098448 ## 9 138.1504 5.944778 ## 2 142.8621 5.454106 ## 6 146.7815 4.107752 ## 7 146.1244 5.061676 ## 17 142.9973 8.419906 ## 16 147.5373 4.658399 ## 15 144.2861 7.040730 ## 8 148.2941 6.459313 ## 20 151.4568 4.533071 ## 1 148.1253 7.124661 ## 18 151.1749 6.010602 ## 5 151.4249 6.282388 ## 23 151.0655 7.156877 ## 11 150.0557 8.382801 ## 21 150.5243 7.444412 ## 3 155.6331 4.943658 ## 24 153.1363 6.781996 ## 22 154.5675 8.030986 ## 12 156.8026 7.048445 ## 13 156.0722 8.423049 ## 14 159.4704 8.619141 ## 19 164.5675 9.032669 ## 4 165.0645 9.312700 En la presente aplicación es posible incluir la recta de regresión para cada individuo al diagrama de dispersión original. El código de R para obtener esto es el siguiente. library(lattice) xyplot(height ~ age | Subject, data=Oxboys, fit=fit, strip=strip.custom(bg=&quot;white&quot;), pch=16, cex=0.7, col=&#39;indianred1&#39;, panel = function(x, y, ..., fit, subscripts) { panel.xyplot(x, y, ...) ypred &lt;- fitted(fit)[subscripts] panel.lines(x, ypred, col=&quot;deepskyblue3&quot;, lwd=1) }, ylab=&quot;Height (cm)&quot;, xlab=&quot;Centered age&quot;) En la figura anterior se tienen las observaciones (crecimiento) representado por los puntos rojos, adicionalmente, aparece una recta de color azul que representa la recta de regresión para cada individuo. De la figura se observa que la linea logra explicar la evolución del crecimiento para cada individuo. Ejercicios Repita el ejercicio anterior considerando un modelo sólo con intercepto aleatorio. Dibuje las rectas de regresión para cada individuo. ¿Qué opina de este modelo? Repita el ejercicio anterior considerando un modelo sólo con pendiente aleatoria. Dibuje las rectas de regresión para cada individuo. ¿Qué opina de este modelo? Estime la estatura para el individuo # 3 cuando su edad centrada sea de 1.1. Replique los ejemplo de este documento. "],["apli-rat-pup.html", "8 Aplicación rat pup", " 8 Aplicación rat pup En este capítulo se mostrará un ejemplo de un modelo mixto con dos niveles usando la base de datos RatPupWeight del paquete nlme. Este ejemplo corresponde al ejemplo de la sección 3.2 de West (2014). Figure 8.1: Camada de ratones, tomada de https://www.howcast.com/videos/509444-how-to-care-for-a-pregnant-rat-pet-rats A continuación la base de datos a utilizar. library(nlme) head(RatPupWeight) ## Grouped Data: weight ~ 1 | Litter ## weight sex Litter Lsize Treatment ## 1 6.60 Male 1 12 Control ## 2 7.40 Male 1 12 Control ## 3 7.15 Male 1 12 Control ## 4 7.24 Male 1 12 Control ## 5 7.10 Male 1 12 Control ## 6 6.04 Male 1 12 Control Esta base de datos sobre crecimiento contiene la información sobre altura (weigth), sexo (sex), camada (litter), tamaño de la camada (Lsize) y tratamiento (Treatment) al que se sometió un rata antes de tener ratones. La estrategia es crear el modelo de forma incremental. Vamos a comenzar la construcción a partir del modelo mod31 que usa como efectos fijos el tratamiento, el sexo, la interacción entre tratamiento y sexo, el tamaño de la camada. Adicionalmente, este modelo incluye intercepto aleatorio debido a la camada. mod31 &lt;- lme(weight ~ Treatment * sex + Lsize, random= ~ 1 | Litter, data=RatPupWeight, method = &quot;REML&quot;) Vamos a usar la función anova.lme para estudiar la importancia de cada efecto fijo en el modelo. anova(mod31) ## numDF denDF F-value p-value ## (Intercept) 1 292 9093.772 &lt;.0001 ## Treatment 2 23 5.082 0.0149 ## sex 1 292 52.602 &lt;.0001 ## Lsize 1 23 47.374 &lt;.0001 ## Treatment:sex 2 292 0.466 0.6282 El otro modelo inicial mod31a es un modelo lineal sin intercepto aleatorio y se ajusta con la función gls. mod31a &lt;- gls(weight ~ Treatment * sex + Lsize, data=RatPupWeight, method = &quot;REML&quot;) anova(mod31, mod31a) ## Model df AIC BIC logLik Test L.Ratio p-value ## mod31 1 9 421.3015 455.0747 -201.6508 ## mod31a 2 8 508.7072 538.7277 -246.3536 1 vs 2 89.40562 &lt;.0001 mod32a &lt;- lme(weight ~ Treatment * sex + Lsize, random= ~ 1 | Litter, data=RatPupWeight, method = &quot;REML&quot;, weights = varIdent(form = ~1 | Treatment)) summary(mod32a) ## Linear mixed-effects model fit by REML ## Data: RatPupWeight ## AIC BIC logLik ## 384.0819 425.3602 -181.041 ## ## Random effects: ## Formula: ~1 | Litter ## (Intercept) Residual ## StdDev: 0.3134846 0.5147948 ## ## Variance function: ## Structure: Different standard deviations per stratum ## Formula: ~1 | Treatment ## Parameter estimates: ## Control High Low ## 1.0000000 0.6394383 0.5649830 ## Fixed effects: weight ~ Treatment * sex + Lsize ## Value Std.Error DF t-value p-value ## (Intercept) 7.888771 0.23223913 292 33.96831 0.0000 ## Treatment.L -0.638713 0.13587695 23 -4.70067 0.0001 ## Treatment.Q 0.011965 0.11635236 23 0.10283 0.9190 ## sexFemale -0.351238 0.04682791 292 -7.50062 0.0000 ## Lsize -0.130007 0.01848708 23 -7.03233 0.0000 ## Treatment.L:sexFemale 0.066939 0.09135485 292 0.73274 0.4643 ## Treatment.Q:sexFemale -0.023417 0.06929365 292 -0.33794 0.7357 ## Correlation: ## (Intr) Trtm.L Trtm.Q sexFml Lsize Tr.L:F ## Treatment.L -0.325 ## Treatment.Q -0.139 0.154 ## sexFemale -0.126 -0.008 -0.103 ## Lsize -0.954 0.376 0.190 0.031 ## Treatment.L:sexFemale -0.020 -0.304 -0.012 -0.034 0.015 ## Treatment.Q:sexFemale -0.021 -0.023 -0.300 0.445 -0.017 -0.029 ## ## Standardized Within-Group Residuals: ## Min Q1 Med Q3 Max ## -5.88670114 -0.52493419 0.02123518 0.57307286 2.56409983 ## ## Number of Observations: 322 ## Number of Groups: 27 References "],["estim.html", "9 Métodos de estimación 9.1 ML y REML Ejemplo: comparando REML y ML usando lme4 Ejemplo: comparando REML y ML usando nlme Ejercicios", " 9 Métodos de estimación En este capítulo se muestran los métodos ML (maximum likelihood) y REML (restricted maximum likelihood) para estimar los parámetros de un modelo mixto. 9.1 ML y REML El método de máxima verosimilitud restringida (o residual o reducida) (REML) es una alternativa de estimación de máxima verosimilitud que no basa las estimaciones en un ajuste de máxima verosimilitud de toda la información, sino que utiliza una función de verosimilitud calculada a partir de una conjunto de datos transformado, de modo que los parámetros molestos no tengan ningún efecto. En el caso de la estimación del componente de varianza, el conjunto de datos original se reemplaza por un conjunto de contrastes calculados a partir de los datos, y la función de verosimilitud se calcula a partir de la distribución de probabilidad de estos contrastes, de acuerdo con el modelo para el conjunto de datos completo. En particular, REML se utiliza como método para ajustar modelos lineales mixtos. En contraste con la estimación de máxima verosimilitud anterior, REML puede producir estimaciones insesgadas de parámetros de varianza y covarianza. Ejemplo: comparando REML y ML usando lme4 En este ejemplo vamos a simular datos de un modelo lineal mixto con intercepto y pendiente aleatoria, luego vamos a comparar las estimaciones de los parámetros del modelo usando REML y ML. Solución. Los datos los vamos a simular del siguiente modelo. \\[\\begin{align*} y_{ij} | b_0, b_1 &amp;\\sim N(\\mu_{ij}, \\sigma^2_y) \\\\ \\mu_{ij} &amp;= 4 - 5 x_{ij} + b_{0i} + b_{1i} x_{ij} \\\\ \\sigma^2_y &amp;= 4 \\\\ \\left ( \\begin{matrix} b_{0} \\\\ b_{1} \\end{matrix} \\right ) &amp;\\sim N\\left ( \\left ( \\begin{matrix} 0 \\\\ 0 \\end{matrix} \\right ), \\left ( \\begin{matrix} \\sigma^2_{b0}=40 &amp; \\sigma_{b01}=3 \\\\ \\sigma_{b01}=3 &amp; \\sigma^2_{b1}=50 \\end{matrix} \\right ) \\right ) \\\\ x_{ij} &amp;\\sim U(0, 5) \\end{align*}\\] Vamos a simular datos balanceados del anterior modelo considerando cinco grupos y diez observaciones por grupo. Para hacer esto vamos a usar la siguiente función. gen_data &lt;- function() { ni &lt;- 10 G &lt;- 5 nobs &lt;- ni * G # Numero total de observaciones grupo &lt;- factor(rep(x=1:G, each=ni)) # Para crear la variable grupal obs &lt;- rep(x=1:ni, each=G) # Para identificar las obs por grupo x &lt;- runif(n=nobs, min=0, max=5) # La covariable library(MASS) # Libreria para simular obs de Normal bivariada Sigma &lt;- matrix(c(40, 3, # Matriz de var-cov 3, 50), ncol=2, nrow=2) b &lt;- mvrnorm(n=G, mu=rep(0, 2), Sigma=Sigma) # Simulando b0 y b1 b &lt;- apply(b, MARGIN=2, function(c) rep(c, each=ni)) # Replicando b0 &lt;- as.vector(b[, 1]) # Separando los b0 b1 &lt;- as.vector(b[, 2]) # Separando los b1 media &lt;- 4 - 5 * x + b0 + b1 * x # La media y &lt;- rnorm(n=nobs, mean=media, sd=2) # La variable respuesta datos &lt;- data.frame(grupo, obs, x, y) # El dataframe } set.seed(123456) # Fijando la semilla para replicar el ejemplo datos &lt;- gen_data() # Creando los datos Ahora vamos a ajustar dos modelos, uno con estimación REML y otro con estimación ML. library(lme4) fit_reml &lt;- lmer(y ~ 1 + x + (1 + x| grupo), data = datos, REML = TRUE) fit_ml &lt;- lmer(y ~ 1 + x + (1 + x| grupo), data = datos, REML = FALSE) Para extraer sólo los efectos fijos de los dos modelos ajustados hacemos lo siguiente: fixef(fit_reml) ## (Intercept) x ## 11.449474 -6.236896 fixef(fit_ml) ## (Intercept) x ## 11.449454 -6.235161 Los efectos fijos verdaderos son \\(\\beta_0=4\\) y \\(\\beta_1=-5\\). Al comparar las estimaciones REML y ML vemos que son cercanas entre sí y próximas de los parámetros. Para extraer sólo las componentes de varianza de los dos modelos hacemos lo siguiente: (vc_reml &lt;- VarCorr(fit_reml)) ## Groups Name Std.Dev. Corr ## grupo (Intercept) 6.5259 ## x 4.0121 0.466 ## Residual 2.0379 (vc_ml &lt;- VarCorr(fit_ml)) ## Groups Name Std.Dev. Corr ## grupo (Intercept) 5.8025 ## x 3.5803 0.475 ## Residual 2.0377 Las componentes de varianza son \\(\\sigma_{b0}=6.32\\) (obtenida como \\(\\sqrt{40}\\)), \\(\\sigma_{b1}=7.07\\) (obtenida como \\(\\sqrt{50}\\)), \\(\\sigma_{b01}=3\\) y \\(\\sigma_y=2\\). Vamos a calcular el MSE (mean squared error) para las dos estimaciones REML y ML. a &lt;- vc_reml[[1]] b &lt;- vc_ml[[1]] mean((a[upper.tri(a, diag = TRUE)] - c(40, 3, 50))^2) ## [1] 413.6231 mean((b[upper.tri(b, diag = TRUE)] - c(40, 3, 50))^2) ## [1] 489.9286 De los anteriores resultados vemos que MSE es menor cuando se usa REML. Ejemplo: comparando REML y ML usando nlme Vamos a ajustar nuevamente los modelos pero usando el paquete nlme. library(nlme) fit_reml &lt;- lme(y ~ 1 + x, random = ~ 1 + x | grupo, data = datos, method = &quot;REML&quot;) fit_ml &lt;- lme(y ~ 1 + x, random = ~ 1 + x | grupo, data = datos, method = &quot;ML&quot;) Para extraer sólo los efectos fijos de los dos modelos ajustados hacemos lo siguiente: fixef(fit_reml) ## (Intercept) x ## 11.449474 -6.236896 fixef(fit_ml) ## (Intercept) x ## 11.449459 -6.235162 Los efectos fijos verdaderos son \\(\\beta_0=4\\) y \\(\\beta_1=-5\\). Al comparar las estimaciones REML y ML vemos que son cercanas entre sí, y próximas de los parámetros. Para extraer sólo las componentes de varianza de los dos modelos hacemos lo siguiente: (vc_reml &lt;- VarCorr(fit_reml)) ## grupo = pdLogChol(1 + x) ## Variance StdDev Corr ## (Intercept) 42.588627 6.525996 (Intr) ## x 16.097479 4.012166 0.466 ## Residual 4.153191 2.037938 (vc_ml &lt;- VarCorr(fit_ml)) ## grupo = pdLogChol(1 + x) ## Variance StdDev Corr ## (Intercept) 33.668543 5.802460 (Intr) ## x 12.819501 3.580433 0.475 ## Residual 4.152341 2.037729 Las componentes de varianza son \\(\\sigma_{b0}=6.32\\) (obtenida como \\(\\sqrt{40}\\)), \\(\\sigma_{b1}=7.07\\) (obtenida como \\(\\sqrt{50}\\)), \\(\\sigma_{b01}=3\\) y \\(\\sigma_y=2\\). Cuando se tienen muchos grupos y muchas repeticiones por grupo las estimaciones con REML y ML son muy cercanas. Ejercicios Repita el primer ejemplo de este capítulo para diez grupos y veinte observaciones por grupo. ¿Cuál es el valor de MSE para REML y ML? Repita el primer ejemplo de este capítulo para treinta grupos y cincuenta observaciones por grupo. ¿Cuál es el valor de MSE para REML y ML? Repita el primer ejemplo sin fijar la semilla y haga 100 réplicas con las siguientes combinaciones. Calcule el promedio de los MSE obtenidos. \\(G\\) \\(n_i\\) \\(\\overline{MSE}_{REML}\\) \\(\\overline{MSE}_{ML}\\) 5 10 10 15 20 20 30 25 "],["ph.html", "10 Pruebas de hipótesis 10.1 Prueba razón de verosimilitud 10.2 Prueba de Wald 10.3 Prueba de hipótesis sobre los efectos fijos 10.4 Prueba de hipótesis sobre componentes de varianza Ejercicios", " 10 Pruebas de hipótesis En este capítulo se muestran las pruebas de hipótesis para comparar modelos mixtos. 10.1 Prueba razón de verosimilitud Supongamos que queremos estudiar \\(H_0: \\boldsymbol{\\theta} \\in \\boldsymbol{\\Theta}_0\\) versus \\(H_A: \\boldsymbol{\\theta} \\in \\boldsymbol{\\Theta}\\). La prueba razón de verosimilitud (\\(LR\\)) para \\(H_0\\) está dada por: \\[ LR = -2 \\log \\left( \\frac{ sup_{\\theta \\in \\boldsymbol{\\Theta}_0} L(\\theta)}{ sup_{\\theta \\in \\boldsymbol{\\Theta}} L(\\theta)} \\right). \\] Usualmente la prueba de razón de verosimilitud se expresa en función de los valores de log-verosimilitud del modelo así: \\[ LR = -2 ( l(\\boldsymbol{\\theta}_0) - l(\\hat{\\boldsymbol{\\theta}}) ), \\] y el estadístico \\(LR \\sim \\chi^2_{k-k_0}\\), donde \\(k\\) es el número de parámetros del modelo estimado y \\(k_0\\) el número de parámetros del modelo asumiendo \\(H_0\\) verdadera. El vector \\(\\boldsymbol{\\theta}_0\\) es el vector de parámetros asumiendo que \\(H_0\\) es verdadera mientras que \\(\\hat{\\boldsymbol{\\theta}}\\) es el vector de parámetros del modelo más general. 10.2 Prueba de Wald Si el interés es estudiar \\(H_0: \\beta_k = \\beta_{k0}\\) contra \\(H_A: \\beta_k \\neq \\beta_{k0}\\) se puede usar la prueba de Wald que tiene el siguiente estadístico: \\[ t = \\frac{\\hat{\\beta}_k - \\beta_{k0}}{se(\\hat{\\beta}_k)}, \\] donde \\(se(\\hat{\\beta}_k)\\) corresponde al error estándar de la estimación \\(\\hat{\\beta}_k\\), todo esto disponible en el summary del modelo ajustado. Si \\(H_0\\) es verdadera, \\(t \\sim t_{n-p}\\), siendo \\(n\\) el número de observaciones y \\(p\\) el número de efectos fijos estimados (no el número de variables) en el modelo. 10.3 Prueba de hipótesis sobre los efectos fijos La prueba razón de verosimilitud puede ser usada para comparar modelos ajustados por el método ML y que difieran en su estructura de efectos fijos, pero con la mismas componentes de varianza. Los valores-P de la prueba pueden ser anticonservativos, es decir, más pequeños de lo normal y por lo tanto se podría rechazar \\(H_0\\) más fácilmente (J. Pinheiro and Bates 2000). En lugar de usar la distribución \\(\\chi^2\\) para el estadístico de la prueba razón de verosimilitud, se recomienda usar la distribución empírica del estadístico, obtenida al ajustar los modelos nulo y alternativo con múltiples conjuntos de datos simulados (Galecki and Burzykowski 2012). Ejemplo La base de datos ChickWeight contiene información sobre el peso de un grupo de pollos versus el tiempo bajo diferentes dietas. Abajo una ilustración de los datos. library(ggplot2) ggplot(data = ChickWeight, aes(x = Time, y = weight, color = Diet)) + geom_point() + theme_bw() + facet_wrap(~ Chick) El objetivo es comparar los siguientes dos modelos. Modelo 1 \\[\\begin{align*} Weight_{ij} &amp;\\sim N(\\mu_{ij}, \\sigma^2_{weight}) \\\\ \\mu_{ij} &amp;= \\beta_0 + \\beta_1 tiempo_{ij} + b_{0i} \\\\ b_{0} &amp;\\sim N(0, \\sigma^2_{b0}) \\end{align*}\\] Modelo 2 \\[\\begin{align*} Weight_{ij} &amp;\\sim N(\\mu_{ij}, \\sigma^2_{weight}) \\\\ \\mu_{ij} &amp;= \\beta_0 + \\beta_1 tiempo_{ij} + \\beta_2 dieta2_{i} + \\beta_3 dieta3_{i} + \\beta_4 dieta4_{i} + b_{0i} \\\\ b_{0} &amp;\\sim N(0, \\sigma^2_{b0}) \\end{align*}\\] Solución. El problema de este ejercicio se puede resumir con \\(H_0:\\) la variable Dieta no aporta al modelo, versus, \\(H_A:\\) la variable Dieta si aporta al modelo. Para ajustar ambos modelos se usa el siguiente código. library(nlme) mod1 &lt;- lme(weight ~ Time, data = ChickWeight, random = ~ 1 | Chick, method=&#39;ML&#39;) mod2 &lt;- lme(weight ~ Time + Diet, data = ChickWeight, random = ~ 1 | Chick, method=&#39;ML&#39;) Para calcular la prueba razón de verosimilitud se usa el siguiente código. lrt &lt;- -2 * (logLik(mod1) - logLik(mod2)) lrt ## &#39;log Lik.&#39; 17.14349 (df=4) pchisq(q=lrt, df=7-4, lower.tail=FALSE) ## &#39;log Lik.&#39; 0.000660304 (df=4) De la salida anterior se tiene que el valor-P = 0.000660304 y menor que cualquier \\(\\alpha\\). Sin embargo, como este valor-P puede ser anticonservativo (más pequeño de lo que debería ser), es mejor no sacar conclusiones apresuradas y rechazar \\(H_0\\). La prueba de verosimilitud se puede obtener también así: anova(mod1, mod2) ## Model df AIC BIC logLik Test L.Ratio p-value ## mod1 1 4 5630.344 5647.782 -2811.172 ## mod2 2 7 5619.201 5649.718 -2802.600 1 vs 2 17.14349 7e-04 Para obtener un valor-P más acorde al problema podemos usar simulación. La función simulate.lme simula datos de modelos especificados por medio de los argumentos object y m2, ajusta los modelos, y entrega los valores de log-verosimilitud, con los se puede obtener el estadístico de la prueba de razón de verosimilitud. A continuación el código para obtener el valor-P con simulación. simul &lt;- simulate.lme(object=mod1, m2=mod2, method = &#39;ML&#39;, nsim=1000) lrts_nlme &lt;- -2 * (simul$null$ML[, 2] - simul$alt$ML[, 2]) acumulada1 &lt;- ecdf(x=lrts_nlme) # F(x) para los valores LRT 1 - acumulada1(17.14349) ## [1] 0.001 De la salida anterior se tiene que el valor-P = 0.001 y ya no es tan pequeño como el valor-P anterior. Por esta razón hay evidencias rechazar \\(H_0\\) y por lo tanto la variable Dieta si aporta al modelo. Ejemplo La base de datos Orthodont contiene información sobre una medida de distancia intrafacial para jóvenes sometidos a ortodoncia. data(Orthodont, package=&quot;nlme&quot;) library(ggplot2) ggplot(data = Orthodont, aes(x = age, y = distance, color = Sex)) + geom_point() + theme_bw() + facet_wrap(~ Subject) El objetivo es comparar los siguientes dos modelos. Modelo 1 \\[\\begin{align*} Distance_{ij} &amp;\\sim N(\\mu_{ij}, \\sigma^2_{distance}) \\\\ \\mu_{ij} &amp;= \\beta_0 + \\beta_1 age_{ij} + b_{0i} \\\\ b_{0} &amp;\\sim N(0, \\sigma^2_{b0}) \\end{align*}\\] Modelo 2 \\[\\begin{align*} Distance_{ij} &amp;\\sim N(\\mu_{ij}, \\sigma^2_{distance}) \\\\ \\mu_{ij} &amp;= \\beta_0 + \\beta_1 age_{ij} + \\beta_2 SexFemale_i + b_{0i} \\\\ b_{0} &amp;\\sim N(0, \\sigma^2_{b0}) \\end{align*}\\] Solución. El problema de este ejercicio se puede resumir con \\(H_0:\\) la variable Sexo no aporta al modelo, versus, \\(H_A:\\) la variable Sexo si aporta al modelo. Para ajustar ambos modelos se usa el siguiente código. library(lme4) mod1 &lt;- lmer(distance ~ age + (1|Subject), data=Orthodont, REML=FALSE) mod2 &lt;- lmer(distance ~ age + Sex + (1|Subject), data=Orthodont, REML=FALSE) Para calcular la prueba razón de verosimilitud se usa el siguiente código. lrt &lt;- -2 * (logLik(mod1) - logLik(mod2)) lrt ## &#39;log Lik.&#39; 8.533057 (df=4) pchisq(q=lrt, df=5-4, lower.tail=FALSE) ## &#39;log Lik.&#39; 0.003487534 (df=4) De la salida anterior se tiene que el valor-P = 0.003487534 y menor que cualquier \\(\\alpha\\). Sin embargo, como este valor-P puede ser anticonservativo (más pequeño de lo que debería ser), es mejor no sacar conclusiones apresuradas y rechazar \\(H_0\\). La prueba de verosimilitud se puede obtener también así: anova(mod1, mod2) ## Data: Orthodont ## Models: ## mod1: distance ~ age + (1 | Subject) ## mod2: distance ~ age + Sex + (1 | Subject) ## npar AIC BIC logLik deviance Chisq Df Pr(&gt;Chisq) ## mod1 4 451.39 462.12 -221.69 443.39 ## mod2 5 444.86 458.27 -217.43 434.86 8.5331 1 0.003488 ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Para obtener un valor-P más acorde al problema podemos usar simulación. La función simulate.lme simula respuestas \\(y_{ij}\\) del modelo dado. A continuación el código para obtener el valor-P con simulación (¡tarda varios minutos!). nrep &lt;- 5000 lrts_lme4 &lt;- numeric(nrep) for (i in 1:nrep) { new_y_h0 &lt;- simulate(mod1) # Asumiendo H0 verdadera Orthodont$new_y_h0 &lt;- new_y_h0$sim_1 aux0 &lt;- lmer(new_y_h0 ~ age + (1|Subject), data=Orthodont, REML=FALSE) aux1 &lt;- lmer(new_y_h0 ~ age + Sex + (1|Subject), data=Orthodont, REML=FALSE) lrts_lme4[i] &lt;- -2 * (logLik(aux0) - logLik(aux1)) } acumulada2 &lt;- ecdf(x=lrts_lme4) # F(x) para los valores LRT 1 - acumulada1(8.533057) ## [1] 0.005 De la salida anterior se tiene que el valor-P = 0.005 y ya no es tan pequeño como el valor-P anterior. Por esta razón hay evidencias rechazar \\(H_0\\) y por lo tanto la variable Sexo si aporta al modelo. 10.4 Prueba de hipótesis sobre componentes de varianza Las componentes de varianza corresponden a las varianzas y covarianzas del vector de efectos aleatorios. La prueba razón de verosimilitud puede ser usada para comparar modelos ajustados por el método REML y que difieran en sus componentes de varianza, pero que tenga igual estructura de efectos fijos. Para hacer pruebas de hipótesis sobre las componentes de varianza se tienen dos casos que se explican en las siguientes subsecciones. 10.4.1 Componentes de varianza lejos del borde Luego un ejemplo. 10.4.2 Componentes de varianza en el borde Este caso se presenta cuando la hipótesis nula considera que uno o varios parámetros están justo en el borde del dominio del parámetro en cuestion. Por ejemplo, si queremos estudiar la inclusión del intercepto aleatorio \\(b_0\\) en un modelo de regresión clásico, tendríamos las siguientes hipótesis: \\(H_0: \\sigma^2_{b0} = 0\\) versus \\(H_A: \\sigma^2_{b0} &gt; 0\\). Debido a la condición de \\(\\sigma^2_{b0}\\) en \\(H_0\\), se dice que esa componente de varianza está en el borde de su dominio, ya que \\(\\sigma^2_{b0}\\) no puede ser negativa. En este ejemplo particular, rechazar \\(H_0\\) implicaría que es apropiado incluir \\(b_0\\) en el modelo. En el caso de componentes de varianza cerca de la frontera la distribución del estadístico razón de verosimilitud no es exactamente una \\(\\chi^2\\) (Galecki and Burzykowski 2012). En la sección 6.3.4 de (Verbeke and Molenberghs 2000) se listan cuatro casos en los cuales se usan mezclas de distribuciones corregir la distribución del estadístico y así calcular el valor-P corregido en la prueba razón de verosimilitud. Los cuatro casos son los siguientes: Sin efecto aleatorio versus 1 efecto aleatorio: en este caso lo que interesa es \\(H_0: \\sigma^2_{b} = 0\\) versus \\(H_A: \\sigma^2_{b} &gt; 0\\), la distribución asintótica del estadístico de razon de verosimilitud es una mezcla de \\(\\chi^2_1\\) y \\(\\chi^2_0\\) con pesos iguales a 0.5. 1 efecto aleatorio versus 2 efectos aleatorios: en este caso lo que interesa es \\(H_0: \\boldsymbol{D} = \\begin{pmatrix} d_{11} &amp; 0 \\\\ 0 &amp; 0 \\end{pmatrix}\\) versus \\(H_A: \\boldsymbol{D} \\neq \\boldsymbol{0}\\) para un \\(d_{11}&gt;0\\), en este caso la distribución asintótica del estadístico razón de verosimilitud es una mezcla de \\(\\chi^2_2\\) y \\(\\chi^2_1\\) con pesos iguales a 0.5. \\(q\\) efectos aleatorios versus \\(q+1\\) efectos aleatorios: en este caso lo que interesa es \\(H_0: \\boldsymbol{D} = \\begin{pmatrix} \\boldsymbol{D_{11}} &amp; \\boldsymbol{0}\\\\ \\boldsymbol{0}^\\top &amp; 0 \\end{pmatrix}\\) donde \\(\\boldsymbol{D_{11}}\\) es una matriz de covarianzas (positiva definida) de dimensión \\(q \\times q\\) versus que \\(\\boldsymbol{D}\\) es una matriz general de dimensión \\(q+1 \\times q+1\\). En este caso la distribución asintótica del estadística razón de verosimilitud es una mezcla de \\(\\chi^2_{q+1}\\) y \\(\\chi^2_q\\) con pesos iguales a 0.5. \\(q\\) efectos aleatorios versus \\(q+k\\) efectos aleatorios: en este caso lo que interesa es \\(H_0: \\boldsymbol{D} = \\begin{pmatrix} \\boldsymbol{D_{11}} &amp; \\boldsymbol{0}\\\\ \\boldsymbol{0}^\\top &amp; \\boldsymbol{0} \\end{pmatrix}\\) donde \\(\\boldsymbol{D}\\) es una matriz de covarianzas (positiva definida) de dimensión \\(q+k \\times q+k\\) versus que \\(H_A: \\boldsymbol{D} = \\begin{pmatrix} \\boldsymbol{D_{11}} &amp; \\boldsymbol{D_{12}}\\\\ \\boldsymbol{D_{12}}^\\top &amp; \\boldsymbol{D_{22}} \\end{pmatrix}\\) es una matriz general de dimensión \\(q+k \\times q+k\\). En este caso la distribución asintótica del estadística razón de verosimilitud es una mezcla de \\(\\chi^2_{q+k}\\) y \\(\\chi^2_q\\) con pesos iguales a 0.5. Si la distribución nula del estadístico razón de verosimilitud no puede ser obtenida analíticamente, una posible solución es usar la distribución empírica del estadístico obtenida al ajustar múltiples modelos nulos y alternativos (Galecki and Burzykowski 2012). Ejemplo Simule 10 observaciones para cada uno de los 10 grupos siguiendo el siguiente modelo y luego aplique la prueba de razón de verosimilitud para estudiar \\(H_0: \\sigma^2_{b0} = 0\\) versus \\(H_A: \\sigma^2_{b0} &gt; 0\\). \\[\\begin{align*} y_{ij} &amp;\\sim N(\\mu_{ij}, \\sigma^2_y) \\\\ \\mu_{ij} &amp;= 4 - 6 x_{ij} + b_{0i} \\\\ \\sigma^2_y &amp;= 4 \\\\ b_{0} &amp;\\sim N(0, \\sigma^2_{b0}=4) \\\\ x_{ij} &amp;\\sim U(0, 10) \\end{align*}\\] Solución. La función gen_dat_b0 de abajo permite simular m observaciones de n grupos con intercepto aleatorio \\(b_0 \\sim N(0, \\sigma^2_{b0})\\). Adicionalmente, es posible elegir los efectos fijos beta0, beta_1 y la varianza sigma de la variable respuesta. gen_dat_b0 &lt;- function(n, m, beta0, beta1, sigmay, sigmab0, seed=NULL) { if(is.null(seed)) seed &lt;- as.integer(runif(1)*2e9) group &lt;- rep(1:n, each=m) set.seed(seed) b0 &lt;- rep(rnorm(n=n, mean=0, sd=sigmab0), each=m) set.seed(seed) x &lt;- runif(n=n*m, min=0, max=10) set.seed(seed) y &lt;- rnorm(n=n*m, mean=beta0 + beta1 * x + b0, sd=sigmay) data.frame(group=group, x=x, y=y) } Vamos ahora a generar 10 observaciones para 10 grupos con intercepto aleatorio con una varianza \\(\\sigma^2_{b0}=2^2=4\\). La semilla se va a fijar en un valor de 1220872376 por cuestiones didácticas. datos &lt;- gen_dat_b0(n=10, m=10, beta0=4, beta1=-6, sigmay=2, sigmab0=2, seed=1220872376) head(datos) ## group x y ## 1 1 3.817132 -20.106729 ## 2 1 8.951117 -49.950457 ## 3 1 5.710726 -33.154170 ## 4 1 7.451320 -39.583303 ## 5 1 1.263282 -1.070788 ## 6 1 6.114367 -33.423587 Vamos a ajustar dos modelos, el primero sin incluir \\(b_0\\) y el segundo incluyendo \\(b_0\\). library(nlme) fit1 &lt;- gls(y ~ x, data=datos, method=&quot;REML&quot;) # Igual resultado con lm fit2 &lt;- lme(y ~ x, random = ~ 1| group, data=datos, method=&quot;REML&quot;) Resultados del primer modelo. summary(fit1) ## Generalized least squares fit by REML ## Model: y ~ x ## Data: datos ## AIC BIC logLik ## 475.8248 483.5797 -234.9124 ## ## Coefficients: ## Value Std.Error t-value p-value ## (Intercept) 4.64931 0.5180190 8.97517 0 ## x -6.00175 0.0814173 -73.71588 0 ## ## Correlation: ## (Intr) ## x -0.875 ## ## Standardized residuals: ## Min Q1 Med Q3 Max ## -2.14346496 -0.64999607 -0.06461389 0.60660976 3.48238119 ## ## Residual standard error: 2.50842 ## Degrees of freedom: 100 total; 98 residual Resultados del segundo modelo. summary(fit2) ## Linear mixed-effects model fit by REML ## Data: datos ## AIC BIC logLik ## 474.7777 485.1175 -233.3888 ## ## Random effects: ## Formula: ~1 | group ## (Intercept) Residual ## StdDev: 0.8166724 2.383898 ## ## Fixed effects: y ~ x ## Value Std.Error DF t-value p-value ## (Intercept) 4.640053 0.5652943 89 8.20821 0 ## x -6.000087 0.0795348 89 -75.43973 0 ## Correlation: ## (Intr) ## x -0.783 ## ## Standardized Within-Group Residuals: ## Min Q1 Med Q3 Max ## -2.19536246 -0.56396957 0.05433633 0.61634184 3.29594400 ## ## Number of Observations: 100 ## Number of Groups: 10 Ahora vamos a calcular el estadístico y su valor-P. lrt &lt;- -2 * (logLik(fit1) - logLik(fit2)) lrt ## &#39;log Lik.&#39; 3.04712 (df=3) p_value &lt;- pchisq(q=3.04712, df=1, lower.tail=FALSE) p_value ## [1] 0.08088045 De la salida anterior se tiene que \\(valor-P = 0.0809\\) y como \\(\\alpha=0.05\\), por lo tanto NO hay evidencias para rechazar \\(H_0: \\sigma^2_{b0} = 0\\). ¿No es extraña esta conclusión ? Lo anterior ocurre porque la distribución del estadístico \\(LR\\) no es un \\(\\chi^2\\) sino una mezcla de distribuciones \\(\\chi^2_1\\) y \\(\\chi^2_0\\) con pesos iguales a 0.5. A continuación vamos a mostrar la distribución de \\(LR\\) en este ejemplo. library(emdbook) # Para usar la función dchibarsq library(ggplot2) ggplot(data = data.frame(x = 0), mapping = aes(x = x)) + stat_function(fun = dchibarsq, args = list(df = 1)) + xlim(0, 5) Para calcular el valor-P de la prueba hacemos pchibarsq(p=3.04712, df = 1, mix = 0.5, lower.tail=FALSE) ## [1] 0.04044023 También es posible obtener el valor-P usando simulación. Vamos a simular 50 conjuntos de datos suponiendo \\(H_0\\) verdadera y luego calcularemos los lrt para así tener la distribución empírica de los lrt bajo la hipótesis nula \\(H_0: \\sigma^2_{b0} = 0\\) verdadera. En un aplicación se deberían generar más conjuntos de pero aquí vamos a usar sólo 50 por comodidad. pseudo_gen_dat &lt;- function(nobs, beta0, beta1, sigmay) { group &lt;- datos$group # Aqui la diferencia x &lt;- datos$x # Aqui la diferencia y &lt;- rnorm(n=nobs, mean=beta0 + beta1 * x, sd=sigmay) data.frame(group=group, x=x, y=y) } nrep &lt;- 50 lrts &lt;- numeric(nrep) for (i in 1:nrep) { pseudo_datos &lt;- pseudo_gen_dat(nobs=100, beta0=4.64931, beta1=-6.00175, sigma=2.50842) m1 &lt;- gls(y ~ x, data=pseudo_datos, method=&quot;REML&quot;) m2 &lt;- lme(y ~ x, random = ~ 1| group, data=pseudo_datos, method=&quot;REML&quot;) lrts[i] &lt;- -2 * (logLik(m1) - logLik(m2)) } Dibujando la densidad de los lrt. plot(density(lrts), main=&#39;Densidad empírica de los lrts&#39;) Calculando el valor-P. acumulada &lt;- ecdf(x=lrts) # F(x) para los valores LRT 1 - acumulada(3.04712) # Valor-P ## [1] 0.04 De la salida anterior se tiene que \\(valor-P &lt; \\alpha\\) por lo tanto SI hay evidencias para rechazar \\(H_0: \\sigma^2_{b0} = 0\\). ¿Es esto coherente ahora ? Los resultados anteriores se obtuvieron usando nrep &lt;- 50, en la práctica ese número de repeticiones debería subir al menos a 1000. Repita el procedimiento anterior con nrep &lt;- 5000 y observe lo que sucede. El paquete RLRsim de Scheipl (2020) tiene la función exactRLRT que permite extraer el valor-P mediante simulación. Abajo un ejemplo de como usarla en el presente ejemplo. library(RLRsim) exactRLRT(m=fit2, nsim=1000) ## Warning in model.matrix.default(~m$groups[[n.levels - i + 1]] - 1, contrasts.arg ## = c(&quot;contr.treatment&quot;, : non-list contrasts argument ignored ## ## simulated finite sample distribution of RLRT. ## ## (p-value based on 1000 simulated values) ## ## data: ## RLRT = 3.0471, p-value = 0.039 Consulte la ayuda de la función exactRLRT para que conozca sus posibilidades y limitaciones. Ejemplo Simule 10 observaciones para cada uno de los 10 grupos siguiendo el siguiente modelo y luego aplique la prueba de razón de verosimilitud para estudiar \\(H_0:\\) el modelo con intercepto aleatorio está bien versus \\(H_A:\\) se necesita intercepto y pendiente aleatoria. \\[\\begin{align*} y_{ij} &amp;\\sim N(\\mu_{ij}, \\sigma^2_y) \\\\ \\mu_{ij} &amp;= 4 - 6 x_{ij} + b_{0i} + b_{1i} x_{ij} \\\\ \\sigma^2_y &amp;= 4 \\\\ \\left ( \\begin{matrix} b_{0} \\\\ b_{1} \\end{matrix} \\right ) &amp;\\sim N\\left ( \\left ( \\begin{matrix} 0 \\\\ 0 \\end{matrix} \\right ), \\left ( \\begin{matrix} \\sigma^2_{b0}=10 &amp; \\sigma_{b01}=3 \\\\ \\sigma_{b01}=3 &amp; \\sigma^2_{b1}=2 \\end{matrix} \\right ) \\right ) \\\\ x_{ij} &amp;\\sim U(0, 10) \\end{align*}\\] Solución. La función gen_dat_b0_b1 de abajo permite simular m observaciones de n grupos con intercepto y pendiente aleatoria según el modelo exigido. gen_dat_b0_b1 &lt;- function(n, m, beta0, beta1, sigma2y, sigma2b0, sigma2b1, sigmab0b1, seed=NULL) { if(is.null(seed)) seed &lt;- as.integer(runif(1)*2e9) group &lt;- rep(1:n, each=m) Sigma &lt;- matrix(c(sigma2b0, sigmab0b1, sigmab0b1, sigma2b1), ncol=2, nrow=2) set.seed(seed) b &lt;- MASS::mvrnorm(n=n, mu=c(0, 0), Sigma=Sigma, empirical=TRUE) b &lt;- apply(X=b, MARGIN=2, rep, each=m) b0 &lt;- b[, 1] # Extrayendo los b0 b1 &lt;- b[, 2] # Extrayendo los b1 set.seed(seed) x &lt;- runif(n=n*m, min=0, max=10) mu &lt;- beta0 + beta1 * x + b0 + b1 * x set.seed(seed) y &lt;- rnorm(n=n*m, mean=mu, sd=sqrt(sigma2y)) data.frame(group=group, x=x, y=y) } Vamos ahora a generar 10 observaciones para 10 grupos con intercepto y pendiente aleatoria. La semilla se va a fijar en un valor de 1234 por cuestiones didácticas. datos &lt;- gen_dat_b0_b1(n=10, m=10, beta0=4, beta1=-6, sigma2y=4, sigma2b0=10, sigma2b1=2, sigmab0b1=3, seed=1234) head(datos) ## group x y ## 1 1 1.137034 -6.60088 ## 2 1 6.222994 -39.51716 ## 3 1 6.092747 -36.98415 ## 4 1 6.233794 -44.83962 ## 5 1 8.609154 -56.04992 ## 6 1 6.403106 -40.33074 Vamos a ajustar dos modelos, el primero sólo con \\(b_0\\) y el segundo incluyendo \\(b_0\\) y \\(b_1\\). library(lme4) fit0 &lt;- lmer(y ~ x + (1 | group), data=datos, REML=TRUE) fit1 &lt;- lmer(y ~ x + (1 + x | group), data=datos, REML=TRUE) Vamos a calcular ahora el valor del estadístico de la prueba razón de verosimilitudes así: lrt &lt;- -2 * (logLik(fit0) - logLik(fit1)) lrt ## &#39;log Lik.&#39; 122.1118 (df=4) Como la distribución del estadístico es una mezcla de distribuciones vamos a calcular el valor P de la siguiente manera. p_value &lt;- 0.5 * (1-pchisq(lrt, 1)) + 0.5 * (1-pchisq(lrt, 2)) p_value &lt;- as.numeric(p_value) p_value # p-value from equal mixture chi_1^2:chi_2^2 ## [1] 0 De la salida anterior vemos que el valor-P es muy pequeño, eso significa que rechazamos \\(H_0\\) y concluimos que el modelo con \\(b_0\\) y \\(b_1\\) es más apropiado que el modelo que tiene sólo intercepto aleatorio. La conclusión a la que llegamos es correcta porque así fue que generamos los datos. Es posible obtener el valor-P anterior usando boostrap por medio de la función PBmodcomp del paquete pbkrtest de Halekoh and Højsgaard (2021). library(pbkrtest) PBmodcomp(largeModel=fit1, smallModel=fit0, nsim=1000, seed=123) Bootstrap test; time: 21.86 sec; samples: 1000; extremes: 0; Requested samples: 1000 Used samples: 999 Extremes: 0 large : y ~ x + (1 + x | group) y ~ x + (1 | group) stat df p.value LRT 122.82 2 &lt;2e-16 *** PBtest 122.82 0.001 *** --- Signif. codes: 0 *** 0.001 ** 0.01 * 0.05 . 0.1   1 En el código anterior se usó la semilla seed = 123 para simular los nuevos conjuntos de datos. De la salida anterior se observa que el valor-P es 0.001 con lo que se concluye que hay evidencias para rechazar \\(H_0\\). Para usar la función PBmodcomp es necesario que los modelos sean de la clase lme4. Consulte la ayuda de la función para más detalles. Ejercicios ¿Qué son modelos anidados? ¿Son modelos que usan datos relacionados con aves? Considere la base de datos sleepstudy del paquete lme4. El objetivo es comparar los siguientes dos modelos. Modelo 1 \\[\\begin{align*} Reaction_{ij} &amp;\\sim N(\\mu_{ij}, \\sigma^2_{reaction}) \\\\ \\mu_{ij} &amp;= \\beta_0 + \\beta_1 days_{ij} + b_{0i} + b_{1i} days_{ij} \\\\ (b_0, b_1)^\\top &amp;\\sim N(\\boldsymbol{0}, \\boldsymbol{D}) \\end{align*}\\] Modelo 2 \\[\\begin{align*} Reaction_{ij} &amp;\\sim N(\\mu_{ij}, \\sigma^2_{reaction}) \\\\ \\mu_{ij} &amp;= \\beta_0 + \\beta_1 days_{ij} + \\beta_2 days_{ij}^2 + b_{0i} + b_{1i} days_{ij} \\\\ (b_0, b_1)^\\top &amp;\\sim N(\\boldsymbol{0}, \\boldsymbol{D}) \\end{align*}\\] Escriba las hipótesis del problema en forma simbólica y en lenguaje sencillo. Aplique la prueba razón de verosimilitud usando simulación y concluya. Rta: el valor-P \\(\\approx\\) 0.136. Considere el ejemplo del capítulo 7 sobre el estudio de crecimiento de un grupo de jóvenes. Aplique la prueba razón de verosimilitud para estudiar \\(H_0: \\sigma^2_{b0} = 0\\) versus \\(H_A: \\sigma^2_{b0} &gt; 0\\), es decir, ajuste un modelo lineal simple para explicar la estatura en función de la edad y luego un modelo mixto con intercepto aleatorio. ¿Cuál de los dos modelos parece explicar mejor los datos? Use \\(\\alpha=0.06\\). En este enlace está la pregunta de un usuario de StackExange sobre prueba de hipótesis (PH). ¿Fue la pregunta sobre PH sobre efectos fijos o PH sobre componentes de varianza? ¿Quería el usuario un PH asintótica o una PH basada en bootstrap (relacionado con simulación)? Mire el ejemplo que dió YaronZ, ¿por qué no definió el método REML dentro de las funciones lmer y lm? En este enlace está la extensa pregunta del usuario Patrick. En el primer cajón de código Patrick escribió un código para simular observaciones de un modelo mixto. ¿Cómo le parece esa forma de simular? ¿Cuántos elementos tiene el vector de parámetros del modelo de Patrick? ¿Cuáles son los valores de los parámetros? En este enlace está la pregunta del usuario biostat_newbie. ¿Qué nombre recibe el modelo que le interesa a biostat_newbie? ¿Qué es lo que necesita 0.7494974? ¿Cuál es el mensaje de primer párrafo de que respondió Fabians? En la respuesta que Fabians dió hay un código de R. ¿Para qué sirve ese código tan extraño? ¿Quién es Ben Bolker? ¿En cuáles paquetes de R ha participado Ben Bolker? En este enlace está la pregunta del usuario user9171. ¿Cuál es el error que comete user9171 al usar el siguiente código? &gt; anova(fit.fe, fit.me) Error: $ operator not defined for this S4 class ¿Qué le respondió Karl Ove Hufthammer? Karl le agrega en su respuesta And really the choice of whether to include the random effects should be based on theory (e.g., the sampling plan), not on a statistical test. ¿Qué quiere decir eso? Ben Bolker escribió unas notas sobre pruebas de hipótesis, revise este enlace para consultarlas. En el ejemplo de Ben Bolker hay tres modelos: m2, m1 y m0. ¿Cuál es el full model y cuál es el reduced model? ¿Para qué sirve la función update? ¿Usted la ha usado alguna vez? ¿No? Pues úsela de aquí en adelante. Ben escribe which has a fast implementation of simulation-based tests of null hypotheses about zero variances, for simple tests. ¿A qué paquete se refiere con esa frase? References "],["reg-diagnos.html", "11 Diagnóstico del modelo de regresión de efectos mixtos 11.1 Supuestos del modelo de regresión 11.2 Los residuos 11.3 Diagnóstico del modelo de regresión: prueba de hipótesis e inferencia visual", " 11 Diagnóstico del modelo de regresión de efectos mixtos El diagnóstico del modelo de regresión es uno de un conjunto de procedimientos disponibles para el análisis de regresión que buscan evaluar la validez de un modelo previamente ajustado. Esta evaluación puede ser una exploración de los supuestos estadísticos del modelo. El objetivo de este capitulo consiste en introducir al lector los distintos métodos de diagnostico del modelo de regresión. 11.1 Supuestos del modelo de regresión Existen un conjunto de supuestos cuando se modela la relación entre una variable respuesta y un regresor. Estos supuestos son esencialmente condiciones que deben cumplirse. Cuando no es el caso, las estimaciones y predicciones pueden comportarse mal e incluso pueden tergiversar por completo los datos. El diagnóstico de regresión puede revelar el problema y, a menudo, señalar el camino hacia las soluciones. Si un modelo de regresión ajustado representa adecuadamente los datos, sus residuos deberan: Tener varianza constante (homogeneidad de la varianza); Estar aproximadamente distribuidos de forma normal y; Ser independientes el uno del otro. Por tanto los supuestos del modelo de regresión se examinan a partir de los residuos que resultan del ajuste previo. 11.2 Los residuos Los residuos son la base de la mayoría de los métodos de diagnóstico. Estos pueden ser de distinto tipo. Los residuos más básicos son los denominados residuos ordinarios, \\(\\hat{\\epsilon}_{i}\\), el cual se define como la diferencia entre el valor observado, \\(y_{i}\\), y su correspondiente valor estimado por el modelo, \\(\\hat{\\mu}_{i}\\), así: \\[\\begin{align*} \\hat{\\epsilon}_{i} = y_{i} - \\hat{\\mu}_{i}, i = 1, 2, ..., n \\end{align*}\\] donde \\(\\hat{\\mu}_{i}\\) es igual a \\(x^{&#39;}_{i}\\hat{\\beta}\\). A continuación, se presenta una representación gráfica de \\(\\hat{\\epsilon}_{i}\\): Luego los residuos ordinarios se escalan con el fin de que su interpretación no dependa de las unidades de medida de la variable respuesta. El proceso de estandarización consiste en dividir el residuo ordinario, \\(\\hat{\\epsilon}_{i}\\), por la expresión \\(\\sigma\\sqrt{(1-h_{i})}\\), donde \\({\\sigma}\\) corresponde a la desviación estandar verdadera y \\(h_{i}\\) al leverage (en inglés). Los residuos obtenidos de esta manera se denominan como residuos estandarizados. Sin embargo la verdadera desviación estándar rara vez se conoce. Por lo tanto, el escalado se puede realizar utilizando un estimador del mismo, es decir \\(\\hat{\\sigma}\\). Los residuos obtenidos de esta manera se denominan como residuos estudentizados, los cuales a su vez se dividen en dos: los residuos internamente estudentizados y los residuos externamente estudentizados. La tabla a continuación, resume las formas básicas de los residuos escalados: Formula matemática Estandarizado \\(\\frac{\\hat\\epsilon_i}{\\sigma\\sqrt{(1-h_i)}}\\) Internamente estudentizado \\(\\frac{\\hat\\epsilon_i}{\\hat\\sigma\\sqrt{(1-h_i)}}\\) Externamente estudentizado \\(\\frac{\\hat\\epsilon_i}{\\hat\\sigma_{(-i)}\\sqrt{(1-h_i)}}\\) * En el residuo internamente estudentizado, \\(\\hat\\sigma\\) denota una estimación de \\(\\sigma\\) basada en todas las observaciones;  En el residuo externamente estudentizado, \\(\\hat\\sigma_{(-i)}\\) es una estimación obtenida luego de excluir la i-ésima observación de los cálculos. Se usara la base de datos hsb del paquete merTools para entender mejor de que tratan los residuos, así como también los métodos de diagnosticos que explicaremos más adelante en este capitulo. A continuación podra ver la base de datos a usar: Se puede entender bien la lógica de los que son los residuos ajustando un modelo de regresión simple. El diagnóstico del modelo de regresión aborda la adecuación de un modelo estadístico una vez se han ajustado los datos. De hecho, el ajuste de un modelo debe verse como un proceso iterativo en el que se ajusta el modelo, se evalúan sus residuos y se mejora. Así hasta llegar a un modelo óptimo. Suponga que se quiere poner en relación dos variables: la variable \\(x_{1}\\) que representa el nivel socio-económico de los estudiantes (ses), y la variable \\(y\\), que es el rendimiento de los mismos estudiantes en una prueba de matemáticas (mathach). Para facilitar este análisis (y los posteriores) se asumira que \\(x_{1}\\) es una variable continua que toma valores entre -4 y +4, donde valores cercanos a 0 indican nivel socio-económico medio, cercanos a +4 indican nivel socio-económico alto y cercanos a -4 indican nivel socio-económico bajo. El modelo de regresión simple aplicado a este ejemplo se puede representar así: \\[\\begin{align} \\label{mod2} y_i &amp;\\sim N(\\mu_i, \\sigma^2), \\\\ \\mu_i &amp;= \\beta_0 + \\beta_1 x_{1i}, \\\\ \\sigma^2 &amp;= \\text{constante} \\end{align}\\] El codigó en R para ajustar el anterior modelo se presenta a continuación: Modelo_simple &lt;- lm(mathach ~ ses, data = hsb) summary(Modelo_simple) ## ## Call: ## lm(formula = mathach ~ ses, data = hsb) ## ## Residuals: ## Min 1Q Median 3Q Max ## -19.4382 -4.7580 0.2334 5.0649 15.9007 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 12.74740 0.07569 168.42 &lt;2e-16 *** ## ses 3.18387 0.09712 32.78 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 6.416 on 7183 degrees of freedom ## Multiple R-squared: 0.1301, Adjusted R-squared: 0.13 ## F-statistic: 1075 on 1 and 7183 DF, p-value: &lt; 2.2e-16 Luego, los residuos (en este caso los residuos ordinarios) se pueden obtener con las siguientes funciones genericas: muestra_aleatoria$val_predicho &lt;- predict(Modelo_simple) muestra_aleatoria$res_ordinario &lt;- residuals(Modelo_simple) La gráfica a continuación presenta los valores observados y estimados en el rendimiento de los estudiantes en una prueba de matemáticas según su nivel socio-económico, siendo la misma una representación gráfica similar a la presentada en la Figura 6.1: Tenga en cuenta que se bien el modelo se ajusto con las 7185 valores observados, la gráfica a continuación solo presenta 150 valores. Esto debido a que al no restringir por este valor, la gráfica se presentaba muy saturada de valores observados y estimados. ## Warning: `guides(&lt;scale&gt; = FALSE)` is deprecated. Please use `guides(&lt;scale&gt; = ## &quot;none&quot;)` instead. Figure 11.1: Valores obserados y estimados en el rendimiento en una prueba matemática según el nivel socio-económico del estudiante. La gráfica anterior representa la relación existente entre el rendimiento académico y el nivel socio-económico del estudiante. Claramente se puede observar que a mayor nivel socio-económico, mejor es el rendimiento del estudiante. Una vez ajustado el modelo de regresión, y como se puede observar en la anterior gráfica, se tienen los valores observados (puntos con relleno), los valores estimados (puntos sin relleno) y el residuo (representado por una línea vertical que une a los valores observados con los estimados). Por tanto, puede imaginar ahora que cada dato (valor observado) tiene un valor estimado y un residuo (residuo ordinario en este caso) como se detalla a continuación: Rendimiento real Rendimiento estimado Residuo ordinario 9.670 16.44451 -6.774512 24.488 17.39127 7.096730 12.500 11.01095 1.489052 23.231 15.78590 7.445102 Luego dichos residuos se consideran como elementos clave en la evaluación del modelo ajustado. Estos suelen emplearse en los métodos de diagnosticos del modelo de regresión mediante pruebas de hipótesis acompañadas de inferencia visual (gráficos). Por ejemplo, la figura a continuación muestra una de las gráficas comunmente usadas en los métodos de diagnostico: ## Warning: `guides(&lt;scale&gt; = FALSE)` is deprecated. Please use `guides(&lt;scale&gt; = ## &quot;none&quot;)` instead. Figure 11.2: Gráfica de residuos ordinarios vs Valores estimados. Existe una gran variedad de gráficos (como la presentada anteriormente) lo que refleja el hecho de que ningún gráfico de diagnóstico es apropiado para todos los propósitos. Veremos la interpretación de la misma con más detalle a continuación. 11.3 Diagnóstico del modelo de regresión: prueba de hipótesis e inferencia visual Como es sabido, la inferencia estadística clásica consiste en formular inicialmente un juego de hipótesis (hipótesis nula y alternativa), y calcular posteriormente un estadístico de prueba del cual se deriva un valor p que permitira concluir en relación a las hipótesis planteadas. Este proceso tiene su análogo en inferencia visual. Suponga que el interés consiste en verificar alguna suposición sobre el modelo ajustado, por ejemplo, la homogeneidad de la varianza residual. Para ello se plantea como hipótesis nula el cumplimiento de dicha homogeneidad, mientras que la hipótesis alternativa abarca cualquier violación de este supuesto. Para la inferencia visual, el estadístico de prueba corresponde a una gráfica que muestra un aspecto del supuesto que se desea verifcar, y permite al observador distinguir entre escenarios bajo la hipótesis nula y la alternativa. A continuación se mostrará como llevar a cabo el diagnóstico del modelo de regresión empleando tanto pruebas de hipótesis como inferencia visual. Para ello, haremos uso de nuevo de la base de datos anteriormente mencionada hsb. 11.3.1 Ajustando el modelo Vimos anteriormente en este capitulo que era posible determinar si el rendimiento de los estudiantes en una prueba de matemáticas (mathach) estaba relacionada con su nivel socio-económico (ses). Se considerará ahora la posibilidad de que la relación entre el rendimiento y el nivel socio-económico del estudiante varien según las características de la escuela, específicamente, si la escuela es una escuela pública o una escuela privada (schtype). Un buen punto de partida consiste es ver la relación entre el rendimiento y el nivel socio-económico por separado para cada escuela: Figure 11.3: Diagrama de dispersión del rendimiento matemático según el nivel socio-económico en escuelas públicas. Figure 11.4: Diagrama de dispersión del rendimiento matemático según el nivel socio-económico en escuelas privadas. En cada panel, la línea representa un ajuste lineal por mínimos cuadrados a los datos. El número en la parte superior corresponde a la identificación de la escuela (en este caso se han elegido doce escuelas para cada tipo). Claramente parece haber una diferencia entre la escuelas públicas y privadas: las líneas para las escuelas públicas parecen tener pendientes más pronunciadas. Esto hace pensar que un modelo de efectos mixtos con intercepto y pendiente aleatoria podría ser adecuado para modelar este tipo de datos. Por tal motivo, el modelo de regresión de efectos mixtos aplicado a este ejemplo se puede representar así: \\[\\begin{align*} y_{ij} &amp;\\sim N(\\mu_{ij}, \\sigma^2), \\\\ \\mu_{ij} &amp;= \\beta_0 + \\beta_1 x_{ij} + b_{0i} + b_{1i} x_{ij}, \\\\ \\left ( \\begin{matrix} b_{0} \\\\ b_{1} \\end{matrix} \\right ) &amp;\\sim N\\left [ \\left ( \\begin{matrix} 0 \\\\ 0 \\end{matrix} \\right ), \\left ( \\begin{matrix} \\sigma^2_{b0} &amp; \\sigma_{b01} \\\\ \\sigma_{b01} &amp; \\sigma^2_{b1} \\end{matrix} \\right ) \\right ] \\end{align*}\\] Esta ecuación representa la relación existente entre el rendimiento acádemico y el nivel socio-económico de los estudiantes. La variable respuesta, \\(y_{ij}\\), es el rendimiento del estudiante, \\(i\\), en la escuela \\(j\\). El codigó en R para ajustar el anterior modelo se presenta a continuación. Se hara uso del paquete lme4 ya mencionado en el capitulo 3 del presente libro: library(lme4) Modelo_mixto &lt;- lmer(mathach ~ ses + (ses | schtype), REML = TRUE, data = hsb) La siguiente figura, obtenida a partir del modelo anteriormente ajustado, pone de manifiesto la posibilidad real y plausible de que el intercepto y la pendiente varíen según las características de cada escuela (privada o pública): Figure 11.5: Grafica del modelo de regresión ajustado para dos escuelas. Luego de ajustado el modelo de regresión, el procedimiento a seguir corresponde a evaluar el cumplimiento de los supuestos del mismo mediante métodos de diagnóstico. 11.3.2 Varianza constante de los residuos mediante inferencia visual Uno de los supuestos del modelo de regresión es la varianza constante de los residuos. Para comprobar dicho supuesto, se suele emplear la gráfica de residuos contra los valores estimados. La misma es considerada como la gráfica de diagnóstico más básica. A continuación podrá observar varios ejemplos de la misma: Figure 11.6: Representación visual de la gráfica de residuos contra los valores estimados. Si se cumple el supuesto de varianza constante de los residuos, estos se dispersarían de forma aleatoria alrededor de la línea central (como si se tratara de una nube de puntos) sin un patrón obvio, como se puede observar en la figura 6.7 A. La varianza no constante se diagnosticaría si la variabilidad de los residuos en el gráfico mostraran un patrón no aleatorio, como por ejemplo, si hubiera una curvatura presente (figura 6.7 B), o bien, si los residuos cambiaran de forma abrupta a medida que aumentan los valores estimados. Finalmente, un patrón inusual puede ser causado por un valor atípico. En el ejemplo visual anterior (figura 6.7 C), se muestra un valor atípico obvio. En el ejemplo planteado usando la base de datos hsb, esta gráfica se muestra en las figuras 6.8 A y 6.8 C, basados en dos tipos de residuos (ordinarios y pearson): Figure 11.7: Gráficos residuales para el modelo de efectos mixtos (a) entre los residuos ordinarios contra los valores estimados (b) residuos ordinarios en cada tipo de escuela (c) residuos pearson contra los valores estimados (d) residuos pearson en cada tipo de escuela. En relación al código presentado anteriormente, tenga en cuenta lo siguiente: Las gráficas se realizaron usando la función ggplot (aquí subrayado en color amarillo) del paquete ggplot2; Luego en la asignación estética (aes), se proporcionó los valores estimados y los residuos pearson u ordinarios (aquí subrayados en color azul), datos que se obtuvieron mediante previo ajuste del modelo; La línea discontinua en las gráficas superior e inferior izquierda, es la línea horizontal a través de \\(\\hat{\\epsilon}_{i} = 0\\) (es decir, donde la diferencia entre los valores observados y estimados son iguales a cero), siendo el mismo el caso ideal; La línea continua en rojo en las gráficas superior e inferior izquierda, obtenidas a partir de la función stat_smoot (aquí subrayado en amarillo), representan una curva suave ajustada mediante el método loess, que indica la relación de los valores estimados con los residuos. En general, los gráficos anteriores se evalúan de forma informal con respecto a la presencia o ausencia de patrones específicos y/o puntos de datos periféricos o aislados. Respecto a la línea de referencia en cero y la línea ajustada mediante el método de loess, estas deberían parecerse. Por otro lado en cuanto al gráfico de caja y bigotes (parte superior e inferior derecha de la anterior figura), si estas tienen aproximadamente el mismo centro y distancia intercuartil, indicarían el cumplimiento de varianza constante de los residuos. 11.3.3 Varianza constante de los residuos mediante prueba de hipótesis Por lo general, es suficiente con interpretar de forma visual una gráfica de residuos contra valores estimados para comprobar la validez del supuesto de varianza constante de los residuos. Sin embargo, existen pruebas que pueden proporcionar una justificación adicional en el análisis. Dichas pruebas plantean el siguiente constraste de hipótesis: \\[H_{0}: \\sigma^{2}_{\\epsilon_{1}} = \\sigma^{2}_{\\epsilon_{2}}\\] \\[H_{A}: \\sigma^{2}_{\\epsilon_{1}} \\ne \\sigma^{2}_{\\epsilon_{2}}\\] Así, \\(H_{0}\\) (la hipótesis nula) sugiere una varianza constante de los residuos. A continuación se mencionan algunas de estas pruebas: Prueba Función en R Paquete en R Contraste de razón de varianzas var.test stats Prueba de Levene leveneTest car Prueba de Bartlett bartlett.test stats Prueba de Brown-Forsyth hov HH Prueba de Fligner-Killeen fligner.test stats * La diferencias entre estas pruebas es el estadístico de centralidad que utilizan, así como también la sensibilidad o no al cumplimiento del supuesto de normalidad. Para el contraste de hipótesis, cada una de las pruebas entrega un valor-P. Si el valor-P cumple con la condición de ser menor que un nivel de significancia impuesto arbitrariamente, este se considera como un resultado estadisticamente significativo y, por lo tanto, permite rechazar la hipótesis nula, dando como resultado el no cumplimiento de la varianza constante de los residuos. Ejemplo La función help y el operador de ayuda ? en R proporcionan acceso a las páginas de documentación para funciones de R, conjuntos de datos y otros objetos, así por ejemplo para acceder a la documentación de la función var.test del paquete stats, se puede ingresar el comando help(var.test) o help(\"var.test\"), o ?var.test o ?\"var.test\" (por tanto, las comillas son opcionales). Haciendo uso de cualquiera de los dos comandos de ayuda anteriores, se plantea como ejemplo acceder a la documentación de la función leveneTest del paquete car, y con ella evaluar por medio de la prueba de Brown-Forsyth si las varianzas de los errores de los dos tipos de escuela (privada y pública) de la base de datos hsb cumplen con el supuesto de varianza constante de los errores. Suponga un nivel de significancia igual a 0.05. Solución. Para acceder a la documentación de ayuda de la función leveneTest del paquete car: help(&quot;leveneTest&quot;, package = &quot;car&quot;) Dicha documentación indica que el argumento y corresponde a la variable respuesta, group corresponde a la variable (factor) al que se desea evaluar la homogeneidad, y center donde se define el estadístico de centralidad. Para el ejemplo: library(car) leveneTest(y = hsb$res_ordinario, group = hsb$schtype, center = &#39;median&#39;) ## Levene&#39;s Test for Homogeneity of Variance (center = &quot;median&quot;) ## Df F value Pr(&gt;F) ## group 1 20.102 7.456e-06 *** ## 7183 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Por lo tanto como el valor-P (7.456e-06) fue menor al nivel de significancia (0.05), se rechaza \\(H_{0}\\), lo que permite concluir que los dos tipos de escuela (privada y pública) presentan diferencias estadísticas significativas en la varianza de los errores. 11.3.4 Distribución normal de los residuos mediante inferencia visual Los análisis de normalidad, también denominados como contraste de normalidad, son otro tipo de supuesto del modelo de regresión. Al igual que el supuesto de varianza constante de los residuos, en el análisis de normalidad se suele emplear representaciones gráficas. Esta representación consiste en la gráfica de probabilidad normal de los residuos, también denominada como gráfico cuantil cuantil. A continuación podrá observar un ejemplo de dichas representaciones en el caso del cumplimiento o no del supuesto de normalidad: Figure 11.8: Ejemplo de distribución normal de los residuos y de aquellos residuos que no cumplen con este supuesto. Si se cumple el supuesto de normalidad de los residuos, los puntos que constituyen la gráfica de probabilidad normal deberían alinearse entorno a la línea recta, como se puede observar en la figura 6.9 A (a la izquierda). Esta interpretación se evidencia al representar su equivalente mediante un histograma (figura 6.9 A a la derecha). Las posibles causas de alejamiento a la normalidad se mencionan a continuación: La variable respuesta podría tener muchos valores pequeños y pocos valores grandes, dando una representación de asimetría positiva (figura 6.9 B), o lo contrario, pocos valores pequeños y muchos valores grandes (asimetría negativa); Al ajustarse el modelo y representar los residuos resultantes mediante un histograma, se podría observar una distribución de colas livianas producto de obtener pocos residuos de gran magnitud (figura 6.9 C), o bien, muchos residuos de gran magnitud podría conducir a una distribución de colas pesadas. El gráfico cuantil cuantil tiene dos ejes, uno para los cuantiles que se generan a partir del conjunto de datos (cuantiles de la distribución observada) y uno para los cuantiles generados a partir de la distribución normal (cuantiles teóricos de la distribución normal). En el ejemplo planteado usando la base de datos hsb, la gráfica de probabilidad normal de los residuos se muestra en la figura a continuación. Figure 11.9: Gráfico cuantil cuantil para el modelo de efectos mixtos previamente ajustado. En relación al código presentado anteriormente, tenga en cuenta lo siguiente: En la asignación estética (aes) usando el paquete ggplot2, se proporcionó los residuos pearson (aquí subrayados en color azul), datos que se obtuvieron mediante previo ajuste del modelo; A partir de la función stat_qq (aquí subrayado en color amarillo), se dibuja la línea de puntos el cual indica la ubicación de los datos de acuerdo a los cuantiles de la distribución normal y de la distribución observada; Con la función stat_qq_line (aquí subrayado en color amarillo), se dibuja una línea recta. Si los puntos estan cerca a la misma, significa que los datos y la distribución normal tienen cuantiles comparables y se cumple el supuesto de normalidad de los residuos. Ejemplo En algunos casos es deseable identificar la distribución que siguen los datos en lugar de identificar la distribución que no siguen. Aswath Damodaran en el documento probabilistic approaches: scenario analysis, decision trees and simulation discute las características clave de las distribuciones más comunes, y en una de las figuras presentadas en dicho documento proporciona un diagrama de árbol para elegir una distribución. Un ejemplo del mismo (para datos continuos) se presenta a continuación: Figure 11.10: Diagrama de árbol para elegir el tipo de distribución de los datos, adaptado de Aswath Damodaran. Al observar la figura 6.10 se puede concluir que el rendimiento en la evaluación en la prueba de matemáticas (mathach) de la base de datos hsb no cumple el supuesto de normalidad, una vez se aprecia que los puntos no están del todo alineados entorno a la recta, observándose unas ligeras desviaciones en las colas. En este sentido y haciendo uso del diagrama de árbol presentado con anterioridad, elija la distribución que más se acerca a la distribución presentada por dicho datos. Para ello le puede resultar útil construir un histograma. Solución. ggplot(data = hsb, aes(x = res_pearson)) + geom_histogram(aes(y = ..density..), bins = 8, colour = &quot;yellow&quot;, fill = &quot;yellow&quot;, alpha = 0.4) + geom_density(size = 1.0, colour = &quot;black&quot;) + labs(x = &quot;Residuos Pearson&quot;, y = &quot;Frecuencia&quot;) + theme_bw() + theme(axis.text = element_text(size = 12, face = &quot;bold&quot;), axis.title = element_text(size = 12, face = &quot;bold&quot;), plot.title = element_text(size = 12, face = &quot;bold&quot;)) Figure 11.11: . Verificar la distribución de los datos es uno de los primeros pasos en el análisis de datos. Al conocer dicha distribución se obtiene información sobre algunas de las propiedades estadísticas de los datos, las cuales se vuelven útiles, por ejemplo, cuando se necesita justificar si una prueba estadística en particular es apropiada. 11.3.5 Distribución normal de los residuos mediante prueba de hipótesis En el supuesto de normalidad de los residuos es posible realizar contraste de hipótesis que determinan si los datos siguen una distribución normal. Al igual que el supuesto de varianza constante, la prueba de distribución normal tiene una hipótesis nula (\\(H_{0}\\)) y una hipótesis alternativa (\\(H_{A}\\)): \\[H_{0}: e \\sim N(0, \\sigma^{2})\\] \\[H_{A}: e \\nsim N(0, \\sigma^{2})\\] Así, \\(H_{0}\\) (la hipótesis nula) sugiere una distribución normal de los residuos. A continuación se mencionan algunas de las pruebas estadísticas usadas para comprobar la validez del supuesto de normalidad de los residuos: Prueba Función en R Paquete en R Shapiro-Wilk shapiro.test stats Kolmogorov-Smirnov ks.test stats Lillefors lillie.test nortest Jarque-Bera jarque.bera.test tseries De las anteriores pruebas de distribución, un valor-P menor a un nivel de significancia previamente definido indica el rechazo de la hipótesis nula, lo que permite concluir que los datos no siguen la distribución normal de los residuos. En relación a los resultados de las pruebas de normalidad, es importante tener en cuenta que al tratarse de valores-P, cuanto mayor es el tamaño de la muestra más poder estadístico tienen y más fácil es encontrar evidencias en contra de la hipótesis nula. Al mismo tiempo, cuanto mayor es el tamaño de la muestra, menos sensible es la prueba a la falta de normalidad. Por esta razón, es importante no basar las conclusiones únicamente en el valor-P de la prueba, sino también considerar la representación gráfica y el tamaño de la muestra. "],["var-fun.html", "12 Modelando la heterocedasticidad", " 12 Modelando la heterocedasticidad En este capítulo se mostrará como usar el paquete nlme para modelar heterocedasticidad. https://pegasus.uprm.edu/~pedro.torres/book/ "],["glmm.html", "13 Modelos Lineales Generalizados Mixtos 13.1 Videos de apoyo", " 13 Modelos Lineales Generalizados Mixtos Los modelos lineales generalizados mixtos (glmm) fueron propuestos por (Breslow and Clayton 1993) y en ellos se asume que existe una relación entre el vector de observaciones \\(\\boldsymbol{Y}_i\\) del sujeto o grupo \\(i\\) y las covariables por medio de la siguiente expresión \\[\\begin{equation} \\begin{aligned} \\boldsymbol{Y}_i \\mid \\boldsymbol{b}_i &amp;\\sim \\mathcal{F}(\\boldsymbol{X}_i \\boldsymbol{\\beta} + \\boldsymbol{Z}_i \\boldsymbol{b}_i, \\phi), \\\\ \\boldsymbol{b}_i &amp;\\sim \\mathcal{N}(\\boldsymbol{0}, \\boldsymbol{D}), \\end{aligned} \\tag{13.1} \\end{equation}\\] donde \\(\\mathcal{F}\\) corresponde a una distribución de la familia exponencial que incluye las distribuciones normal, Poisson, binomial negativa, gamma e inversa gaussiana. Las matrices \\(\\boldsymbol{X}_i\\) y \\(\\boldsymbol{Z}_i\\) son matrices de diseño conocidas con la información de las covariables, siendo \\(\\boldsymbol{X}_i\\) de dimensión \\(n_i \\times p\\) y \\(\\boldsymbol{Z}_i\\) de dimensión \\(n_i \\times q\\). El elemento \\(\\boldsymbol{\\beta}\\) representa el vector de efectos fijos general, \\(\\boldsymbol{b}_i\\) el vector de efectos aleatorios exclusivo para el grupo \\(i\\). El vector \\(\\boldsymbol{b}_i\\) en la expresión (13.1) es llamado efecto aleatorio porque éste cambia la media de sujeto a sujeto y su función es la de mejorar el ajuste general dado por el elemento \\(\\boldsymbol{X}_i \\boldsymbol{\\beta}\\) al agregar la cantidad \\(\\boldsymbol{Z}_i \\boldsymbol{b}_i\\). El modelo dado en la expresión (13.1) es llamado también modelo mixto porque involucra tanto efectos fijos (\\(\\boldsymbol{\\beta}\\)) como efectos aleatorios (\\(\\boldsymbol{b}_i\\)). La distribución marginal de \\(\\boldsymbol{Y}_i\\) está dada por \\[\\begin{equation} f_i(\\boldsymbol{Y}_i) = \\int f(\\boldsymbol{Y}_i | \\boldsymbol{b}_i) f(\\boldsymbol{b}_i) \\, d \\boldsymbol{b}_i \\end{equation}\\] donde \\(f(\\boldsymbol{Y}_i | \\boldsymbol{b}_i)\\) corresponde a la densidad normal, Poisson, binomial negativa, gamma o inversa gaussina y \\(f(\\boldsymbol{b}_i)\\) corresponde a la distribución normal bivariada mostrada en (13.1). La función de verosimilitud para el vector de parámetros \\(\\boldsymbol{\\Theta}=(\\boldsymbol{\\beta}, \\phi, \\boldsymbol{D})^\\top\\) se puede escribir como \\[ L(\\boldsymbol{\\Theta}) = \\prod_{i=1}^{n} \\int f(\\boldsymbol{Y}_i | \\boldsymbol{b}_i) f(\\boldsymbol{b}_i) \\, d \\boldsymbol{b}_i . \\] 13.1 Videos de apoyo En esta sección se muestran los videos sobre glmm creados por la profesora Christina Knudson. Esta lista de reproducción contiene varios con explicaciones sencillas sobre los glmm que sirven como introducción al tema. A continuación el primer video de la lista de reproducción. References "],["pac-glmmTMB.html", "14 Paquete glmmTMB 14.1 Función glmmTMB Ejemplo: modelo normal con intercepto aleatorio Ejemplo: recuperando los interceptos aleatorios Ejemplo: modelo gamma con intercepto aleatorio", " 14 Paquete glmmTMB El paquete glmmTMB de Magnusson et al. (2021) se utiliza para estimar modelos glmm por medio de máxima verosimilitud a través de TMB (Template Model Builder). Se supone que los efectos aleatorios son gaussianos en la escala del predictor lineal y se integran utilizando la aproximación de Laplace. Los gradientes se calculan mediante la diferenciación automática. Al visitar este enlace se encontrará la página de apoyo del paquete, allí se puede consultar el manual de referencia y las viñetas. 14.1 Función glmmTMB La función glmmTMB es la principal función del paquete glmmTMB. Esta función sirve para ajustar un glmm y su estructura es la siguiente: glmmTMB(formula, data = NULL, family = gaussian(), ziformula = ~0, dispformula = ~1, weights = NULL, offset = NULL, contrasts = NULL, na.action, se = TRUE, verbose = FALSE, doFit = TRUE, control = glmmTMBControl(), REML = FALSE, start = NULL, map = NULL, sparseX = NULL ) Los principales argumentos de la función son: formula: es una fórmula similar a la usada en el modelo lineal clásico. Un ejemplo de fórmula sería y ~ 1 + x1 + x2 + (1 + x2 | grupo) con la cual se indican los efectos fijos y los efectos aleatorios del modelo. Más abajo hay una tabla con más detalles sobre la fórmula. data: marco de datos donde están las variables. family: argumento para indicar la distribución de la variable respuesta. REML: valor lógico que sirve para indicar si queremos estimaciones maximizando la verosimilitud restringida o la verosimilitud usual. Ejemplo: modelo normal con intercepto aleatorio En este ejemplo vamos a simular observaciones \\(n_i=50\\) observaciones para \\(G=10\\) grupos (en total 500 obs) que tengan la estructura mostrada abajo. El objetivo del ejemplo es ilustrar el uso de la función glmmTMB para estimar los parámetros del modelo. \\[\\begin{align*} y_{ij} | b_0 &amp;\\sim N(\\mu_{ij}, \\sigma^2_y) \\\\ \\mu_{ij} &amp;= 4 - 6 x_{ij} + b_{0i} \\\\ \\sigma^2_y &amp;= 16 \\\\ b_{0} &amp;\\sim N(0, \\sigma^2_{b0}=625) \\\\ x_{ij} &amp;\\sim U(-5, 6) \\end{align*}\\] El vector de parámetros de este modelo es \\(\\boldsymbol{\\Theta}=(\\beta_0=4, \\beta_1=-6, \\sigma_y=4, \\sigma_{b0}=25)^\\top\\). Solución. El código para simular las 500 observaciones se muestra a continuación. Observe que se fijó la semilla en dos ocasiones para que el lector pueda replicar el ejemplo y obtener los mismos resultados. ni &lt;- 50 G &lt;- 10 nobs &lt;- ni * G grupo &lt;- factor(rep(x=1:G, each=ni)) obs &lt;- rep(x=1:ni, times=G) set.seed(1234567) x &lt;- runif(n=nobs, min=-5, max=6) set.seed(1234567) b0 &lt;- rnorm(n=G, mean=0, sd=sqrt(625)) # Intercepto aleatorio b0 &lt;- rep(x=b0, each=ni) # El mismo intercepto aleatorio pero repetido media &lt;- 4 - 6 * x + b0 set.seed(1234567) y &lt;- rnorm(n=nobs, mean=media, sd=sqrt(16)) datos &lt;- data.frame(obs, grupo, b0, x, media, y) Vamos a explorar los datos simulados. library(rmarkdown) paged_table(datos, options = list(rows.print = 6)) El siguiente paso es dibujar los datos para explorar si sería apropiado usar un modelo con intercepto aleatorio (obvio porque así se simularon los datos). El código para dibujar los datos se muestra abajo. library(ggplot2) ggplot(datos, aes(x, y, color=grupo) ) + geom_point() + labs(colour=&quot;Grupo/Cluster&quot;) En la figura anterior se observa un patrón claro, todas las 10 nubes de puntos tienen la misma pendiente pero diferente intercepto con el eje vertical, eso se debe a que en la simulación se incluyó un \\(b_0\\). Para estimar los parámetros del modelo se usa la función glmmTMB de la siguiente forma. library(glmmTMB) fit1 &lt;- glmmTMB(y ~ x + (1 | grupo), data = datos) La función summary se puede usar sobre el objeto fit1 para obtener una tabla de resumen, a continuación se ilustra el uso y la salida de summary. summary(fit1) ## Family: gaussian ( identity ) ## Formula: y ~ x + (1 | grupo) ## Data: datos ## ## AIC BIC logLik deviance df.resid ## 2871.3 2888.1 -1431.6 2863.3 496 ## ## Random effects: ## ## Conditional model: ## Groups Name Variance Std.Dev. ## grupo (Intercept) 579.20 24.066 ## Residual 15.46 3.931 ## Number of obs: 500, groups: grupo, 10 ## ## Dispersion estimate for gaussian family (sigma^2): 15.5 ## ## Conditional model: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) 2.23779 7.61256 0.29 0.769 ## x -6.02640 0.05614 -107.35 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Según el resultado anterior \\(\\hat{\\boldsymbol{\\Theta}}=(\\hat{\\beta}_0=2.2378, \\hat{\\beta}_1=-6.0264, \\hat{\\sigma}_y=3.931, \\hat{\\sigma}_{b0}=24.066)^\\top\\) mientras que el vector real de parámetros es \\(\\boldsymbol{\\Theta}=(\\beta_0=4, \\beta_1=-6, \\sigma_y=4, \\sigma_{b0}=25)^\\top\\). Compare los resultados de la tabla anterior obtenida con la función lmer anterior con los resultados obtenidos con la función lme de capítulo 6. ¿Hay alguna similitud? Ejemplo: recuperando los interceptos aleatorios ¿Cómo se pueden obtener los interceptos aleatorios a partir del modelo ajustado en la sección anterior? Solución. Para obtener los interceptos aleatorios se usa la función ranef del paquete glmmTMB de Magnusson et al. (2021). A continuación vamos a obtener los interceptos aleatorios y los vamos a comparar con los \\(b_0\\) simulados. interceptos_aleatorios &lt;- ranef(fit1) cbind(interceptos_aleatorios$grupo, b0=unique(b0)) ## b0 ## [1,] 3.917594 ## [2,] 34.345280 ## [3,] 18.266756 ## [4,] -33.770023 ## [5,] -0.212874 ## [6,] 8.024547 ## [7,] -44.453710 ## [8,] 22.737596 ## [9,] -22.985108 ## [10,] -3.942871 De la salida anterior vemos que los \\(\\tilde{b}_0\\) son cercanos a los valores reales de \\(b_0\\). La comparación anterior solo es posible cuando usamos datos simulados. Cuando se usan datos de un fenómeno real no se tienen los valores de \\(b_0\\). Ejemplo: modelo gamma con intercepto aleatorio En este ejemplo vamos a simular observaciones \\(n_i=20\\) observaciones para \\(G=10\\) grupos (en total 200 obs) que tengan la estructura mostrada abajo. El objetivo del ejemplo es ilustrar el uso de la función glmmTMB para estimar los parámetros del modelo. \\[\\begin{align*} y_{ij} | b_0 &amp;\\sim Gamma(\\mu_{ij}, \\phi) \\\\ \\log(\\mu_{ij}) &amp;= 2 - 8 x_{ij} + b_{0i} \\\\ \\phi &amp;= 0.5 \\\\ b_{0} &amp;\\sim N(0, \\sigma^2_{b0}=9) \\\\ x_{ij} &amp;\\sim U(0, 1) \\end{align*}\\] El vector de parámetros de este modelo es \\(\\boldsymbol{\\Theta}=(\\beta_0=2, \\beta_1=-8, \\phi=0.5, \\sigma_{b0}=3)^\\top\\). Solución. La función rgamma_glm que se muestra a continuación es una modificación de la función rgamma para tener la parametrización usada en los glm. rgamma_glm &lt;- function(n, mu, phi) { x &lt;- rgamma(n=n, shape=1/phi, scale=mu*phi) return(x) } A continuación el código para simular datos del modelo de interés. ni &lt;- 20 G &lt;- 10 nobs &lt;- ni * G grupo &lt;- factor(rep(x=1:G, each=ni)) obs &lt;- rep(x=1:ni, times=G) set.seed(123456) x &lt;- runif(n=nobs, min=0, max=1) set.seed(123456) b0 &lt;- rnorm(n=G, mean=0, sd=sqrt(9)) # Intercepto aleatorio b0 &lt;- rep(x=b0, each=ni) # El mismo intercepto aleatorio pero repetido media &lt;- exp(2 - 8 * x + b0) set.seed(123456) y &lt;- rgamma_glm(n=nobs, mu=media, phi=0.5) datos &lt;- data.frame(obs, grupo, b0, x, media, y) Vamos a explorar los datos simulados. library(rmarkdown) paged_table(datos, options = list(rows.print = 6, cols.print=6)) El siguiente paso es explorar los datos simulados. El código para dibujar los datos se muestra abajo. library(ggplot2) ggplot(datos, aes(x, y, color=grupo) ) + geom_point() + labs(colour=&quot;Grupo/Cluster&quot;) Para estimar los parámetros del modelos se usa la función glmer de la siguiente forma. library(glmmTMB) fit2 &lt;- glmmTMB(y ~ x + (1 | grupo), family=Gamma(link=&quot;log&quot;), data = datos) La función summary se puede usar sobre el objeto fit2 para obtener una tabla de resumen, a continuación se la salida de summary. summary(fit2) ## Family: Gamma ( log ) ## Formula: y ~ x + (1 | grupo) ## Data: datos ## ## AIC BIC logLik deviance df.resid ## 595.9 609.1 -294.0 587.9 196 ## ## Random effects: ## ## Conditional model: ## Groups Name Variance Std.Dev. ## grupo (Intercept) 9.073 3.012 ## Number of obs: 200, groups: grupo, 10 ## ## Dispersion estimate for Gamma family (sigma^2): 0.507 ## ## Conditional model: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) 4.4102 0.9581 4.60 4.16e-06 *** ## x -8.0789 0.1830 -44.14 &lt; 2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Según el resultado anterior \\(\\hat{\\boldsymbol{\\Theta}}=(\\hat{\\beta}_0=4.4102, \\hat{\\beta}_1=-8.0789, \\hat{\\phi}=0.507, \\hat{\\sigma}_{bo}=3.012)^\\top\\) mientras que el vector real de parámetros es \\(\\boldsymbol{\\Theta}=(\\beta_0=2, \\beta_1=-8, \\phi=0.50, \\sigma_{b0}=3)^\\top\\). References "],["pac-glmm.html", "15 Paquete glmm 15.1 Función glmm Ejemplo: modelo Poisson con intercepto aleatorio", " 15 Paquete glmm El paquete glmm de Knudson (2020) aproxima la verosimilitud de un modelo mixto lineal generalizado mediante aproximación de Monte Carlo. Al visitar este enlace se encontrará la página de apoyo del paquete, allí se puede consultar el manual de referencia y las viñetas. 15.1 Función glmm La función glmm es la principal función del paquete glmm. Esta función sirve para ajustar un glmm y su estructura es la siguiente: glmm(fixed, random, varcomps.names, data, family.glmm, m, varcomps.equal, weights=NULL, doPQL = TRUE,debug=FALSE, p1=1/3,p2=1/3, p3=1/3, rmax=1000,iterlim=1000, par.init, zeta=5, cluster=NULL) Los principales argumentos de la función son: formula: es una fórmula similar a la usada en el modelo lineal clásico. Un ejemplo de fórmula sería y ~ 1 + x1 + x2. random: es una fórmula solo con lado derecho. Si queremos indicar intercepto aleatorio se escribe ~ 1 | group y si se desea intercepto y pendiente aleatoria se escribe ~ 1 + x2 | group. data: marco de datos donde están las variables. family.glm: argumento para indicar la distribución de la variable respuesta. Ejemplo: modelo Poisson con intercepto aleatorio En este ejemplo vamos a simular observaciones \\(n_i=50\\) observaciones para \\(G=10\\) grupos (en total 500 obs) que tengan la estructura mostrada abajo. El objetivo del ejemplo es ilustrar el uso de la función glmm para estimar los parámetros del modelo. \\[\\begin{align*} y_{ij} | b_0 &amp;\\sim Poisson(\\mu_{ij}) \\\\ \\log(\\mu_{ij}) &amp;= 4 - 6 x_{ij} + b_{0i} \\\\ \\sigma^2_y &amp;= 16 \\\\ b_{0} &amp;\\sim N(0, \\sigma^2_{b0}=4) \\\\ x_{ij} &amp;\\sim U(0, 1) \\end{align*}\\] El vector de parámetros de este modelo es \\(\\boldsymbol{\\Theta}=(\\beta_0=4, \\beta_1=-6, \\sigma_y=4, \\sigma_{b0}=4)^\\top\\). Solución. El código para simular las 500 observaciones se muestra a continuación. Observe que se fijó la semilla en dos ocasiones para que el lector pueda replicar el ejemplo y obtener los mismos resultados. ni &lt;- 50 G &lt;- 10 nobs &lt;- ni * G grupo &lt;- factor(rep(x=1:G, each=ni)) obs &lt;- rep(x=1:ni, times=G) set.seed(1234567) x &lt;- runif(n=nobs, min=0, max=1) set.seed(1234567) b0 &lt;- rnorm(n=G, mean=0, sd=sqrt(4)) # Intercepto aleatorio b0 &lt;- rep(x=b0, each=ni) # El mismo intercepto aleatorio pero repetido media &lt;- exp(4 - 6 * x + b0) set.seed(1234567) y &lt;- rpois(n=nobs, lambda=media) datos &lt;- data.frame(obs, grupo, b0, x, media, y) Vamos a explorar los datos simulados. library(rmarkdown) paged_table(datos, options = list(rows.print = 6)) El siguiente paso es dibujar los datos para explorar si sería apropiado usar un modelo con intercepto aleatorio (obvio porque así se simularon los datos). El código para dibujar los datos se muestra abajo. library(ggplot2) ggplot(datos, aes(x, y, color=grupo) ) + geom_point() + labs(colour=&quot;Grupo/Cluster&quot;) Para estimar los parámetros del modelo se usa la función glmm de la siguiente forma. library(glmm) fit1 &lt;- glmm(y ~ x, random = list(y ~ 0 + grupo), varcomps.names = c(&quot;b0&quot;), family.glmm = poisson.glmm, data = datos, m = 10000) La función summary se puede usar sobre el objeto fit1 para obtener una tabla de resumen, a continuación se ilustra el uso y la salida de summary. summary(fit1) Call: glmm(fixed = y ~ x, random = list(y ~ 0 + grupo), varcomps.names = c(&quot;b0&quot;), data = datos, family.glmm = poisson.glmm, m = 10000) Link is: &quot;log&quot; Fixed Effects: Estimate Std. Error z value Pr(&gt;|z|) (Intercept) 0 0 28.39 &lt;2e-16 *** x -10 0 -115.47 &lt;2e-16 *** --- Signif. codes: 0 *** 0.001 ** 0.01 * 0.05 . 0.1   1 Variance Components for Random Effects (P-values are one-tailed): Estimate Std. Error z value Pr(&gt;|z|)/2 b0 0 0 2.212 0.0135 * --- Signif. codes: 0 *** 0.001 ** 0.01 * 0.05 . 0.1   1 Nota: este paquete se debe usar con precaución. References "],["pac-MASS.html", "16 Paquete MASS 16.1 Función glmmPQL Ejemplo: modelo Bernoulli (binomial) con intercepto aleatorio 16.2 what it means for AIC NA in glmmPQL (MASS) summary output? 16.3 Two questions on the results from glmmPQL(MASS) 16.4 How do I interpret the variance of random effect in a generalized linear mixed model?", " 16 Paquete MASS El paquete MASS de Ripley (2021) se utiliza para estimar modelos glmm por medio de Penalized Quasi-Likelihood (PQL). Al visitar este enlace se encontrará la página de apoyo del paquete, allí se puede consultar el manual de referencia y las viñetas. 16.1 Función glmmPQL La función glmmPQL es la principal función del paquete glmmMAAS. Esta función sirve para ajustar un glmm y su estructura es la siguiente: glmmPQL(fixed, random, family, data, correlation, weights, control, niter = 10, verbose = TRUE, ...) Los principales argumentos de la función son: formula: es una fórmula similar a la usada en el modelo lineal clásico. Un ejemplo de fórmula sería y ~ 1 + x1 + x2 + (1 + x2 | grupo) con la cual se indican los efectos fijos y los efectos aleatorios del modelo. Más abajo hay una tabla con más detalles sobre la fórmula. random: es una fórmula solo con lado derecho. Si queremos indicar intercepto aleatorio se escribe ~ 1 | group y si se desea intercepto y pendiente aleatoria se escribe ~ 1 + x2 | group. data: marco de datos donde están las variables. family: argumento para indicar la distribución de la variable respuesta. Ejemplo: modelo Bernoulli (binomial) con intercepto aleatorio En este ejemplo vamos a simular observaciones \\(n_i=50\\) observaciones para \\(G=10\\) grupos (en total 500 obs) que tengan la estructura mostrada abajo. El objetivo del ejemplo es ilustrar el uso de la función glmmPQL para estimar los parámetros del modelo. \\[\\begin{align*} y_{ij} | b_0 &amp;\\sim \\text{Bernoulli}(\\mu_{ij}) \\\\ \\text{logit}(\\mu_{ij}) &amp;= 4 - 8 x_{ij} + b_{0i} \\\\ b_{0} &amp;\\sim N(0, \\sigma^2_{b0}=4) \\\\ x_{ij} &amp;\\sim U(0, 1) \\end{align*}\\] El vector de parámetros de este modelo es \\(\\boldsymbol{\\Theta}=(\\beta_0=4, \\beta_1=-8, \\sigma_{b0}=2)^\\top\\). Solución. El código para simular las 500 observaciones se muestra a continuación. Observe que se fijó la semilla en dos ocasiones para que el lector pueda replicar el ejemplo y obtener los mismos resultados. logit_inv &lt;- function(x) exp(x) / (exp(x) + 1) # Función enlace inversa ni &lt;- 50 G &lt;- 10 nobs &lt;- ni * G grupo &lt;- factor(rep(x=1:G, each=ni)) obs &lt;- rep(x=1:ni, times=G) set.seed(12345) x &lt;- runif(n=nobs, min=0, max=1) set.seed(12345) b0 &lt;- rnorm(n=G, mean=0, sd=sqrt(4)) # Intercepto aleatorio b0 &lt;- rep(x=b0, each=ni) # El mismo intercepto aleatorio pero repetido prob &lt;- logit_inv(4 - 8 * x + b0) set.seed(12345) y &lt;- rbinom(n=nobs, size=1, prob=prob) datos &lt;- data.frame(obs, grupo, b0, x, prob, y) Para estimar los parámetros del modelo se usa la función glmmPQL de la siguiente forma. library(nlme) library(MASS) fit1 &lt;- glmmPQL(y ~ x, random = ~ 1 | grupo, niter=20, family = binomial(link = &quot;logit&quot;), data = datos) La función summary se puede usar sobre el objeto fit1 para obtener una tabla de resumen, a continuación se ilustra el uso y la salida de summary. summary(fit1) ## Linear mixed-effects model fit by maximum likelihood ## Data: datos ## AIC BIC logLik ## NA NA NA ## ## Random effects: ## Formula: ~1 | grupo ## (Intercept) Residual ## StdDev: 3.089343 1.195473 ## ## Variance function: ## Structure: fixed weights ## Formula: ~invwt ## Fixed effects: y ~ x ## Value Std.Error DF t-value p-value ## (Intercept) 4.864553 1.1476975 489 4.238533 0 ## x -7.811406 0.9982813 489 -7.824854 0 ## Correlation: ## (Intr) ## x -0.493 ## ## Standardized Within-Group Residuals: ## Min Q1 Med Q3 Max ## -5.88958933 -0.20167529 0.02509534 0.24445852 8.17974927 ## ## Number of Observations: 500 ## Number of Groups: 10 Según el resultado anterior \\(\\hat{\\boldsymbol{\\Theta}}=(\\hat{\\beta}_0=4.86, \\hat{\\beta}_1=-7.81, \\hat{\\sigma}_{b0}=3.09)^\\top\\) mientras que el vector real de parámetros es \\(\\boldsymbol{\\Theta}=(\\beta_0=4, \\beta_1=-8, \\sigma_{b0}=2)^\\top\\). 16.2 what it means for AIC NA in glmmPQL (MASS) summary output? Esta pregunta fue hecha en StackOverFlow y puede ser consultada en este enlace. 16.3 Two questions on the results from glmmPQL(MASS) Esta pregunta fue hecha en la comunidad de usuarios de R y puede ser consultada en este enlace. 16.4 How do I interpret the variance of random effect in a generalized linear mixed model? Esta pregunta fue hecha en CrossValidated y puede ser consultada en este enlace. References "],["glmm_poisson.html", "17 GLMM Poisson", " 17 GLMM Poisson En este capítulo se presenta un ejemplo de glmm con variable respuesta Poisson y está basado en esta publicación. A continuación la base de datos a utilizar. require(foreign) datos &lt;- read.dta(&quot;https://stats.idre.ucla.edu/stat/data/hsbdemo.dta&quot;) # Cambios menores a algunas variables datos$cid &lt;- factor(datos$cid) datos$female &lt;- ifelse(datos$female == &#39;female&#39;, 1, 0) Los datos corresponden a una muestra de 200 estudiantes de educación secundaria, los cuales están agrupados en 20 escuelas diferentes. El propósito es modelar el número de premios que recibe un estudiante dada la escuela a la cual pertenece, teniendo en cuenta la variable género como la variable que mejor podría ayudar en la predicción. Las variables de la base de datos son: awards: Variable respuesta que hace referencia al número de premios que recibe un estudiante. id: Identificación única de los estudiantes de educación secundaria que participaron en el estudio. female: Variable correspondiente al género de los estudiantes. ses: Variable categórica que representa el estatus socioeconómico del estudiante, teniendo tres distinciones las cuales son: bajo, medio y alto. schtyp: Tipo de escuela, ya sea privado o público. prog: Programa de formación del estudiante, ya sea general, vocación o académico. read: Puntuación del estudiante en comprensión lectora. write: Puntuación del estudiante en escritura. math: Puntuación del estudiante en matemáticas. science: Puntuación del estudiante en ciencias. honors: Variable que hace referencia si el estudiante presenta matrículas de honor o no. cid: Variable que indica la escuela a la cual pertenece el estudiante. Vamos a explorar las primeras líneas de la base de datos. head(datos, n=5) ## id female ses schtyp prog read write math science socst honors ## 1 45 1 low public vocation 34 35 41 29 26 not enrolled ## 2 108 0 middle public general 34 33 41 36 36 not enrolled ## 3 15 0 high public vocation 39 39 44 26 42 not enrolled ## 4 67 0 low public vocation 37 37 42 33 32 not enrolled ## 5 153 0 middle public vocation 39 31 40 39 51 not enrolled ## awards cid ## 1 0 1 ## 2 0 1 ## 3 0 1 ## 4 0 1 ## 5 0 1 El siguiente código sirve para construir un histograma que muestra el número de premios por cada escuela. library(ggplot2) ggplot(datos, aes(awards)) + geom_histogram(binwidth = 0.5) + facet_wrap(~cid) De la figura anterior vemos que el comportamiento de la variable respuesta awards es muy diferente dada la escuela. En la siguiente figura se relaciona el número de premios awards con la variable género. ggplot(datos, aes(factor(awards))) + geom_bar(aes(fill = factor(female)), position = &quot;fill&quot;) + geom_hline(yintercept = 0.5) De la figura anterior se observa una posible relación entre el número de premios está relacionado y el género. Los modelos lineales generalizados mixtos nos permiten modelar la variable respuesta con la distribución Poisson o la binomial negativa, en este caso, vamos a usar la distribución Poisson. El primer modelo que vamos a considerar aquí es el siguiente: \\[\\begin{align*} y_{ij} | b_0 &amp;\\sim Poisson(\\mu_{ij}) \\\\ \\log(\\mu_{ij}) &amp;= \\beta_0 + b_{0i} \\\\ b_0 &amp;\\sim N(0, \\sigma_{b0}^2) \\end{align*}\\] con \\(i=1, 2, \\ldots, 20\\) y \\(j=1, 2, \\ldots, n_i\\). El modelo anterior se va a ajustar con la función glmer del paquete lme4 de Bates et al. (2021) y utilizando 15 puntos en la aproximación de Gauss para la log-verosimilitud. require(lme4) m1 &lt;- glmer(awards ~ 1 + (1 | cid), data = datos, family = poisson(link = &quot;log&quot;), nAGQ = 15) Los resultados del modelo se muestran a continuación. summary(m1) ## Generalized linear mixed model fit by maximum likelihood (Adaptive ## Gauss-Hermite Quadrature, nAGQ = 15) [glmerMod] ## Family: poisson ( log ) ## Formula: awards ~ 1 + (1 | cid) ## Data: datos ## ## AIC BIC logLik deviance df.resid ## 228.6 235.2 -112.3 224.6 198 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -1.3857 -0.5260 -0.3383 0.3379 3.3769 ## ## Random effects: ## Groups Name Variance Std.Dev. ## cid (Intercept) 1.458 1.207 ## Number of obs: 200, groups: cid, 20 ## ## Fixed effects: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) -0.009572 0.290292 -0.033 0.974 El segundo modelo que se propone es una modificación del modelo 1, agregando como variable explicativa el género femenino. El modelo propuesto es el siguiente: \\[\\begin{align*} y_{ij} | b_0 &amp;\\sim Poisson(\\mu_{ij}) \\\\ \\log(\\mu_{ij}) &amp;= \\beta_0 + \\beta_1 female_{ij} + b_{0i} \\\\ b_0 &amp;\\sim N(0, \\sigma_{b0}^2) \\end{align*}\\] con \\(i=1, 2, \\ldots, 20\\) y \\(j=1, 2, \\ldots, n_i\\). require(lme4) m2 &lt;- glmer(awards ~ 1 + female + (1 | cid), data = datos, family = poisson(link = &quot;log&quot;), nAGQ = 15) Los resultados del modelo se muestran a continuación. summary(m2) ## Generalized linear mixed model fit by maximum likelihood (Adaptive ## Gauss-Hermite Quadrature, nAGQ = 15) [glmerMod] ## Family: poisson ( log ) ## Formula: awards ~ 1 + female + (1 | cid) ## Data: datos ## ## AIC BIC logLik deviance df.resid ## 221.1 231.0 -107.6 215.1 197 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -1.5312 -0.5919 -0.3304 0.2047 2.8806 ## ## Random effects: ## Groups Name Variance Std.Dev. ## cid (Intercept) 1.431 1.196 ## Number of obs: 200, groups: cid, 20 ## ## Fixed effects: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) -0.2229 0.2975 -0.749 0.45370 ## female 0.3632 0.1193 3.044 0.00234 ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Correlation of Fixed Effects: ## (Intr) ## female -0.252 Para comparar los dos modelos ajustados propuestos colocamos los resultados en una única tabla como se muestra a continuación. library(&quot;texreg&quot;) screenreg(list(m1, m2)) ## ## ========================================== ## Model 1 Model 2 ## ------------------------------------------ ## (Intercept) -0.01 -0.22 ## (0.29) (0.30) ## female 0.36 ** ## (0.12) ## ------------------------------------------ ## AIC 228.63 221.12 ## BIC 235.23 231.01 ## Log Likelihood -112.32 -107.56 ## Num. obs. 200 200 ## Num. groups: cid 20 20 ## Var: cid (Intercept) 1.46 1.43 ## ========================================== ## *** p &lt; 0.001; ** p &lt; 0.01; * p &lt; 0.05 library(stargazer) stargazer(m1, m2, type = &quot;html&quot;) Dependent variable: awards (1) (2) female 0.363*** (0.119) Constant -0.010 -0.223 (0.290) (0.298) Observations 200 200 Log Likelihood -112.315 -107.558 Akaike Inf. Crit. 228.630 221.116 Bayesian Inf. Crit. 235.227 231.011 Note: p&lt;0.1; p&lt;0.05; p&lt;0.01 En los resultados que obtenemos de esta tabla podemos ver que la log-verosimilitud aument para el modelo 2 en relación ál modelo 1. Además podemos observar que tanto el AIC como el BIC del modelo 2 son menores que los del modelo 1. Por lo tanto, basados en esto, concluimos que el mejor modelo propuesto es el modelo 2, es decir, vale la pena agregarle como variable explicativa el género femenino, va a generar un modelo más confiable. ## QQ plot plot(ranef(m2)) ## $cid ## Caterpillar plot lattice::dotplot(ranef(m2, condVar = TRUE)) ## $cid Los modelos anteriores se pueden ajustar usando la función glmmadmb del paquete glmmADMB, a continuación se muestra el código. Para conocer más sobre este paquete se recomienda visitar este enlace library(glmmADMB) m1_alt &lt;- glmmadmb(awards ~ 1 + (1 | cid), data = datos, family = &quot;poisson&quot;, link = &quot;log&quot;) m2_alt &lt;- glmmadmb(awards ~ 1 + female + (1 | cid), data = datos, family = &quot;poisson&quot;, link = &quot;log&quot;) References "],["glmm_gamma.html", "18 GLMM gamma", " 18 GLMM gamma En este capítulo se presenta un ejemplo de glmm con variable respuesta gamma. A continuación la base de datos a utilizar. library(hglm) data(semiconductor) En este ejemplo, analizamos los datos de semiconductores tomados de Myers et al. (2002), que implica un experimento diseñado en una planta de semiconductores. Se emplean seis factores, temperatura de laminación, tiempo de laminación, presión de laminación, temperatura de cocción, tiempo de ciclo de cocción y punto de rocío de cocción, y estamos interesados en la curvatura de los dispositivos de sustrato producidos en la planta. La medición de la curvatura se realiza cuatro veces en cada dispositivo fabricado. Cada variable de diseño se toma en dos niveles. Se sabe que la medida no tiene una distribución normal y las medidas tomadas en el mismo dispositivo están correlacionadas. Myers et al. (2002) consideraron un modelo de respuesta gamma con un enlace logarítmico y utilizaron un método GEE asumiendo una correlación de trabajo AR(1). Las variables de la base de datos se muestran a continuación. Device: Subtrate device x1: Lamination Temperature; two levels +1 and -1. x2: Lamination Time; two levels: +1 and -1. x3: Lamination Presure; two levels: +1 and -1. x4: Firing Temperature; two levels: +1 and -1. x5: Firing Cycle Time; two levels: +1 and -1. x6: Firing Dew Point: two levels: +1 and -1. y: Camber measure; in 1e-4 in./in. Vamos a explorar las primeras líneas de la base de datos. head(semiconductor, n=5) ## Device x1 x2 x3 x4 x5 x6 y ## 1 1 -1 -1 -1 -1 -1 -1 0.0167 ## 2 1 -1 -1 -1 -1 -1 -1 0.0128 ## 3 1 -1 -1 -1 -1 -1 -1 0.0149 ## 4 1 -1 -1 -1 -1 -1 -1 0.0185 ## 5 2 1 -1 -1 -1 1 1 0.0062 El siguiente código sirve para construir una densidad para la variable respuesta. library(ggplot2) ggplot(semiconductor, aes(y)) + geom_density() De la figura anterior vemos que la variable respuesta tomá solo valores positivos. # install.packages(&quot;GGally&quot;) library(GGally) ## Registered S3 method overwritten by &#39;GGally&#39;: ## method from ## +.gg ggplot2 ggpairs(semiconductor, # Data frame columns = 2:8) # Columns El primer modelo que vamos a ajustar contiene todos los factores x y se puede representar de la siguiente manera. \\[\\begin{align*} y_{ij} | b_0 &amp;\\sim Gamma(\\mu_{ij}, \\phi) \\\\ \\log(\\mu_{ij}) &amp;= \\beta_0 + \\beta_1 x1_{ij} + \\beta_2 x2_{ij} + \\beta_3 x3_{ij} + \\beta_4 x4_{ij} + \\beta_5 x5_{ij} + \\beta_6 x6_{ij} + b_{0i} \\\\ b_{0} &amp;\\sim N(0, \\sigma^2_{b0}) \\end{align*}\\] Para ajustar el modelo anterior usamos el siguiente código. library(lme4) mod1 &lt;- glmer(y ~ x1 + x2 + x3 + x4 + x5 + x6 + (1 | Device), data = semiconductor, family = Gamma(link = log)) summary(mod1) ## Generalized linear mixed model fit by maximum likelihood (Laplace ## Approximation) [glmerMod] ## Family: Gamma ( log ) ## Formula: y ~ x1 + x2 + x3 + x4 + x5 + x6 + (1 | Device) ## Data: semiconductor ## ## AIC BIC logLik deviance df.resid ## -547.0 -527.6 282.5 -565.0 55 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -1.8492 -0.5712 -0.1592 0.7227 2.5022 ## ## Random effects: ## Groups Name Variance Std.Dev. ## Device (Intercept) 0.02734 0.1653 ## Residual 0.09655 0.3107 ## Number of obs: 64, groups: Device, 16 ## ## Fixed effects: ## Estimate Std. Error t value Pr(&gt;|z|) ## (Intercept) -4.7117204 0.0752768 -62.592 &lt; 2e-16 *** ## x1 0.1842486 0.0752816 2.447 0.01439 * ## x2 0.0008432 0.0752894 0.011 0.99106 ## x3 0.3074319 0.0752837 4.084 4.43e-05 *** ## x4 -0.0125486 0.0752601 -0.167 0.86758 ## x5 -0.1943372 0.0752885 -2.581 0.00984 ** ## x6 -0.3660413 0.0752584 -4.864 1.15e-06 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Correlation of Fixed Effects: ## (Intr) x1 x2 x3 x4 x5 ## x1 0.000 ## x2 0.001 0.021 ## x3 0.000 0.008 0.023 ## x4 -0.001 0.005 0.014 -0.007 ## x5 0.000 0.023 0.008 0.021 0.008 ## x6 0.000 -0.007 0.008 0.005 0.008 0.014 Del resumen anterior se observa que los factores x2 y x4 no son significativos, por esa razón vamos a ajustar otro modelo sin esos factores, el modelo se puede representar así. \\[\\begin{align*} y_{ij} | b_0 &amp;\\sim Gamma(\\mu_{ij}, \\phi) \\\\ \\log(\\mu_{ij}) &amp;= \\beta_0 + \\beta_1 x1_{ij} + \\beta_3 x3_{ij} + \\beta_5 x5_{ij} + \\beta_6 x6_{ij} + b_{0i} \\\\ b_{0} &amp;\\sim N(0, \\sigma^2_{b0}) \\end{align*}\\] Para ajustar el modelo anterior usamos el siguiente código. mod2 &lt;- glmer(y ~ x1 + x3 + x5 + x6 + (1 | Device), data = semiconductor, family = Gamma(link = log)) summary(mod2) ## Generalized linear mixed model fit by maximum likelihood (Laplace ## Approximation) [glmerMod] ## Family: Gamma ( log ) ## Formula: y ~ x1 + x3 + x5 + x6 + (1 | Device) ## Data: semiconductor ## ## AIC BIC logLik deviance df.resid ## -551.0 -535.9 282.5 -565.0 57 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -1.8424 -0.5565 -0.1762 0.7429 2.4663 ## ## Random effects: ## Groups Name Variance Std.Dev. ## Device (Intercept) 0.02744 0.1657 ## Residual 0.09652 0.3107 ## Number of obs: 64, groups: Device, 16 ## ## Fixed effects: ## Estimate Std. Error t value Pr(&gt;|z|) ## (Intercept) -4.71177 0.07542 -62.475 &lt; 2e-16 *** ## x1 0.18429 0.07541 2.444 0.0145 * ## x3 0.30732 0.07540 4.076 4.59e-05 *** ## x5 -0.19423 0.07543 -2.575 0.0100 * ## x6 -0.36594 0.07540 -4.853 1.21e-06 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Correlation of Fixed Effects: ## (Intr) x1 x3 x5 ## x1 0.000 ## x3 0.000 0.008 ## x5 0.000 0.023 0.021 ## x6 0.000 -0.007 0.005 0.014 Para comparar los dos modelos ajustados propuestos colocamos los resultados en una única tabla como se muestra a continuación. library(&quot;texreg&quot;) screenreg(list(mod1, mod2)) ## ## ================================================= ## Model 1 Model 2 ## ------------------------------------------------- ## (Intercept) -4.71 *** -4.71 *** ## (0.08) (0.08) ## x1 0.18 * 0.18 * ## (0.08) (0.08) ## x2 0.00 ## (0.08) ## x3 0.31 *** 0.31 *** ## (0.08) (0.08) ## x4 -0.01 ## (0.08) ## x5 -0.19 ** -0.19 * ## (0.08) (0.08) ## x6 -0.37 *** -0.37 *** ## (0.08) (0.08) ## ------------------------------------------------- ## AIC -546.99 -550.96 ## BIC -527.56 -535.85 ## Log Likelihood 282.50 282.48 ## Num. obs. 64 64 ## Num. groups: Device 16 16 ## Var: Device (Intercept) 0.03 0.03 ## Var: Residual 0.10 0.10 ## ================================================= ## *** p &lt; 0.001; ** p &lt; 0.01; * p &lt; 0.05 El problema de comparar los dos modelos se puede resumir con \\(H_0:\\) las variables x2 y x4 no aportan al modelo, versus, \\(H_A:\\) al menos una de esas variables si aporta al modelo. Para abordar el problema lo podemos hacer por medio de la prueba razón de verosimilitud. Debemos tener en cuenta que el modelo 1 tiene 9 parámetros y el modelo 2 tiene 7 parámetros. lrt &lt;- -2 * (logLik(mod2) - logLik(mod1)) lrt ## &#39;log Lik.&#39; 0.02762921 (df=7) pchisq(q=lrt, df=9-7, lower.tail=FALSE) ## &#39;log Lik.&#39; 0.9862804 (df=7) De la salida anterior se tiene que el valor-P = 0.9862804 y mayor que cualquier \\(\\alpha\\), eso significa que no hay evidencia para rechazar \\(H_0\\), en otras palabras, las variables x2 y x4 no aportan al modelo. La prueba de verosimilitud se puede obtener también así: anova(mod1, mod2) ## Data: semiconductor ## Models: ## mod2: y ~ x1 + x3 + x5 + x6 + (1 | Device) ## mod1: y ~ x1 + x2 + x3 + x4 + x5 + x6 + (1 | Device) ## npar AIC BIC logLik deviance Chisq Df Pr(&gt;Chisq) ## mod2 7 -550.96 -535.85 282.48 -564.96 ## mod1 9 -546.99 -527.56 282.50 -564.99 0.0276 2 0.9863 Es posible obtener el valor-P anterior usando boostrap por medio de la función PBmodcomp del paquete pbkrtest de Halekoh and Højsgaard (2021). library(pbkrtest) PBmodcomp(largeModel=mod1, smallModel=mod2, nsim=100, seed=123) Bootstrap test; time: 100.44 sec; samples: 100; extremes: 100; large : y ~ x1 + x2 + x3 + x4 + x5 + x6 + (1 | Device) y ~ x1 + x3 + x5 + x6 + (1 | Device) stat df p.value LRT 0.0276 2 0.9863 PBtest 0.0276 1.0000 --- Signif. codes: 0 *** 0.001 ** 0.01 * 0.05 . 0.1   1 En el código anterior se usó la semilla seed = 123 para simular los nuevos conjuntos de datos. De la salida anterior se observa que el valor-P es mayor que un 5% con lo que se concluye que no hay evidencias para rechazar \\(H_0\\). References "],["simul-glmm.html", "19 Simulación de glmm", " 19 Simulación de glmm Simular observaciones de un glmm es muy importante para comprender este tipo de modelos y para estudiar las propiedades de estos modelos. A continuación se muestran los enlaces a varias publicaciones. glmm binomial. glmm Poisson. "],["blobs.html", "20 Otro material interesante", " 20 Otro material interesante En este capítulo se listan algunos blogs y publicaciones interesantes relacionados con modelos mixtos. A Practical Guide to Mixed Models in R. Introduction to linear mixed models. How to choose nlme or lme4 R library for mixed effects models?. GLMM FAQ. Paquete glmmsr. https://stats.stackexchange.com/questions/486561/can-i-compare-lmer-models-with-different-fixed-effects-using-anova "],["references.html", "References", " References "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
