[["index.html", "Modelos Mixtos con R Bienvenido Estructura del libro Software y convenciones Bloques informativos", " Modelos Mixtos con R Freddy Hernández Barajas Jorge Leonardo López Martínez 2021-12-02 Bienvenido Este libro está destinado para usuarios de R interesados en aplicar modelos mixtos. Freddy Hernández Barajas Jorge Leonardo López Martínez Estructura del libro En el capítulo 1 se hace un repaso básico del modelo de regresión lineal clásico. En el capítulo 2 se presentan los modelos mixtos y en el capítulo 4 se presentan los modelos lineales generalizados mixtos. En el capítulo 5 se presenta el paquete lme4 y sus principales funciones para modelación, mientras que en el capítulo 6 se presenta el paquete nlme y sus principales funciones para modelación. Software y convenciones Para realizar este libro usamos los paquetes knitr (Xie 2015) y bookdown (Xie 2021) que permiten unir la ventajas de LaTeX y R en un mismo archivo. En todo el libro se presentarán códigos que el lector puede copiar y pegar en su consola de R para obtener los mismos resultados aquí del libro. Los códigos se destacan en una caja de color similar a la mostrada a continuación. 4 + 6 a &lt;- c(1, 5, 6) 5 * a 1:10 Los resultados o salidas obtenidos de cualquier código se destacan con dos símbolos de númeral (##) al inicio de cada línea o renglón, esto quiere decir que todo lo que inicie con ## son resultados obtenidos y NO los debe copiar. Abajo se muestran los resultados obtenidos luego de correr el código anterior. ## [1] 10 ## [1] 5 25 30 ## [1] 1 2 3 4 5 6 7 8 9 10 Bloques informativos En varias partes del libro usaremos bloques informativos para resaltar algún aspecto importante. Abajo se encuentra un ejemplo de los bloques y su significado. Nota aclaratoria. Sugerencia. Advertencia. Solución a ejemplos. References "],["reg-lin.html", "1 Regresión lineal 1.1 Modelo estadístico 1.2 Verosimilitud del modelo", " 1 Regresión lineal En este capítulo se presenta el modelo de regresión lineal clásico. 1.1 Modelo estadístico El modelo estadístico en regresión lineal clásico permite modelar la media de una variable \\(Y\\) en función de \\(k\\) covariables. El modelo se puede expresar como sigue. \\[\\begin{align} \\label{mod2} y_i &amp;\\sim N(\\mu_i, \\sigma^2), \\\\ \\mu_i &amp;= \\beta_0 + \\beta_1 x_{1i} + \\beta_2 x_{2i} + \\cdots + \\beta_k x_{ki}, \\\\ \\sigma^2 &amp;= \\text{constante} \\end{align}\\] donde \\(i=1, 2, \\ldots, n\\) es el índice que identifica las \\(n\\) observaciones del conjunto de entrenamiento. El vector de parámetros del modelo es \\(\\boldsymbol{\\theta}=(\\beta_0, \\beta_1, \\cdots, \\beta_k, \\sigma)^\\top\\). 1.2 Verosimilitud del modelo La función de verosimilitud \\(L\\) para el modelo es la siguiente: \\[ L(\\boldsymbol{\\theta}) = \\prod_i^n f(y_i \\vert \\beta_0, \\beta_1, \\cdots, \\beta_k, \\sigma), \\] donde \\(f\\) corresponde a la función de densidad de la normal. Para estimar el vector de parámetros \\(\\boldsymbol{\\theta}\\) del modelo se usa el método de Máxima Verosimilitud sobre la función \\(L\\) o sobre la función de log-verosimilitud siguiente: \\[ l(\\boldsymbol{\\theta}) = \\sum_i^n \\log(f(y_i \\vert \\beta_0, \\beta_1, \\cdots, \\beta_k, \\sigma)), \\] Ejemplo Como ilustración vamos a usar los datos del ejemplo 3.1 del libro de Montgomery, Peck and Vining (2003). En el ejemplo 3.1 los autores ajustaron un modelo de regresión lineal múltiple para explicar el Tiempo necesario para que un trabajador haga el mantenimiento y surta una máquina dispensadora de refrescos en función de las variables Número de Cajas y Distancia. Los datos del ejemplo están disponibles en el paquete MPV (por los apellidos de los autores). A continuación el código para cargar los datos y una muestra de las 6 primeras observaciones de la base de datos, en total se disponen de 20 observaciones. require(MPV) colnames(softdrink) &lt;- c(&#39;tiempo&#39;, &#39;cantidad&#39;, &#39;distancia&#39;) head(softdrink) ## tiempo cantidad distancia ## 1 16.68 7 560 ## 2 11.50 3 220 ## 3 12.03 3 340 ## 4 14.88 4 80 ## 5 13.75 6 150 ## 6 18.11 7 330 Un gráfico en 3d es obligratorio para explorar la relación entre las variables, este diagrama de puede obtener usando el paquete scatterplot3d. A continuación el código para construirlo. library(scatterplot3d) attach(softdrink) scatterplot3d(x=cantidad, y=distancia, z=tiempo, pch=16, cex.lab=1, highlight.3d=TRUE, type=&quot;h&quot;, xlab=&#39;Cantidad de cajas&#39;, ylab=&#39;Distancia (pies)&#39;, zlab=&#39;Tiempo (min)&#39;) De la figura anterior se ve claramente que a medida que aumenta el número de cajas y la distancia los tiempos tienden a ser mayores. A continuación se define la función de menos log-verosimilitud para el modelo anterior. A pesar de que nos interesa maximizar la función de log-verosimilitud hemos creado su negativo, esto porque la mayoría de las funciones de optimización minimizan y no maximizan; maximizar \\(f(x)\\) es equivalente a minimizar \\(-f(x)\\). minusll &lt;- function(theta, y, x1, x2) { media &lt;- theta[1] + theta[2] * x1 + theta[3] * x2 # Se define la media desvi &lt;- theta[4] # Se define la desviación. - sum(dnorm(x=y, mean=media, sd=desvi, log=TRUE)) } Ahora vamos a usar la función optim para encontrar los valores que maximizan la función de log-verosimilitud, el código para hacer eso se muestra a continuación. En el parámetro par se coloca un vector de posibles valores de \\(\\boldsymbol{\\Theta}\\) para iniciar la búsqueda, en fn se coloca la función de interés, en lower y upper se colocan vectores que indican los límites de búsqueda de cada parámetro, los \\(\\beta_k\\) pueden variar entre \\(-\\infty\\) y \\(\\infty\\) mientras que el parámetro \\(\\sigma\\) toma valores en el intervalo \\((0, \\infty)\\). Como la función minusll tiene argumentos adicionales y, x1 y x2, estos pasan a la función optim al final como se muestra en el código. mod1 &lt;- optim(par=c(0, 0, 0, 1), fn=minusll, method=&#39;L-BFGS-B&#39;, lower=c(-Inf, -Inf, -Inf, 0), upper=c(Inf, Inf, Inf, Inf), y=softdrink$tiempo, x1=softdrink$cantidad, x2=softdrink$distancia) En el objeto res1 está el resultado de la optimización, para explorar los resultados usamos mod1 ## $par ## [1] 2.34103296 1.61590757 0.01438512 3.05769678 ## ## $value ## [1] 63.41469 ## ## $counts ## function gradient ## 58 58 ## ## $convergence ## [1] 0 ## ## $message ## [1] &quot;CONVERGENCE: REL_REDUCTION_OF_F &lt;= FACTR*EPSMCH&quot; De esta forma el vector de parámetros estimados del modelo es \\(\\hat{\\boldsymbol{\\theta}}=(2.34, 1.62, 0.01, 3.06)^\\top\\). Usualmente en la práctica se usa la función lm para estimar el vector de parámetros, a continuación el código necesario para usar la funcion lm. mod2 &lt;- lm(tiempo ~ cantidad + distancia, data=softdrink) summary(mod2) ## ## Call: ## lm(formula = tiempo ~ cantidad + distancia, data = softdrink) ## ## Residuals: ## Min 1Q Median 3Q Max ## -5.7880 -0.6629 0.4364 1.1566 7.4197 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 2.341231 1.096730 2.135 0.044170 * ## cantidad 1.615907 0.170735 9.464 3.25e-09 *** ## distancia 0.014385 0.003613 3.981 0.000631 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 3.259 on 22 degrees of freedom ## Multiple R-squared: 0.9596, Adjusted R-squared: 0.9559 ## F-statistic: 261.2 on 2 and 22 DF, p-value: 4.687e-16 De la salida anterior vemos que el vector de parámetros estimados del modelo es \\(\\hat{\\boldsymbol{\\theta}}=(2.34, 1.62, 0.01, 3.26)^\\top\\). Para profundizar en el modelo de regresion lineal se recomienda consultar libro Modelos de Regresión con R "],["lmm.html", "2 Modelos Lineales Mixtos 2.1 Entrevista con Jim Ware y Nan Laird", " 2 Modelos Lineales Mixtos Los modelos lineales mixtos fueron propuestos por (Laird and Ware 1982) y en ellos se asume que existe una relación entre el vector de observaciones \\(\\boldsymbol{Y}_i\\) del sujeto o grupo \\(i\\) y las covariables por medio de la siguiente expresión \\[\\begin{equation} \\begin{aligned} \\boldsymbol{Y}_i \\mid \\boldsymbol{b}_i &amp;\\sim \\mathcal{N}(\\boldsymbol{X}_i \\boldsymbol{\\beta} + \\boldsymbol{Z}_i \\boldsymbol{b}_i, \\boldsymbol{\\Sigma}_i), \\\\ \\boldsymbol{b}_i &amp;\\sim \\mathcal{N}(\\boldsymbol{0}, \\boldsymbol{D}), \\end{aligned} \\tag{2.1} \\end{equation}\\] donde \\(\\boldsymbol{X}_i\\) y \\(\\boldsymbol{Z}_i\\) son matrices de diseño conocidas con la información de las covariables, siendo \\(\\boldsymbol{X}_i\\) de dimensión \\(n_i \\times p\\) y \\(\\boldsymbol{Z}_i\\) de dimensión \\(n_i \\times q\\). El elemento \\(\\boldsymbol{\\beta}\\) representa el vector de efectos fijos general, \\(\\boldsymbol{b}_i\\) el vector de efectos aleatorios exclusivo para el grupo \\(i\\). El vector \\(\\boldsymbol{b}_i\\) en la expresión (2.1) es llamado efecto aleatorio porque éste cambia la media de sujeto a sujeto y su función es la de mejorar el ajuste general dado por el elemento \\(\\boldsymbol{X}_i \\boldsymbol{\\beta}\\) al agregar la cantidad \\(\\boldsymbol{Z}_i \\boldsymbol{b}_i\\). El modelo dado en la expresión (2.1) es llamado también modelo mixto porque involucra tanto efectos fijos (\\(\\boldsymbol{\\beta}\\)) como efectos aleatorios (\\(\\boldsymbol{b}_i\\)). La distribución marginal de \\(\\boldsymbol{Y}_i\\) está dada por \\[\\begin{equation} f_i(\\boldsymbol{Y}_i) = \\int f(\\boldsymbol{Y}_i | \\boldsymbol{b}_i) f(\\boldsymbol{b}_i) \\, d \\boldsymbol{b}_i \\end{equation}\\] donde \\(f(\\boldsymbol{Y}_i | \\boldsymbol{b}_i)\\) y \\(f(\\boldsymbol{b}_i)\\) corresponden a las densidades normales mostradas en la expresión (2.1). Esta distribución marginal tiene forma cerrada y se puede mostrar fácilmente que la distribución de \\(\\boldsymbol{Y}_i\\) es una normal multivariada con vector de medias y matriz de covarianzas como se muestra a continuación. \\[\\begin{equation} \\boldsymbol{Y}_i \\sim \\mathcal{N}(\\boldsymbol{X}_i \\boldsymbol{\\beta}, \\boldsymbol{V}_i), \\end{equation}\\] donde \\(\\boldsymbol{V}_i=\\boldsymbol{Z}_i \\boldsymbol{D} \\boldsymbol{Z}_i^\\top + \\boldsymbol{\\Sigma}_i\\). El vector de parámetros en este caso es \\(\\boldsymbol{\\theta}=(\\boldsymbol{\\beta}, \\boldsymbol{\\alpha})^\\top\\) donde \\(\\boldsymbol{\\alpha}\\) consiste de los \\(q(q+1)/2\\) elementos diferentes de la matriz \\(\\boldsymbol{D}\\) y todos los elementos de la matriz \\(\\boldsymbol{\\Sigma}_i\\). 2.1 Entrevista con Jim Ware y Nan Laird References "],["shiny.html", "3 Aplicaciones shiny", " 3 Aplicaciones shiny En este capítulo se presentan aplicaciones shiny para ilustrar modelos con efectos aleatorios. Aplicación lmm con intercepto aleatorio. Aplicación lmm con intercepto y pendiente aleatorias. "],["glmm.html", "4 Modelos Lineales Generalizados Mixtos", " 4 Modelos Lineales Generalizados Mixtos Los modelos lineales generalizados mixtos fueron propuestos por (Breslow and Clayton 1993) y en ellos se asume que existe una relación entre el vector de observaciones \\(\\boldsymbol{Y}_i\\) del sujeto o grupo \\(i\\) y las covariables por medio de la siguiente expresión \\[\\begin{equation} \\begin{aligned} \\boldsymbol{Y}_i \\mid \\boldsymbol{b}_i &amp;\\sim \\mathcal{F}(\\boldsymbol{X}_i \\boldsymbol{\\beta} + \\boldsymbol{Z}_i \\boldsymbol{b}_i, \\phi), \\\\ \\boldsymbol{b}_i &amp;\\sim \\mathcal{N}(\\boldsymbol{0}, \\boldsymbol{D}), \\end{aligned} \\tag{4.1} \\end{equation}\\] donde \\(\\mathcal{F}\\) corresponde a una distribución de la familia exponencial que incluye las distribuciones normal, Poisson, binomial negativa, gamma e inversa gaussiana. Las matrices \\(\\boldsymbol{X}_i\\) y \\(\\boldsymbol{Z}_i\\) son matrices de diseño conocidas con la información de las covariables, siendo \\(\\boldsymbol{X}_i\\) de dimensión \\(n_i \\times p\\) y \\(\\boldsymbol{Z}_i\\) de dimensión \\(n_i \\times q\\). El elemento \\(\\boldsymbol{\\beta}\\) representa el vector de efectos fijos general, \\(\\boldsymbol{b}_i\\) el vector de efectos aleatorios exclusivo para el grupo \\(i\\). El vector \\(\\boldsymbol{b}_i\\) en la expresión (4.1) es llamado efecto aleatorio porque éste cambia la media de sujeto a sujeto y su función es la de mejorar el ajuste general dado por el elemento \\(\\boldsymbol{X}_i \\boldsymbol{\\beta}\\) al agregar la cantidad \\(\\boldsymbol{Z}_i \\boldsymbol{b}_i\\). El modelo dado en la expresión (4.1) es llamado también modelo mixto porque involucra tanto efectos fijos (\\(\\boldsymbol{\\beta}\\)) como efectos aleatorios (\\(\\boldsymbol{b}_i\\)). La distribución marginal de \\(\\boldsymbol{Y}_i\\) está dada por \\[\\begin{equation} f_i(\\boldsymbol{Y}_i) = \\int f(\\boldsymbol{Y}_i | \\boldsymbol{b}_i) f(\\boldsymbol{b}_i) \\, d \\boldsymbol{b}_i \\end{equation}\\] donde \\(f(\\boldsymbol{Y}_i | \\boldsymbol{b}_i)\\) corresponde a la densidad normal, Poisson, binomial negativa, gamma o inversa gaussina y \\(f(\\boldsymbol{b}_i)\\) corresponde a la distribución normal bivariada mostrada en (4.1). La función de verosimilitud para el vector de parámetros \\(\\boldsymbol{\\Theta}=(\\boldsymbol{\\beta}, \\phi, \\boldsymbol{D})^\\top\\) se puede escribir como \\[ L(\\boldsymbol{\\Theta}) = \\prod_{i=1}^{n} \\int f(\\boldsymbol{Y}_i | \\boldsymbol{b}_i) f(\\boldsymbol{b}_i) \\, d \\boldsymbol{b}_i . \\] References "],["pac-lme4.html", "5 Paquete lme4 5.1 Función lmer Ejemplo: modelo normal con intercepto aleatorio Ejemplo: recuperando los interceptos aleatorios 5.2 Función glmer Ejemplo: modelo gamma con intercepto aleatorio", " 5 Paquete lme4 El paquete lme4 de Bates et al. (2021) es uno de los paquetes más completos para modelos mixtos. Al visitar este enlace se encontrará la página de apoyo del paquete, allí se puede consultar el manual de referencia y las viñetas. 5.1 Función lmer La función lmer es la principal función del paquete lme4. Esta función sirve para ajustar un modelo mixto y su estructura es la siguiente: lmer(formula, data = NULL, REML = TRUE, control = lmerControl(), start = NULL, verbose = 0L, subset, weights, na.action, offset, contrasts = NULL, devFunOnly = FALSE, ...) Los principales argumentos de la función son: formula: es una fórmula similar a la usada en el modelo lineal clásico. Un ejemplo de fórmula sería y ~ 1 + x1 + x2 + (1 + x2 | grupo) con la cual se indican los efectos fijos y los efectos aleatorios del modelo. Más abajo hay una tabla con más detalles sobre la fórmula. data: marco de datos donde están las variables. REML: valor lógico que sirve para indicar si queremos estimaciones maximizando la verosimilitud restringida o la verosimilitud usual. La siguiente imagen corresponde a la tabla 2 de la viñeta Fitting Linear Mixed-Effects Models using lme4. En la tabla las dos primeras columnas muestran formas equivalentes de incluir las estructuras de modelos mixtos más comunes. Ejemplo: modelo normal con intercepto aleatorio En este ejemplo vamos a simular observaciones \\(n_i=50\\) observaciones para \\(G=10\\) grupos (en total 500 obs) que tengan la estructura mostrada abajo. El objetivo del ejemplo es ilustrar el uso de la función lmer para estimar los parámetros del modelo. \\[\\begin{align*} y_{ij} &amp;\\sim N(\\mu_{ij}, \\sigma^2_y) \\\\ \\mu_{ij} &amp;= 4 - 6 x_{ij} + b_{0i} \\\\ \\sigma^2_y &amp;= 16 \\\\ b_{0} &amp;\\sim N(0, \\sigma^2_{b0}=625) \\\\ x_{ij} &amp;\\sim U(-5, 6) \\end{align*}\\] El vector de parámetros de este modelo es \\(\\boldsymbol{\\Theta}=(\\beta_0=4, \\beta_1=-6, \\sigma_y=4, \\sigma_{b0}=25)^\\top\\). Solución. El código para simular las 500 observaciones se muestra a continuación. Observe que se fijó la semilla en dos ocasiones para que el lector pueda replicar el ejemplo y obtener los mismos resultados. ni &lt;- 50 G &lt;- 10 nobs &lt;- ni * G grupo &lt;- factor(rep(x=1:G, each=ni)) obs &lt;- rep(x=1:ni, times=G) set.seed(1234567) x &lt;- runif(n=nobs, min=-5, max=6) set.seed(1234567) b0 &lt;- rnorm(n=G, mean=0, sd=sqrt(625)) # Intercepto aleatorio b0 &lt;- rep(x=b0, each=ni) # El mismo intercepto aleatorio pero repetido media &lt;- 4 - 6 * x + b0 set.seed(1234567) y &lt;- rnorm(n=nobs, mean=media, sd=sqrt(16)) datos &lt;- data.frame(obs, grupo, b0, x, media, y) Vamos a explorar los datos simulados. library(rmarkdown) paged_table(datos, options = list(rows.print = 6)) El siguiente paso es dibujar los datos para explorar si sería apropiado usar un modelo con intercepto aleatorio (obvio porque así se simularon los datos). El código para dibujar los datos se muestra abajo. library(ggplot2) ggplot(datos, aes(x, y, color=grupo) ) + geom_point() + labs(colour=&quot;Grupo/Cluster&quot;) En la figura anterior se observa un patrón claro, todas las 10 nubes de puntos tienen la misma pendiente pero diferente intercepto con el eje vertical, eso se debe a que en la simulación se incluyó un \\(b_0\\). Para estimar los parámetros del modelos se usa la función mler de la siguiente forma. library(lme4) fit1 &lt;- lmer(y ~ x + (1 | grupo), data = datos) La función summary se puede usar sobre el objeto fit1 para obtener una tabla de resumen, a continuación se ilustra el uso y la salida de summary. summary(fit1) Según el resultado anterior \\(\\hat{\\boldsymbol{\\Theta}}=(\\hat{\\beta}_0=2.2378, \\hat{\\beta}_1=-6.0264, \\hat{\\sigma}_y=3.9352, \\hat{\\sigma}_{b0}=25.369)^\\top\\) mientras que el vector real de parámetros es \\(\\boldsymbol{\\Theta}=(\\beta_0=4, \\beta_1=-6, \\sigma_y=4, \\sigma_{b0}=25)^\\top\\). Compare los resultados de la tabla anterior obtenida con la función lmer anterior con los resultados obtenidos con la función lme de capítulo 6. ¿Hay alguna similitud? Ejemplo: recuperando los interceptos aleatorios ¿Cómo se pueden obtener los interceptos aleatorios a partir del modelo ajustado en la sección anterior? Solución. Para obtener los interceptos aleatorios se usa la función ranef del paquete lme4 de Bates et al. (2021). A continuación vamos a obtener los interceptos aleatorios y los vamos a comparar con los \\(b_0\\) simulados. interceptos_aleatorios &lt;- ranef(fit1) cbind(interceptos_aleatorios$grupo, b0=unique(b0)) ## (Intercept) b0 ## 1 5.388795 3.917594 ## 2 35.790443 34.345280 ## 3 19.885504 18.266756 ## 4 -31.893039 -33.770023 ## 5 1.074942 -0.212874 ## 6 10.680482 8.024547 ## 7 -43.320003 -44.453710 ## 8 25.363102 22.737596 ## 9 -20.648195 -22.985108 ## 10 -2.322031 -3.942871 De la salida anterior vemos que los \\(\\tilde{b}_0\\) son cercanos a los valores reales de \\(b_0\\). La comparación anterior solo es posible cuando usamos datos simulados. Cuando se usan datos de un fenómeno real no se tienen los valores de \\(b_0\\). 5.2 Función glmer La función glmer es la función del paquete lme4 para ajustar modelo lineales generalizados mixtos y su estructura es la siguiente: lmer(formula, data = NULL, family = gaussian, control = glmerControl(), start = NULL, verbose = 0L, nAGQ = 1L, subset, weights, na.action, offset, contrasts = NULL, mustart, etastart, devFunOnly = FALSE) Los principales argumentos de la función son: formula: es una fórmula similar a la usada en el modelo lineal clásico. Un ejemplo de fórmula sería y ~ 1 + x1 + x2 + (1 + x2) con la cual se indican los efectos fijos y los efectos aleatorios del modelo. Más abajo hay una tabla con más detalles sobre la fórmula. data: marco de datos donde están las variables. family: argumento para seleccionar la distribución de la variable respuesta. Para más detalles de las distribuciones y funciones de enlace se recomienda ver la ayuda de la función family escribiendo esto en la consola ?family. Ejemplo: modelo gamma con intercepto aleatorio En este ejemplo vamos a simular observaciones \\(n_i=20\\) observaciones para \\(G=10\\) grupos (en total 200 obs) que tengan la estructura mostrada abajo. El objetivo del ejemplo es ilustrar el uso de la función glmer para estimar los parámetros del modelo. \\[\\begin{align*} y_{ij} &amp;\\sim Gamma(\\mu_{ij}, \\phi) \\\\ \\log(\\mu_{ij}) &amp;= 2 - 8 x_{ij} + b_{0i} \\\\ \\phi &amp;= 0.5 \\\\ b_{0} &amp;\\sim N(0, \\sigma^2_{b0}=9) \\\\ x_{ij} &amp;\\sim U(0, 1) \\end{align*}\\] El vector de parámetros de este modelo es \\(\\boldsymbol{\\Theta}=(\\beta_0=2, \\beta_1=-8, \\phi=0.5, \\sigma_{b0}=3)^\\top\\). Solución. La función rgamma_glm que se muestra a continuación es una modificación de la función rgamma para tener la parametrización usada en los glm. rgamma_glm &lt;- function(n, mu, phi) { x &lt;- rgamma(n=n, shape=1/phi, scale=mu*phi) return(x) } A continuación el código para simular datos del modelo de interés. ni &lt;- 20 G &lt;- 10 nobs &lt;- ni * G grupo &lt;- factor(rep(x=1:G, each=ni)) obs &lt;- rep(x=1:ni, times=G) set.seed(123456) x &lt;- runif(n=nobs, min=0, max=1) set.seed(123456) b0 &lt;- rnorm(n=G, mean=0, sd=sqrt(9)) # Intercepto aleatorio b0 &lt;- rep(x=b0, each=ni) # El mismo intercepto aleatorio pero repetido media &lt;- exp(2 - 8 * x + b0) set.seed(123456) y &lt;- rgamma_glm(n=nobs, mu=media, phi=0.5) datos &lt;- data.frame(obs, grupo, b0, x, media, y) Vamos a explorar los datos simulados. library(rmarkdown) paged_table(datos, options = list(rows.print = 6, cols.print=6)) El siguiente paso es explorar los datos simulados. El código para dibujar los datos se muestra abajo. library(ggplot2) ggplot(datos, aes(x, y, color=grupo) ) + geom_point() + labs(colour=&quot;Grupo/Cluster&quot;) Para estimar los parámetros del modelos se usa la función glmer de la siguiente forma. library(lme4) fit2 &lt;- glmer(y ~ x + (1 | grupo), family=Gamma(link=&quot;log&quot;), data = datos) La función summary se puede usar sobre el objeto fit2 para obtener una tabla de resumen, a continuación se la salida de summary. summary(fit2) ## Generalized linear mixed model fit by maximum likelihood (Laplace ## Approximation) [glmerMod] ## Family: Gamma ( log ) ## Formula: y ~ x + (1 | grupo) ## Data: datos ## ## AIC BIC logLik deviance df.resid ## 591.6 604.8 -291.8 583.6 196 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -1.4164 -0.7151 -0.2155 0.5631 3.0609 ## ## Random effects: ## Groups Name Variance Std.Dev. ## grupo (Intercept) 4.3265 2.0800 ## Residual 0.4728 0.6876 ## Number of obs: 200, groups: grupo, 10 ## ## Fixed effects: ## Estimate Std. Error t value Pr(&gt;|z|) ## (Intercept) 4.3965 0.9566 4.596 4.31e-06 *** ## x -8.0784 0.0411 -196.549 &lt; 2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Correlation of Fixed Effects: ## (Intr) ## x -0.021 Según el resultado anterior \\(\\hat{\\boldsymbol{\\Theta}}=(\\hat{\\beta}_0=4.3965, \\hat{\\beta}_1=-8.0784, \\hat{\\phi}=0.4728, \\hat{\\sigma}_{bo}=4.3265)^\\top\\) mientras que el vector real de parámetros es \\(\\boldsymbol{\\Theta}=(\\beta_0=2, \\beta_1=-8, \\phi=0.50, \\sigma_{b0}=3)^\\top\\). References "],["pac-nlme.html", "6 Paquete nlme 6.1 Función lme Ejemplo: modelo normal con intercepto aleatorio", " 6 Paquete nlme El paquete nlme de José Pinheiro, Bates, and R-core (2021) es otro de los paquetes para modelos mixtos. Al visitar este enlace se encontrará la página de apoyo del paquete, allí se puede consultar el manual de referencia. 6.1 Función lme La función lme es la principal función del paquete nlme. Esta función sirve para ajustar un modelo mixto y su estructura es la siguiente: lme(fixed, data, random, correlation, weights, subset, method, na.action, control, contrasts = NULL, keep.data = TRUE) Los principales argumentos de la función son: formula: es una fórmula similar a la usada en el modelo lineal clásico. Un ejemplo de fórmula sería y ~ 1 + x1 + x2 con la cual se indican los efectos fijos del modelo. data: marco de datos donde están las variables. random: es una fórmula solo con lado derecho. Si queremos indicar intercepto aleatorio se escribe ~ 1 | group y si se desea intercepto y pendiente aleatoria se escribe ~ 1 + x2 | group. correlation: es un parámetro opcional para indicar la estructura de correlación entre las observaciones de cada grupo. Para más detalles consulte la ayuda de la función corClasses. method: valor lógico que sirve para indicar si queremos estimaciones maximizando la verosimilitud restringida o la verosimilitud usual, las dos opciones son ML o REML. Ejemplo: modelo normal con intercepto aleatorio En este ejemplo vamos a simular observaciones \\(n_i=50\\) observaciones para \\(G=10\\) grupos (en total 500 obs) que tengan la estructura mostrada abajo. El objetivo del ejemplo es ilustrar el uso de la función lmer para estimar los parámetros del modelo. \\[\\begin{align*} y_{ij} &amp;\\sim N(\\mu_{ij}, \\sigma^2_y) \\\\ \\mu_{ij} &amp;= 4 - 6 x_{ij} + b_{0i} \\\\ \\sigma^2_y &amp;= 16 \\\\ b_{0} &amp;\\sim N(0, \\sigma^2_{b0}=625) \\\\ x_{ij} &amp;\\sim U(-5, 6) \\end{align*}\\] El vector de parámetros de este modelo es \\(\\boldsymbol{\\Theta}=(\\beta_0=4, \\beta_1=-6, \\sigma_y=4, \\sigma_{b0}=25)^\\top\\). Solución. El código para simular las 500 observaciones se muestra a continuación. Observe que se fijó la semilla en dos ocasiones para que el lector pueda replicar el ejemplo y obtener los mismos resultados. ni &lt;- 50 G &lt;- 10 nobs &lt;- ni * G grupo &lt;- factor(rep(x=1:G, each=ni)) obs &lt;- rep(x=1:ni, times=G) set.seed(1234567) x &lt;- runif(n=nobs, min=-5, max=6) set.seed(1234567) b0 &lt;- rnorm(n=G, mean=0, sd=sqrt(625)) # Intercepto aleatorio b0 &lt;- rep(x=b0, each=ni) # El mismo intercepto aleatorio pero repetido media &lt;- 4 - 6 * x + b0 set.seed(1234567) y &lt;- rnorm(n=nobs, mean=media, sd=sqrt(16)) datos &lt;- data.frame(obs, grupo, b0, x, media, y) Vamos a explorar los datos simulados. library(rmarkdown) paged_table(datos, options = list(rows.print = 6)) El siguiente paso es dibujar los datos para explorar si sería apropiado usar un modelo con intercepto aleatorio (obvio porque así se simularon los datos). El código para dibujar los datos se muestra abajo. library(ggplot2) ggplot(datos, aes(x, y, color=grupo) ) + geom_point() + labs(colour=&quot;Grupo/Cluster&quot;) En la figura anterior se observa un patrón claro, todas las 10 nubes de puntos tienen la misma pendiente pero diferente intercepto con el eje vertical, eso se debe a que en la simulación se incluyó un \\(b_0\\). Para estimar los parámetros del modelos se usa la función mler de la siguiente forma. library(nlme) fit1 &lt;- lme(y ~ x, random = ~ 1 | grupo, data=datos) La función summary se puede usar sobre el objeto fit para obtener una tabla de resumen, a continuación se ilustra el uso y la salida de summary. summary(fit1) Según el resultado anterior \\(\\hat{\\boldsymbol{\\Theta}}=(\\hat{\\beta}_0=2.2378, \\hat{\\beta}_1=-6.0264, \\hat{\\sigma}_y=3.9354, \\hat{\\sigma}_{b0}=25.3690)^\\top\\) mientras que el vector real de parámetros es \\(\\boldsymbol{\\Theta}=(\\beta_0=4, \\beta_1=-6, \\sigma_y=4, \\sigma_{b0}=25)^\\top\\). Compare los resultados de la tabla anterior obtenida con la función lme anterior con los resultados obtenidos con la función lmer de capítulo 5. ¿Hay alguna similitud? References "],["estim.html", "7 Métodos de estimación 7.1 ML y REML Ejemplo: comparando REML y ML usando lme4 Ejemplo: comparando REML y ML usando nlme Ejercicios", " 7 Métodos de estimación En este capítulo se muestran los métodos ML (maximum likelihood) y REML (restricted maximum likelihood) para estimar los parámetros de un modelo mixto. 7.1 ML y REML El método de máxima verosimilitud restringida (o residual o reducida) (REML) es una alternativa de estimación de máxima verosimilitud que no basa las estimaciones en un ajuste de máxima verosimilitud de toda la información, sino que utiliza una función de verosimilitud calculada a partir de una conjunto de datos transformado, de modo que los parámetros molestos no tengan ningún efecto. En el caso de la estimación del componente de varianza, el conjunto de datos original se reemplaza por un conjunto de contrastes calculados a partir de los datos, y la función de verosimilitud se calcula a partir de la distribución de probabilidad de estos contrastes, de acuerdo con el modelo para el conjunto de datos completo. En particular, REML se utiliza como método para ajustar modelos lineales mixtos. En contraste con la estimación de máxima verosimilitud anterior, REML puede producir estimaciones insesgadas de parámetros de varianza y covarianza. Ejemplo: comparando REML y ML usando lme4 En este ejemplo vamos a simular datos de un modelo lineal mixto con intercepto y pendiente aleatoria, luego vamos a comparar las estimaciones de los parámetros del modelo usando REML y ML. Solución. Los datos los vamos a simular del siguiente modelo. \\[\\begin{align*} y_{ij} &amp;\\sim N(\\mu_{ij}, \\sigma^2_y) \\\\ \\mu_{ij} &amp;= 4 - 5 x_{ij} + b_{0i} + b_{1i} x_{ij} \\\\ \\sigma^2_y &amp;= 4 \\\\ \\left ( \\begin{matrix} b_{0} \\\\ b_{1} \\end{matrix} \\right ) &amp;\\sim N\\left ( \\left ( \\begin{matrix} 0 \\\\ 0 \\end{matrix} \\right ), \\left ( \\begin{matrix} \\sigma^2_{b0}=40 &amp; \\sigma_{b01}=3 \\\\ \\sigma_{b01}=3 &amp; \\sigma^2_{b1}=50 \\end{matrix} \\right ) \\right ) \\\\ x_{ij} &amp;\\sim U(0, 5) \\end{align*}\\] Vamos a simular datos balanceados del anterior modelo considerando cinco grupos y diez observaciones por grupo. Para hacer esto vamos a usar la siguiente función. gen_data &lt;- function() { ni &lt;- 10 G &lt;- 5 nobs &lt;- ni * G # Numero total de observaciones grupo &lt;- factor(rep(x=1:G, each=ni)) # Para crear la variable grupal obs &lt;- rep(x=1:ni, each=G) # Para identificar las obs por grupo x &lt;- runif(n=nobs, min=0, max=5) # La covariable library(MASS) # Libreria para simular obs de Normal bivariada Sigma &lt;- matrix(c(40, 3, # Matriz de var-cov 3, 50), ncol=2, nrow=2) b &lt;- mvrnorm(n=G, mu=rep(0, 2), Sigma=Sigma) # Simulando b0 y b1 b &lt;- apply(b, MARGIN=2, function(c) rep(c, each=ni)) # Replicando b0 &lt;- as.vector(b[, 1]) # Separando los b0 b1 &lt;- as.vector(b[, 2]) # Separando los b1 media &lt;- 4 - 5 * x + b0 + b1 * x # La media y &lt;- rnorm(n=nobs, mean=media, sd=2) # La variable respuesta datos &lt;- data.frame(grupo, obs, x, y) # El dataframe } set.seed(123456) # Fijando la semilla para replicar el ejemplo datos &lt;- gen_data() # Creando los datos Ahora vamos a ajustar dos modelos, uno con estimación REML y otro con estimación ML. library(lme4) fit_reml &lt;- lmer(y ~ 1 + x + (1 + x| grupo), data = datos, REML = TRUE) fit_ml &lt;- lmer(y ~ 1 + x + (1 + x| grupo), data = datos, REML = FALSE) Para extraer sólo los efectos fijos de los dos modelos ajustados hacemos lo siguiente: fixef(fit_reml) ## (Intercept) x ## 11.449474 -6.236896 fixef(fit_ml) ## (Intercept) x ## 11.449454 -6.235161 Los efectos fijos verdaderos son \\(\\beta_0=4\\) y \\(\\beta_1=-5\\). Al comparar las estimaciones REML y ML vemos que son cercanas entre sí y próximas de los parámetros. Para extraer sólo las componentes de varianza de los dos modelos hacemos lo siguiente: (vc_reml &lt;- VarCorr(fit_reml)) ## Groups Name Std.Dev. Corr ## grupo (Intercept) 6.5259 ## x 4.0121 0.466 ## Residual 2.0379 (vc_ml &lt;- VarCorr(fit_ml)) ## Groups Name Std.Dev. Corr ## grupo (Intercept) 5.8025 ## x 3.5803 0.475 ## Residual 2.0377 Las componentes de varianza son \\(\\sigma_{b0}=6.32\\) (obtenida como \\(\\sqrt{40}\\)), \\(\\sigma_{b1}=7.07\\) (obtenida como \\(\\sqrt{50}\\)), \\(\\sigma_{b01}=3\\) y \\(\\sigma_y=2\\). Vamos a calcular el MSE (mean squared error) para las dos estimaciones REML y ML. a &lt;- vc_reml[[1]] b &lt;- vc_ml[[1]] mean((a[upper.tri(a, diag = TRUE)] - c(40, 3, 50))^2) ## [1] 413.6231 mean((b[upper.tri(b, diag = TRUE)] - c(40, 3, 50))^2) ## [1] 489.9286 De los anteriores resultados vemos que MSE es menor cuando se usa REML. Ejemplo: comparando REML y ML usando nlme Vamos a ajustar nuevamente los modelos pero usando el paquete nlme. library(nlme) fit_reml &lt;- lme(y ~ 1 + x, random = ~ 1 + x | grupo, data = datos, method = &quot;REML&quot;) fit_ml &lt;- lme(y ~ 1 + x, random = ~ 1 + x | grupo, data = datos, method = &quot;ML&quot;) Para extraer sólo los efectos fijos de los dos modelos ajustados hacemos lo siguiente: fixef(fit_reml) ## (Intercept) x ## 11.449474 -6.236896 fixef(fit_ml) ## (Intercept) x ## 11.449459 -6.235162 Los efectos fijos verdaderos son \\(\\beta_0=4\\) y \\(\\beta_1=-5\\). Al comparar las estimaciones REML y ML vemos que son cercanas entre sí, y próximas de los parámetros. Para extraer sólo las componentes de varianza de los dos modelos hacemos lo siguiente: (vc_reml &lt;- VarCorr(fit_reml)) ## grupo = pdLogChol(1 + x) ## Variance StdDev Corr ## (Intercept) 42.588627 6.525996 (Intr) ## x 16.097479 4.012166 0.466 ## Residual 4.153191 2.037938 (vc_ml &lt;- VarCorr(fit_ml)) ## grupo = pdLogChol(1 + x) ## Variance StdDev Corr ## (Intercept) 33.668543 5.802460 (Intr) ## x 12.819501 3.580433 0.475 ## Residual 4.152341 2.037729 Las componentes de varianza son \\(\\sigma_{b0}=6.32\\) (obtenida como \\(\\sqrt{40}\\)), \\(\\sigma_{b1}=7.07\\) (obtenida como \\(\\sqrt{50}\\)), \\(\\sigma_{b01}=3\\) y \\(\\sigma_y=2\\). Cuando se tienen muchos grupos y muchas repeticiones por grupo las estimaciones con REML y ML son muy cercanas. Ejercicios Repita el primer ejemplo de este capítulo para diez grupos y veinte observaciones por grupo. ¿Cuál es el valor de MSE? Repita el primer ejemplo de este capítulo para treinta grupos y cincuenta observaciones por grupo. ¿Cuál es el valor de MSE? Repita el primer ejemplo sin fijar la semilla y haga 100 réplicas con las siguientes combinaciones. Calcule el promedio de los MSE obtenidos. \\(G\\) \\(n_i\\) \\(\\overline{MSE}\\) 5 10 10 15 20 20 30 25 "],["apli-nlme.html", "8 Aplicación con nlme Ejercicios", " 8 Aplicación con nlme En este capítulo se mostrará como usar el paquete nlme para la aplicación de modelos mixtos con la base de datos Oxboys del mismo paquete. A continuación la base de datos a utilizar. library(nlme) head(Oxboys) ## Grouped Data: height ~ age | Subject ## Subject age height Occasion ## 1 1 -1.0000 140.5 1 ## 2 1 -0.7479 143.4 2 ## 3 1 -0.4630 144.8 3 ## 4 1 -0.1643 147.1 4 ## 5 1 -0.0027 147.7 5 ## 6 1 0.2466 150.2 6 Esta base de datos sobre crecimiento contiene la información sobre altura (heigth), edad estandarizada (age) de un grupo de 26 jóvenes. Como la base de datos Oxboys es de la clase groupedData, es posible aplicar un plot directamente y el resultado se muestra continuación. plot(Oxboys) Es posible convertir un data.frame para que tenga la clase groupedData, consulte la ayuda de la función groupedData del paquete nlme para más detalles. De la figura anterior vemos que las curvas de crecimiento inician a diferente altura (intercepto) y que la pendiente del crecimiento no son todas iguales, por ejemplo, el individuo 21 creció más rápido que el individuo 3. Esto nos hace pensar que un modelo con intercepto y pendiente aleatoria podrían ser adecuados para modelar el crecimiento. En las siguientes ecuaciones se resume el modelo matemático que interesa en esta situación. \\[\\begin{align*} Height_{ij} &amp;\\sim N(\\mu_{ij}, \\sigma^2_{Heigth}) \\\\ \\mu_{ij} &amp;= \\beta_0 + \\beta_1 Age_{ij} + b_{0i} + b_{1i} Age_{ij} \\\\ \\left ( \\begin{matrix} b_{0} \\\\ b_{1} \\end{matrix} \\right ) &amp;\\sim N\\left ( \\left ( \\begin{matrix} 0 \\\\ 0 \\end{matrix} \\right ), \\left ( \\begin{matrix} \\sigma^2_{b0} &amp; \\sigma_{b01} \\\\ \\sigma_{b01} &amp; \\sigma^2_{b1} \\end{matrix} \\right ) \\right ) \\end{align*}\\] El vector de parámetros para este modelo sería \\(\\boldsymbol{\\Theta}=(\\beta_0, \\beta_1, \\sigma_{height}, \\sigma_{b0}, \\sigma_{b1}, \\sigma_{b0b1})^\\top\\). Para ajustar este modelo a los datos con el paquete nlme podemos usar el siguiente código. fit &lt;- lme(height ~ age, random= ~ 1 + age | Subject, data=Oxboys, method=&quot;REML&quot;) Para obtener la tabla de resumen usamos: summary(fit) ## Linear mixed-effects model fit by REML ## Data: Oxboys ## AIC BIC logLik ## 736.091 756.7714 -362.0455 ## ## Random effects: ## Formula: ~1 + age | Subject ## Structure: General positive-definite, Log-Cholesky parametrization ## StdDev Corr ## (Intercept) 8.081077 (Intr) ## age 1.680717 0.641 ## Residual 0.659889 ## ## Fixed effects: height ~ age ## Value Std.Error DF t-value p-value ## (Intercept) 149.37175 1.5854173 207 94.21605 0 ## age 6.52547 0.3363003 207 19.40370 0 ## Correlation: ## (Intr) ## age 0.628 ## ## Standardized Within-Group Residuals: ## Min Q1 Med Q3 Max ## -2.65092109 -0.57493341 -0.02842894 0.59604254 2.60496077 ## ## Number of Observations: 234 ## Number of Groups: 26 De la salida anterior se obtiene que \\(\\hat{\\boldsymbol{\\Theta}}=(\\hat{\\beta}_0=149.37, \\hat{\\beta}_1=6.53, \\hat{\\sigma}_{height}=0.66, \\hat{\\sigma}_{b0}=8.08, \\hat{\\sigma}_{b1}=1.68, \\hat{\\sigma}_{b0b1}=8.71)^\\top\\). La estimación \\(\\hat{\\sigma}_{b0b1}\\) no aparece directamente en el summary pero se obtiene utilizando la ecuación \\(Cor=Cov/(\\sigma_1 \\sigma_2)\\) que relaciona correlación, covarianza y desviaciones de los efectos aleatorios. Usando la información anterior se puede escribir el modelo ajustado de la siguiente manera. \\[\\begin{align*} Height_{ij} &amp;\\sim N(\\hat{\\mu}_{ij}, 0.66^2) \\\\ \\hat{\\mu}_{ij} &amp;= 149.37 + 6.53 Age_{ij} + b_{0i} + b_{1i} Age_{ij} \\\\ \\left ( \\begin{matrix} b_{0} \\\\ b_{1} \\end{matrix} \\right ) &amp;\\sim N\\left ( \\left ( \\begin{matrix} 0 \\\\ 0 \\end{matrix} \\right ), \\left ( \\begin{matrix} 8.08^2 &amp; 8.71 \\\\ 8.71 &amp; 1.68^2 \\end{matrix} \\right ) \\right ). \\end{align*}\\] Los elementos \\(b_{0i}\\) y \\(b_{1i}\\) se deben substituir por sus respectivas predicciones \\(\\tilde{b}_{0i}\\) y \\(\\tilde{b}_{1i}\\) y se pueden obtener del modelo ajustado así: ranef(fit) ## (Intercept) age ## 10 -19.0972476 -2.78657472 ## 26 -11.3675996 -0.97474075 ## 25 -10.1595528 -2.42702035 ## 9 -11.2213331 -0.58069044 ## 2 -6.5096277 -1.07136271 ## 6 -2.5902388 -2.41771656 ## 7 -3.2473132 -1.46379286 ## 17 -6.3744842 1.89443713 ## 16 -1.8344703 -1.86707015 ## 15 -5.0856366 0.51526141 ## 8 -1.0776201 -0.06615528 ## 20 2.0850836 -1.99239802 ## 1 -1.2464285 0.59919226 ## 18 1.8031920 -0.51486646 ## 5 2.0531168 -0.24308081 ## 23 1.6937341 0.63140824 ## 11 0.6839704 1.85733185 ## 21 1.1525543 0.91894343 ## 3 6.2613001 -1.58181075 ## 24 3.7645669 0.25652772 ## 22 5.1957592 1.50551719 ## 12 7.4308033 0.52297645 ## 13 6.7004368 1.89758007 ## 14 10.0986013 2.09367207 ## 19 15.1957040 2.50720025 ## 4 15.6927297 2.78723179 Los valores de los efectos fijos estimados se pueden obtener así: fixef(fit) ## (Intercept) age ## 149.371753 6.525469 Usando la información de los efectos fijo y aleatorios obtenidos antes, es posible escribir la ecuación del modelo para cada individuo. Los efectos fijos estimados fueron \\(\\hat{\\beta}_0 \\approx 149.37\\) y \\(\\hat{\\beta}_1\\approx 6.53\\). Para el sujeto # 10 se obtuvo \\(\\tilde{b}_{0, i=10} \\approx -19.10\\) y \\(\\tilde{b}_{1, i=10} \\approx -2.79\\), así la media del individuo # 10 se calcula así: \\[\\begin{align*} \\hat{\\mu}_{i=10, j} &amp;= \\hat{\\beta}_0 + \\hat{\\beta}_0 \\, Age_{i=10, j} + \\tilde{b}_{0, i=10} + \\tilde{b}_{1, i=10} \\, Age_{i=10, j} \\\\ \\hat{\\mu}_{i=10, j} &amp;= 149.37 + 6.53 \\, Age_{i=10, j} - 19.10 - 2.79 \\, Age_{i=10, j} \\\\ \\hat{\\mu}_{i=10, j} &amp;= 130.27 + 3.74 \\, Age_{i=10, j} \\end{align*}\\] Lo anterior se puede resumir en el siguiente modelo. \\[\\begin{align*} Height_{i=10, j} &amp;\\sim N(\\hat{\\mu}_{i=10, j}, \\hat{\\sigma}^2_{Height}) \\\\ \\hat{\\mu}_{i=10, j} &amp;= 130.27 + 3.74 \\, Age_{i=10, j} \\\\ \\hat{\\sigma}_{Height} &amp;= 0.66 \\end{align*}\\] La expresión anterior para cada individuo con los efectos finales (fijos y aleatorios) se puede obtener con R así: coef(fit) ## (Intercept) age ## 10 130.2745 3.738894 ## 26 138.0042 5.550728 ## 25 139.2122 4.098448 ## 9 138.1504 5.944778 ## 2 142.8621 5.454106 ## 6 146.7815 4.107752 ## 7 146.1244 5.061676 ## 17 142.9973 8.419906 ## 16 147.5373 4.658399 ## 15 144.2861 7.040730 ## 8 148.2941 6.459313 ## 20 151.4568 4.533071 ## 1 148.1253 7.124661 ## 18 151.1749 6.010602 ## 5 151.4249 6.282388 ## 23 151.0655 7.156877 ## 11 150.0557 8.382801 ## 21 150.5243 7.444412 ## 3 155.6331 4.943658 ## 24 153.1363 6.781996 ## 22 154.5675 8.030986 ## 12 156.8026 7.048445 ## 13 156.0722 8.423049 ## 14 159.4704 8.619141 ## 19 164.5675 9.032669 ## 4 165.0645 9.312700 En la presente aplicación es posible incluir la recta de regresión para cada individuo al diagrama de dispersión original. El código de R para obtener esto es el siguiente. library(lattice) xyplot(height ~ age | Subject, data=Oxboys, fit=fit, strip=strip.custom(bg=&quot;white&quot;), pch=16, cex=0.7, col=&#39;indianred1&#39;, panel = function(x, y, ..., fit, subscripts) { panel.xyplot(x, y, ...) ypred &lt;- fitted(fit)[subscripts] panel.lines(x, ypred, col=&quot;deepskyblue3&quot;, lwd=1) }, ylab=&quot;Height (cm)&quot;, xlab=&quot;Centered age&quot;) En la figura anterior se tienen las observaciones (crecimiento) representado por los puntos rojos, adicionalmente, aparece una recta de color azul que representa la recta de regresión para cada individuo. De la figura se observa que la linea logra explicar la evolución del crecimiento para cada individuo. Ejercicios Repita el ejercicio anterior considerando un modelo sólo con intercepto aleatorio. Dibuje las rectas de regresión para cada individuo. ¿Qué opina de este modelo? Repita el ejercicio anterior considerando un modelo sólo con pendiente aleatoria. Dibuje las rectas de regresión para cada individuo. ¿Qué opina de este modelo? Estime la estatura para el individuo # 3 cuando su edad centrada sea de 1.1. Replique los ejemplo de este documento. "],["apli-lme4.html", "9 Aplicación con lme4 Ejercicios", " 9 Aplicación con lme4 En este capítulo se mostrará como usar el paquete lme4 para la aplicación de modelos mixtos con la base de datos sleepstudy del mismo paquete. A continuación la base de datos a utilizar. library(lme4) head(sleepstudy) ## Reaction Days Subject ## 1 249.5600 0 308 ## 2 258.7047 1 308 ## 3 250.8006 2 308 ## 4 321.4398 3 308 ## 5 356.8519 4 308 ## 6 414.6901 5 308 Esta base de datos sobre el tiempo de reacción promedio por día para un conjunto de individuos, en un estudio de privación del sueño, contiene la información sobre el tiempo de reacción promedio (Reaction), el número de días de privación del sueño (Days), donde el día 0 corresponde al día en el que los indiviuos tenían su cantidad normal de sueño, y el número del individuo (en total 18) sobre el que se realizó la observación (Subject). A partir del día 0, hubo una restricción en cada individuo a 3 horas de sueño por noche. library(ggplot2) ggplot(data = sleepstudy, aes(x = Days, y = Reaction, color = Subject)) + geom_point() + theme_bw() + facet_wrap(~ Subject) + theme(legend.position = &quot;none&quot;) De la figura anterior vemos que el tiempo de reacción promedio, tanto en el día 0 como en los siguientes días de prueba (del día 1 al día 9), son distintos en cada uno de los individuos. Esta situación conlleva a probar la hipótesis de que el tiempo de reacción promedio en una serie de pruebas varía según los individuos. Esto es, ajustar un modelo donde el intercepto y la pendiente se consideran como efectos aleatorios. Un modelo lineal mixto que describe la anterior situación se puede escribir como: \\[\\begin{align*} Reaction_{ij} &amp;\\sim N(\\mu_{ij}, \\sigma^2_{Reaction}) \\\\ \\mu_{ij} &amp;= \\beta_0 + \\beta_1 Days_{ij} + b_{0i} + b_{1i} Days_{ij} \\\\ \\left ( \\begin{matrix} b_{0} \\\\ b_{1} \\end{matrix} \\right ) &amp;\\sim N\\left ( \\left [ \\begin{matrix} 0 \\\\ 0 \\end{matrix} \\right ], \\left [ \\begin{matrix} \\sigma^2_{b0} &amp; \\sigma_{b01} \\\\ \\sigma_{b01} &amp; \\sigma^2_{b1} \\end{matrix} \\right ] \\right ) \\end{align*}\\] Aquí, los individuos (\\(i\\)) varían en el tiempo de reacción promedio tanto en su intercepto (\\(b_{0i}\\)) como en su pendiente (\\(b_{1i}\\)), que en conjunto componen la varianza total en dicho tiempo atribuible a la variación entre individuos. Esta contribución individual se cuantifica usando un modelo de intercepto y pendiente aleatoria con distribución normal (\\(N\\)). La variación entre individuos en intercepto y pendiente es \\(\\sigma^2_{b0}\\) y \\(\\sigma^2_{b1}\\), respectivamente. La covarianza entre el intercepto y la pendiente esta dada por \\(\\sigma_{b01}\\). El vector de parámetros para este modelo sería \\(\\boldsymbol{\\Theta}=(\\beta_0, \\beta_1, \\sigma_{reaction}, \\sigma_{b0}, \\sigma_{b1}, \\sigma_{b0b1})^\\top\\). Para ajustar el modelo de intercepto y pendiente aleatoria planteado usando el paquete lme4 podemos usar el siguiente código: fit &lt;- lmer(Reaction ~ Days + (Days | Subject), REML = TRUE, data = sleepstudy) Para obtener la tabla de resumen usamos: summary(fit) ## Linear mixed model fit by REML [&#39;lmerMod&#39;] ## Formula: Reaction ~ Days + (Days | Subject) ## Data: sleepstudy ## ## REML criterion at convergence: 1743.6 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -3.9536 -0.4634 0.0231 0.4634 5.1793 ## ## Random effects: ## Groups Name Variance Std.Dev. Corr ## Subject (Intercept) 612.10 24.741 ## Days 35.07 5.922 0.07 ## Residual 654.94 25.592 ## Number of obs: 180, groups: Subject, 18 ## ## Fixed effects: ## Estimate Std. Error t value ## (Intercept) 251.405 6.825 36.838 ## Days 10.467 1.546 6.771 ## ## Correlation of Fixed Effects: ## (Intr) ## Days -0.138 De la salida anterior se obtienen los siguientes parámetros (\\(\\Theta\\)): \\(\\Theta\\) \\(\\beta_{0}\\) 251.40 \\(\\beta_{1}\\) 10.47 \\(\\sigma_{reaction}\\) 25.59 \\(\\sigma_{b0}\\) 24.74 \\(\\sigma_{b1}\\) 5.92 \\(\\sigma_{b0b1}\\) 10.25 * El útimo parámetro estimado se obtiene utilizando la ecuación de correlación (\\(\\rho\\)) que relaciona la covarianza y desviaciones de los efectos aleatorios: \\(\\rho_{b0b1} = \\sigma_{b0b1}/(\\sigma_{b0} * \\sigma_{b1})\\). Usando la información anterior se puede escribir el modelo ajustado de la siguiente manera: \\[\\begin{align*} Reaction_{ij} &amp;\\sim N(\\hat{\\mu}_{ij}, 25.59^2) \\\\ \\hat{\\mu}_{ij} &amp;= 251.40 + 10.47 Days_{ij} + b_{0i} + b_{1i} Days_{ij} \\\\ \\left ( \\begin{matrix} b_{0} \\\\ b_{1} \\end{matrix} \\right ) &amp;\\sim N\\left ( \\left [ \\begin{matrix} 0 \\\\ 0 \\end{matrix} \\right ], \\left [ \\begin{matrix} 24.74^2 &amp; 10.25 \\\\ 10.25 &amp; 5.92^2 \\end{matrix} \\right ] \\right ) \\end{align*}\\] Los elementos \\(b_{0i}\\) y \\(b_{1i}\\) se deben substituir por sus respectivas predicciones \\(\\tilde{b}_{0i}\\) y \\(\\tilde{b}_{1i}\\) y se pueden obtener del modelo ajustado de esta forma: ranef(fit) ## $Subject ## (Intercept) Days ## 308 2.2585509 9.1989758 ## 309 -40.3987381 -8.6196806 ## 310 -38.9604090 -5.4488565 ## 330 23.6906196 -4.8143503 ## 331 22.2603126 -3.0699116 ## 332 9.0395679 -0.2721770 ## 333 16.8405086 -0.2236361 ## 334 -7.2326151 1.0745816 ## 335 -0.3336684 -10.7521652 ## 337 34.8904868 8.6282652 ## 349 -25.2102286 1.1734322 ## 350 -13.0700342 6.6142178 ## 351 4.5778642 -3.0152621 ## 352 20.8636782 3.5360011 ## 369 3.2754656 0.8722149 ## 370 -25.6129993 4.8224850 ## 371 0.8070461 -0.9881562 ## 372 12.3145921 1.2840221 ## ## with conditional variances for &quot;Subject&quot; Y los valores de los efectos fijos estimados se pueden obtener así: fixef(fit) ## (Intercept) Days ## 251.40510 10.46729 Con base en la información anterior de efectos aleatorios y fijos, es posible escribir la ecuación del modelo para cada individuo. Para esto, se debe considerar los efectos fijos estimados (\\(\\hat{\\beta}_0 \\approx 251.40\\) y \\(\\hat{\\beta}_1\\approx 10.47\\)) y los efectos aleatorios de cada uno de los individuos (por ejemplo para el individuo 308, \\(\\tilde{b}_{0, i=308} \\approx 2.26\\) y \\(\\tilde{b}_{1, i=308} \\approx 9.20\\)). Así, el valor medio del individuo 308 se calcula como: \\[\\begin{align*} \\hat{\\mu}_{i=308, j} &amp;= \\hat{\\beta}_0 + \\hat{\\beta}_0 \\, Days_{i=308, j} + \\tilde{b}_{0, i=308} + \\tilde{b}_{1, i=308} \\, Days_{i=308, j} \\\\ \\hat{\\mu}_{i=308, j} &amp;= 251.40 + 10.47 \\, Days_{i=308, j} 2.26 + 9.20 \\, Days_{i=308, j} \\\\ \\hat{\\mu}_{i=308, j} &amp;= 253.66 + 19.67 \\, Days_{i=308, j} \\end{align*}\\] Lo anterior se puede resumir en el siguiente modelo. \\[\\begin{align*} Reaction_{i=308, j} &amp;\\sim N(\\hat{\\mu}_{i=308, j}, \\hat{\\sigma}^2_{Reaction}) \\\\ \\hat{\\mu}_{i=308, j} &amp;= 253.66 + 19.67 \\, Days_{i=308, j} \\\\ \\hat{\\sigma}_{Reaction} &amp;= 25.59 \\end{align*}\\] Los efectos fijos y aleatorios de la expresión anterior para cada uno de los individuos se pueden obtener con R de la siguiente forma: coef(fit) ## $Subject ## (Intercept) Days ## 308 253.6637 19.6662617 ## 309 211.0064 1.8476053 ## 310 212.4447 5.0184295 ## 330 275.0957 5.6529356 ## 331 273.6654 7.3973743 ## 332 260.4447 10.1951090 ## 333 268.2456 10.2436499 ## 334 244.1725 11.5418676 ## 335 251.0714 -0.2848792 ## 337 286.2956 19.0955511 ## 349 226.1949 11.6407181 ## 350 238.3351 17.0815038 ## 351 255.9830 7.4520239 ## 352 272.2688 14.0032871 ## 369 254.6806 11.3395008 ## 370 225.7921 15.2897709 ## 371 252.2122 9.4791297 ## 372 263.7197 11.7513080 ## ## attr(,&quot;class&quot;) ## [1] &quot;coef.mer&quot; A continuación podras observar el diagrama de dispersión mostrado al inicio de este capitulo, agregandole a la misma la recta de regresión para cada individuo. El código de R para obtener esto se presenta a continuación: fit &lt;- lmer(Reaction ~ Days + (Days | Subject), REML = TRUE, data = sleepstudy) sleepstudy$pred_inter_pend_aleatorio &lt;- predict(fit) ggplot(data = sleepstudy, aes(x = Days, y = pred_inter_pend_aleatorio, color = Subject)) + geom_line() + geom_point(aes(x = Days, y = Reaction, color = Subject)) + geom_abline(intercept = 251.40, slope = 10.47, color = &quot;black&quot;, linetype = &quot;dashed&quot;, size = 0.5) + theme_bw() + facet_wrap(~ Subject) + theme(legend.position = &quot;none&quot;) La figura anterior corresponde a un modelo de intercepto y pendiente aleatoria, en el que se permite que tanto los interceptos como las pendientes varíen según los individuos. Las líneas continuas corresponde a la recta de regresión ajustada a los datos. Los puntos representan las observaciones (tiempo de reacción promedio por día) medidas en cada uno de los individuos. La línea negra discontinua representa el valor medio global de la distribución de los efectos aleatorios. A continuación podra observar distintas figuras donde se ajustaron cuatro modelos distintos, entre ellos el modelo mixto con intercepto y pendiente aleatoria ya evaluado aquí (Figura 4). Con base en estas figuras, se plantean los ejercicios posteriores a las mismas figuras: Ejercicios Ajuste el modelo con intercepto aleatorio mostrado en la anterior Figura 2. ¿Qué opina de este modelo? Ajuste el modelo con pendiente aleatoria presentada en la anterior Figura 3. ¿Qué opina de este modelo? Ajustar solo un intercepto aleatorio permite que los individuos varíen asumiendo que los mismos tienen una pendiente común (Figura 2). Al ajustar solo una pendiente aleatoria (Figura 3) permite que la pendiente de un predictor varíe en función de los individuos (la variable de agrupación). Con base esto y teniendo en cuenta el modelo de intercepto y pendiente aleatoria (Figura 4), evalúe cual de estos estos modelos permite un mejor ajuste de los datos presentados en la base de datos sleepstudy del paquete lme4. "],["ph.html", "10 Pruebas de hipótesis 10.1 Prueba razón de verosimilitud 10.2 Prueba de Wald 10.3 Prueba de hipótesis sobre los efectos fijos 10.4 Prueba de hipótesis sobre componentes de varianza Ejercicios", " 10 Pruebas de hipótesis En este capítulo se muestran las pruebas de hipótesis para comparar modelo mixtos. 10.1 Prueba razón de verosimilitud Supongamos que queremos estudiar \\(H_0: \\theta \\in \\boldsymbol{\\Theta}_0\\) versus \\(H_A: \\theta \\in \\boldsymbol{\\Theta}\\). La prueba razón de verosimilitud (\\(LR\\)) para \\(H_0\\) está dada por: \\[ LR = -2 \\log \\left( \\frac{ sup_{\\theta \\in \\boldsymbol{\\Theta}_0} L(\\theta)}{ sup_{\\theta \\in \\boldsymbol{\\Theta}} L(\\theta)} \\right). \\] Usualmente la prueba de razón de verosimilitud se expresa en función de los valores de log-verosimilitud del modelo así: \\[ LR = -2 ( l(\\Theta_0) - l(\\hat{\\Theta}) ), \\] y el estadístico \\(LR \\sim \\chi^2_{k-k_0}\\), donde \\(k\\) es el número de parámetros del modelo estimado y \\(k_0\\) el número de parámetros del modelo asumiendo \\(H_0\\) verdadera. 10.2 Prueba de Wald Si el interés es estudiar \\(H_0: \\beta_k = \\beta_{k0}\\) contra \\(H_A: \\beta_k \\neq \\beta_{k0}\\) se puede usar la prueba de Wald que tiene el siguiente estadístico: \\[ t = \\frac{\\hat{\\beta}_k - \\beta_{k0}}{se(\\hat{\\beta}_k)}, \\] donde \\(se(\\hat{\\beta}_k)\\) corresponde al error estándar de la estimación \\(\\hat{\\beta}_k\\), todo esto disponible en el summary del modelo ajustado. Si \\(H_0\\) es verdadera, \\(t \\sim t_{n-p}\\), siendo \\(n\\) el número de observaciones y \\(p\\) el número de efectos fijos estimados (no el número de variables) en el modelo. 10.3 Prueba de hipótesis sobre los efectos fijos La prueba razón de verosimilitud puede ser usada para comparar modelos ajustados por el método ML y que difieran en su estructura de efectos fijos, pero con la mismas componentes de varianza. Los valores-P de la prueba pueden ser anticonservativos, es decir, más pequeños de lo normal y por lo tanto se podría rechazar \\(H_0\\) más fácilmente (J. Pinheiro and Bates 2000). En lugar de usar la distribución \\(\\chi^2\\) para el estadístico de la prueba razón de verosimilitud, se recomienda usar la distribución empírica del estadístico, obtenida al ajustar los modelos nulo y alternativo con múltiples conjuntos de datos simulados (Galecki and Burzykowski 2012). Ejemplo La base de datos ChickWeight contiene información sobre el peso de un grupo de pollos versus el tiempo bajo diferentes dietas. Abajo una ilustración de los datos. library(ggplot2) ggplot(data = ChickWeight, aes(x = Time, y = weight, color = Diet)) + geom_point() + theme_bw() + facet_wrap(~ Chick) El objetivo es comparar los siguientes dos modelos. Modelo 1 \\[\\begin{align*} Weight_{ij} &amp;\\sim N(\\mu_{ij}, \\sigma^2_{weight}) \\\\ \\mu_{ij} &amp;= \\beta_0 + \\beta_1 tiempo_{ij} + b_{0i} \\\\ b_{0} &amp;\\sim N(0, \\sigma^2_{b0}) \\end{align*}\\] Modelo 2 \\[\\begin{align*} Weight_{ij} &amp;\\sim N(\\mu_{ij}, \\sigma^2_{weight}) \\\\ \\mu_{ij} &amp;= \\beta_0 + \\beta_1 tiempo_{ij} + \\beta_2 dieta2_{i} + \\beta_3 dieta3_{i} + \\beta_4 dieta4_{i} + b_{0i} \\\\ b_{0} &amp;\\sim N(0, \\sigma^2_{b0}) \\end{align*}\\] Solución. El problema de este ejercicio se puede resumir con \\(H_0:\\) la variable Dieta no aporta al modelo, versus, \\(H_A:\\) la variable Dieta si aporta al modelo. Para ajustar ambos modelos se usa el siguiente código. library(nlme) mod1 &lt;- lme(weight ~ Time, data = ChickWeight, random = ~ 1 | Chick, method=&#39;ML&#39;) mod2 &lt;- lme(weight ~ Time + Diet, data = ChickWeight, random = ~ 1 | Chick, method=&#39;ML&#39;) Para calcular la prueba razón de verosimilitud se usa el siguiente código. lrt &lt;- -2 * (logLik(mod1) - logLik(mod2)) lrt ## &#39;log Lik.&#39; 17.14349 (df=4) pchisq(q=lrt, df=7-4, lower.tail=FALSE) ## &#39;log Lik.&#39; 0.000660304 (df=4) De la salida anterior se tiene que el valor-P = 0.000660304 y menor que cualquier \\(\\alpha\\). Sin embargo, como este valor-P puede ser anticonservativo (más pequeño de lo que debería ser), es mejor no sacar conclusiones apresuradas y rechazar \\(H_0\\). La prueba de verosimilitud se puede obtener también así: anova(mod1, mod2) ## Model df AIC BIC logLik Test L.Ratio p-value ## mod1 1 4 5630.344 5647.782 -2811.172 ## mod2 2 7 5619.201 5649.718 -2802.600 1 vs 2 17.14349 7e-04 Para obtener un valor-P más acorde al problema podemos usar simulación. La función simulate.lme simula datos de modelos especificados por medio de los argumentos object y m2, ajusta los modelos, y entrega los valores de log-verosimilitud, con los se puede obtener el estadístico de la prueba de razón de verosimilitud. A continuación el código para obtener el valor-P con simulación. simul &lt;- simulate.lme(object=mod1, m2=mod2, method = &#39;ML&#39;, nsim=1000) lrts_nlme &lt;- -2 * (simul$null$ML[, 2] - simul$alt$ML[, 2]) acumulada1 &lt;- ecdf(x=lrts_nlme) # F(x) para los valores LRT 1 - acumulada1(17.14349) ## [1] 0.001 De la salida anterior se tiene que el valor-P = 0.001 y ya no es tan pequeño como el valor-P anterior. Por esta razón hay evidencias rechazar \\(H_0\\) y por lo tanto la variable Dieta si aporta al modelo. Ejemplo La base de datos Orthodont contiene información sobre una medida de distancia intrafacial para jóvenes sometidos a ortodoncia. data(Orthodont, package=&quot;nlme&quot;) library(ggplot2) ggplot(data = Orthodont, aes(x = age, y = distance, color = Sex)) + geom_point() + theme_bw() + facet_wrap(~ Subject) El objetivo es comparar los siguientes dos modelos. Modelo 1 \\[\\begin{align*} Distance_{ij} &amp;\\sim N(\\mu_{ij}, \\sigma^2_{distance}) \\\\ \\mu_{ij} &amp;= \\beta_0 + \\beta_1 age_{ij} + b_{0i} \\\\ b_{0} &amp;\\sim N(0, \\sigma^2_{b0}) \\end{align*}\\] Modelo 2 \\[\\begin{align*} Distance_{ij} &amp;\\sim N(\\mu_{ij}, \\sigma^2_{distance}) \\\\ \\mu_{ij} &amp;= \\beta_0 + \\beta_1 age_{ij} + \\beta_2 SexFemale_i + b_{0i} \\\\ b_{0} &amp;\\sim N(0, \\sigma^2_{b0}) \\end{align*}\\] Solución. El problema de este ejercicio se puede resumir con \\(H_0:\\) la variable Sexo no aporta al modelo, versus, \\(H_A:\\) la variable Sexo si aporta al modelo. Para ajustar ambos modelos se usa el siguiente código. library(lme4) mod1 &lt;- lmer(distance ~ age + (1|Subject), data=Orthodont, REML=FALSE) mod2 &lt;- lmer(distance ~ age + Sex + (1|Subject), data=Orthodont, REML=FALSE) Para calcular la prueba razón de verosimilitud se usa el siguiente código. lrt &lt;- -2 * (logLik(mod1) - logLik(mod2)) lrt ## &#39;log Lik.&#39; 8.533057 (df=4) pchisq(q=lrt, df=5-4, lower.tail=FALSE) ## &#39;log Lik.&#39; 0.003487534 (df=4) De la salida anterior se tiene que el valor-P = 0.003487534 y menor que cualquier \\(\\alpha\\). Sin embargo, como este valor-P puede ser anticonservativo (más pequeño de lo que debería ser), es mejor no sacar conclusiones apresuradas y rechazar \\(H_0\\). La prueba de verosimilitud se puede obtener también así: anova(mod1, mod2) ## Data: Orthodont ## Models: ## mod1: distance ~ age + (1 | Subject) ## mod2: distance ~ age + Sex + (1 | Subject) ## npar AIC BIC logLik deviance Chisq Df Pr(&gt;Chisq) ## mod1 4 451.39 462.12 -221.69 443.39 ## mod2 5 444.86 458.27 -217.43 434.86 8.5331 1 0.003488 ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Para obtener un valor-P más acorde al problema podemos usar simulación. La función simulate.lme simula respuestas \\(y_{ij}\\) del modelo dado. A continuación el código para obtener el valor-P con simulación (¡tarda varios minutos!). nrep &lt;- 5000 lrts_lme4 &lt;- numeric(nrep) for (i in 1:nrep) { new_y_h0 &lt;- simulate(mod1) # Asumiendo H0 verdadera Orthodont$new_y_h0 &lt;- new_y_h0$sim_1 aux0 &lt;- lmer(new_y_h0 ~ age + (1|Subject), data=Orthodont, REML=FALSE) aux1 &lt;- lmer(new_y_h0 ~ age + Sex + (1|Subject), data=Orthodont, REML=FALSE) lrts_lme4[i] &lt;- -2 * (logLik(aux0) - logLik(aux1)) } acumulada2 &lt;- ecdf(x=lrts_lme4) # F(x) para los valores LRT 1 - acumulada1(8.533057) ## [1] 0.005 De la salida anterior se tiene que el valor-P = 0.005 y ya no es tan pequeño como el valor-P anterior. Por esta razón hay evidencias rechazar \\(H_0\\) y por lo tanto la variable Sexo si aporta al modelo. 10.4 Prueba de hipótesis sobre componentes de varianza Las componentes de varianza corresponden a las varianzas y covarianzas del vector de efectos aleatorios. La prueba razón de verosimilitud puede ser usada para comparar modelos ajustados por el método REML y que difieran en sus componentes de varianza, pero que tenga igual estructura de efectos fijos. Para hacer pruebas de hipótesis sobre las componentes de varianza se tienen dos casos que se explican en las siguientes subsecciones. 10.4.1 Componentes de varianza lejos del borde Luego un ejemplo. 10.4.2 Componentes de varianza en el borde Este caso se presenta cuando la hipótesis nula considera que uno o varios parámetros están justo en el borde del dominio del parámetro en cuestion. Por ejemplo, si queremos estudiar la inclusión del intercepto aleatorio \\(b_0\\) en un modelo de regresión clásico, tendríamos las siguientes hipótesis: \\(H_0: \\sigma^2_{b0} = 0\\) versus \\(H_A: \\sigma^2_{b0} &gt; 0\\). Debido a la condición de \\(\\sigma^2_{b0}\\) en \\(H_0\\), se dice que esa componente de varianza está en el borde de su dominio, ya que \\(\\sigma^2_{b0}\\) no puede ser negativa. En este ejemplo particular, rechazar \\(H_0\\) implicaría que es apropiado incluir \\(b_0\\) en el modelo. En el caso de componentes de varianza cerca de la frontera la distribución del estadístico razón de verosimilitud no es exactamente una \\(\\chi^2\\) (Galecki and Burzykowski 2012). En la sección 6.3.4 de (Verbeke and Molenberghs 2000) se listan cuatro casos en los cuales se usan mezclas de distribuciones corregir la distribución del estadístico y así calcular el valor-P corregido en la prueba razón de verosimilitud. Los cuatro casos son los siguientes: Sin efecto aleatorio versus 1 efecto aleatorio: en este caso lo que interesa es \\(H_0: \\sigma^2_{b} = 0\\) versus \\(H_A: \\sigma^2_{b} &gt; 0\\), la distribución asintótica del estadístico de razon de verosimilitud es una mezcla de \\(\\chi^2_1\\) y \\(\\chi^2_0\\) con pesos iguales a 0.5. 1 efecto aleatorio versus 2 efectos aleatorios: en este caso lo que interesa es \\(H_0: \\boldsymbol{D} = \\begin{pmatrix} d_{11} &amp; 0 \\\\ 0 &amp; 0 \\end{pmatrix}\\) versus \\(H_A: \\boldsymbol{D} \\neq \\boldsymbol{0}\\) para un \\(d_{11}&gt;0\\), en este caso la distribución asintótica del estadístico razón de verosimilitud es una mezcla de \\(\\chi^2_2\\) y \\(\\chi^2_1\\) con pesos iguales a 0.5. \\(q\\) efectos aleatorios versus \\(q+1\\) efectos aleatorios: en este caso lo que interesa es \\(H_0: \\boldsymbol{D} = \\begin{pmatrix} \\boldsymbol{D_{11}} &amp; \\boldsymbol{0}\\\\ \\boldsymbol{0}^\\top &amp; 0 \\end{pmatrix}\\) donde \\(\\boldsymbol{D_{11}}\\) es una matriz de covarianzas (positiva definida) de dimensión \\(q \\times q\\) versus que \\(\\boldsymbol{D}\\) es una matriz general de dimensión \\(q+1 \\times q+1\\). En este caso la distribución asintótica del estadística razón de verosimilitud es una mezcla de \\(\\chi^2_{q+1}\\) y \\(\\chi^2_q\\) con pesos iguales a 0.5. \\(q\\) efectos aleatorios versus \\(q+k\\) efectos aleatorios: en este caso lo que interesa es \\(H_0: \\boldsymbol{D} = \\begin{pmatrix} \\boldsymbol{D_{11}} &amp; \\boldsymbol{0}\\\\ \\boldsymbol{0}^\\top &amp; \\boldsymbol{0} \\end{pmatrix}\\) donde \\(\\boldsymbol{D}\\) es una matriz de covarianzas (positiva definida) de dimensión \\(q+k \\times q+k\\) versus que \\(H_A: \\boldsymbol{D} = \\begin{pmatrix} \\boldsymbol{D_{11}} &amp; \\boldsymbol{D_{12}}\\\\ \\boldsymbol{D_{12}}^\\top &amp; \\boldsymbol{D_{22}} \\end{pmatrix}\\) es una matriz general de dimensión \\(q+k \\times q+k\\). En este caso la distribución asintótica del estadística razón de verosimilitud es una mezcla de \\(\\chi^2_{q+k}\\) y \\(\\chi^2_q\\) con pesos iguales a 0.5. Si la distribución nula del estadístico razón de verosimilitud no puede ser obtenida analíticamente, una posible solución es usar la distribución empírica del estadístico obtenida al ajustar múltiples modelos nulos y alternativos (Galecki and Burzykowski 2012). Ejemplo Simule 10 observaciones para cada uno de los 10 grupos siguiendo el siguiente modelo y luego aplique la prueba de razón de verosimilitud para estudiar \\(H_0: \\sigma^2_{b0} = 0\\) versus \\(H_A: \\sigma^2_{b0} &gt; 0\\). \\[\\begin{align*} y_{ij} &amp;\\sim N(\\mu_{ij}, \\sigma^2_y) \\\\ \\mu_{ij} &amp;= 4 - 6 x_{ij} + b_{0i} \\\\ \\sigma^2_y &amp;= 4 \\\\ b_{0} &amp;\\sim N(0, \\sigma^2_{b0}=4) \\\\ x_{ij} &amp;\\sim U(0, 10) \\end{align*}\\] Solución. La función gen_dat_b0 de abajo permite simular m observaciones de n grupos con intercepto aleatorio \\(b_0 \\sim N(0, \\sigma^2_{b0})\\). Adicionalmente, es posible elegir los efectos fijos beta0, beta_1 y la varianza sigma de la variable respuesta. gen_dat_b0 &lt;- function(n, m, beta0, beta1, sigmay, sigmab0, seed=NULL) { if(is.null(seed)) seed &lt;- as.integer(runif(1)*2e9) group &lt;- rep(1:n, each=m) set.seed(seed) b0 &lt;- rep(rnorm(n=n, mean=0, sd=sigmab0), each=m) set.seed(seed) x &lt;- runif(n=n*m, min=0, max=10) set.seed(seed) y &lt;- rnorm(n=n*m, mean=beta0 + beta1 * x + b0, sd=sigmay) data.frame(group=group, x=x, y=y) } Vamos ahora a generar 10 observaciones para 10 grupos con intercepto aleatorio con una varianza \\(\\sigma^2_{b0}=2^2=4\\). La semilla se va a fijar en un valor de 1220872376 por cuestiones didácticas. datos &lt;- gen_dat_b0(n=10, m=10, beta0=4, beta1=-6, sigmay=2, sigmab0=2, seed=1220872376) head(datos) ## group x y ## 1 1 3.817132 -20.106729 ## 2 1 8.951117 -49.950457 ## 3 1 5.710726 -33.154170 ## 4 1 7.451320 -39.583303 ## 5 1 1.263282 -1.070788 ## 6 1 6.114367 -33.423587 Vamos a ajustar dos modelos, el primero sin incluir \\(b_0\\) y el segundo incluyendo \\(b_0\\). library(nlme) fit1 &lt;- gls(y ~ x, data=datos, method=&quot;REML&quot;) # Igual resultado con lm fit2 &lt;- lme(y ~ x, random = ~ 1| group, data=datos, method=&quot;REML&quot;) Resultados del primer modelo. summary(fit1) ## Generalized least squares fit by REML ## Model: y ~ x ## Data: datos ## AIC BIC logLik ## 475.8248 483.5797 -234.9124 ## ## Coefficients: ## Value Std.Error t-value p-value ## (Intercept) 4.64931 0.5180190 8.97517 0 ## x -6.00175 0.0814173 -73.71588 0 ## ## Correlation: ## (Intr) ## x -0.875 ## ## Standardized residuals: ## Min Q1 Med Q3 Max ## -2.14346496 -0.64999607 -0.06461389 0.60660976 3.48238119 ## ## Residual standard error: 2.50842 ## Degrees of freedom: 100 total; 98 residual Resultados del segundo modelo. summary(fit2) ## Linear mixed-effects model fit by REML ## Data: datos ## AIC BIC logLik ## 474.7777 485.1175 -233.3888 ## ## Random effects: ## Formula: ~1 | group ## (Intercept) Residual ## StdDev: 0.8166724 2.383898 ## ## Fixed effects: y ~ x ## Value Std.Error DF t-value p-value ## (Intercept) 4.640053 0.5652943 89 8.20821 0 ## x -6.000087 0.0795348 89 -75.43973 0 ## Correlation: ## (Intr) ## x -0.783 ## ## Standardized Within-Group Residuals: ## Min Q1 Med Q3 Max ## -2.19536246 -0.56396957 0.05433633 0.61634184 3.29594400 ## ## Number of Observations: 100 ## Number of Groups: 10 Ahora vamos a calcular el estadístico y su valor-P. lrt &lt;- -2 * (logLik(fit1) - logLik(fit2)) lrt ## &#39;log Lik.&#39; 3.04712 (df=3) my_p.value &lt;- pchisq(q=3.04712, df=1, lower.tail=FALSE) my_p.value ## [1] 0.08088045 De la salida anterior se tiene que \\(valor-P = 0.0809\\) y como \\(\\alpha=0.05\\), por lo tanto NO hay evidencias para rechazar \\(H_0: \\sigma^2_{b0} = 0\\). ¿No es extraña esta conclusión ? Los resultados anteriores se pueden obtener por medio de la función anova así. anova(fit1, fit2) ## Model df AIC BIC logLik Test L.Ratio p-value ## fit1 1 3 475.8248 483.5797 -234.9124 ## fit2 2 4 474.7777 485.1175 -233.3888 1 vs 2 3.04712 0.0809 Ahora vamos a simular 50 conjuntos de datos suponiendo \\(H_0\\) verdadera y luego calcularemos los lrt para así tener la distribución empírica de los lrt bajo la hipótesis nula \\(H_0: \\sigma^2_{b0} = 0\\) verdadera. En un aplicación se deberían generar más conjuntos de pero aquí vamos a usar sólo 50 por comodidad. pseudo_gen_dat &lt;- function(nobs, beta0, beta1, sigmay) { group &lt;- datos$group # Aqui la diferencia x &lt;- datos$x # Aqui la diferencia y &lt;- rnorm(n=nobs, mean=beta0 + beta1 * x, sd=sigmay) data.frame(group=group, x=x, y=y) } nrep &lt;- 50 lrts &lt;- numeric(nrep) for (i in 1:nrep) { pseudo_datos &lt;- pseudo_gen_dat(nobs=100, beta0=4.64931, beta1=-6.00175, sigma=2.50842) m1 &lt;- gls(y ~ x, data=pseudo_datos, method=&quot;REML&quot;) m2 &lt;- lme(y ~ x, random = ~ 1| group, data=pseudo_datos, method=&quot;REML&quot;) lrts[i] &lt;- -2 * (logLik(m1) - logLik(m2)) } Dibujando la densidad de los lrt. plot(density(lrts), main=&#39;Densidad empírica de los lrts&#39;) Calculando el valor-P. acumulada &lt;- ecdf(x=lrts) # F(x) para los valores LRT 1 - acumulada(3.04712) # Valor-P ## [1] 0.04 De la salida anterior se tiene que \\(valor-P &lt; \\alpha\\) por lo tanto SI hay evidencias para rechazar \\(H_0: \\sigma^2_{b0} = 0\\). ¿Es esto coherente ahora ? Los resultados anteriores se obtuvieron usando nrep &lt;- 50, en la práctica ese número de repeticiones debería subir al menos a 1000. Repita el procedimiento anterior con nrep &lt;- 5000 y observe lo que sucede. El paquete RLRsim (Scheipl 2020) tiene la función exactRLRT que permite extraer el valor-P mediante simulación. Abajo un ejemplo de como usarla en el presente ejemplo. library(RLRsim) exactRLRT(m=fit2, nsim=1000) ## Warning in model.matrix.default(~m$groups[[n.levels - i + 1]] - 1, contrasts.arg ## = c(&quot;contr.treatment&quot;, : non-list contrasts argument ignored ## ## simulated finite sample distribution of RLRT. ## ## (p-value based on 1000 simulated values) ## ## data: ## RLRT = 3.0471, p-value = 0.039 Consulte la ayuda de la función exactRLRT para que conozca sus posibilidades y limitaciones. Ejercicios ¿Qué son modelos anidados? ¿Son modelos que usan datos relacionados con aves? Considere la base de datos sleepstudy del paquete lme4. El objetivo es comparar los siguientes dos modelos. Modelo 1 \\[\\begin{align*} Reaction_{ij} &amp;\\sim N(\\mu_{ij}, \\sigma^2_{reaction}) \\\\ \\mu_{ij} &amp;= \\beta_0 + \\beta_1 days_{ij} + b_{0i} + b_{1i} days_{ij} \\\\ (b_0, b_1)^\\top &amp;\\sim N(\\boldsymbol{0}, \\boldsymbol{D}) \\end{align*}\\] Modelo 2 \\[\\begin{align*} Reaction_{ij} &amp;\\sim N(\\mu_{ij}, \\sigma^2_{reaction}) \\\\ \\mu_{ij} &amp;= \\beta_0 + \\beta_1 days_{ij} + \\beta_2 days_{ij}^2 + b_{0i} + b_{1i} days_{ij} \\\\ (b_0, b_1)^\\top &amp;\\sim N(\\boldsymbol{0}, \\boldsymbol{D}) \\end{align*}\\] Escriba las hipótesis del problema en forma simbólica y en lenguaje sencillo. Aplique la prueba razón de verosimilitud usando simulación y concluya. Rta: el valor-P \\(\\approx\\) 0.136. Considere el ejemplo del capítulo 8 sobre el estudio de crecimiento de un grupo de jóvenes. Aplique la prueba razón de verosimilitud para estudiar \\(H_0: \\sigma^2_{b0} = 0\\) versus \\(H_A: \\sigma^2_{b0} &gt; 0\\), es decir, ajuste un modelo lineal simple para explicar la estatura en función de la edad y luego un modelo mixto con intercepto aleatorio. ¿Cuál de los dos modelos parece explicar mejor los datos? Use \\(\\alpha=0.06\\). En este enlace está la pregunta de un usuario de StackExange sobre prueba de hipótesis (PH). ¿Fue la pregunta sobre PH sobre efectos fijos o PH sobre componentes de varianza? ¿Quería el usuario un PH asintótica o una PH basada en bootstrap (relacionado con simulación)? Mire el ejemplo que dió YaronZ, ¿por qué no definió el método REML dentro de las funciones lmer y lm? En este enlace está la extensa pregunta del usuario Patrick. En el primer cajón de código Patrick escribió un código para simular observaciones de un modelo mixto. ¿Cómo le parece esa forma de simular? ¿Cuántos elementos tiene el vector de parámetros del modelo de Patrick? ¿Cuáles son los valores de los parámetros? En este enlace está la pregunta del usuario biostat_newbie. ¿Qué nombre recibe el modelo que le interesa a biostat_newbie? ¿Qué es lo que necesita 0.7494974? ¿Cuál es el mensaje de primer párrafo de que respondió Fabians? En la respuesta que Fabians dió hay un código de R. ¿Para qué sirve ese código tan extraño? ¿Quién es Ben Bolker? ¿En cuáles paquetes de R ha participado Ben Bolker? En este enlace está la pregunta del usuario user9171. ¿Cuál es el error que comete user9171 al usar el siguiente código? &gt; anova(fit.fe, fit.me) Error: $ operator not defined for this S4 class ¿Qué le respondió Karl Ove Hufthammer? Karl le agrega en su respuesta And really the choice of whether to include the random effects should be based on theory (e.g., the sampling plan), not on a statistical test. ¿Qué quiere decir eso? Ben Bolker escribió unas notas sobre pruebas de hipótesis, revise este enlace para consultarlas. En el ejemplo de Ben Bolker hay tres modelos: m2, m1 y m0. ¿Cuál es el full model y cuál es el reduced model? ¿Para qué sirve la función update? ¿Usted la ha usado alguna vez? ¿No? Pues úsela de aquí en adelante. Ben escribe which has a fast implementation of simulation-based tests of null hypotheses about zero variances, for simple tests. ¿A qué paquete se refiere con esa frase? References "],["reg-diagnos.html", "11 Diagnóstico del modelo de regresión de efectos mixtos 11.1 Supuestos del modelo de regresión 11.2 Los residuos 11.3 Diagnóstico del modelo de regresión: prueba de hipótesis e inferencia visual", " 11 Diagnóstico del modelo de regresión de efectos mixtos El diagnóstico del modelo de regresión es uno de un conjunto de procedimientos disponibles para el análisis de regresión que buscan evaluar la validez de un modelo previamente ajustado. Esta evaluación puede ser una exploración de los supuestos estadísticos del modelo. El objetivo de este capitulo consiste en introducir al lector los distintos métodos de diagnostico del modelo de regresión. 11.1 Supuestos del modelo de regresión Existen un conjunto de supuestos cuando se modela la relación entre una variable respuesta y un regresor. Estos supuestos son esencialmente condiciones que deben cumplirse. Cuando no es el caso, las estimaciones y predicciones pueden comportarse mal e incluso pueden tergiversar por completo los datos. El diagnóstico de regresión puede revelar el problema y, a menudo, señalar el camino hacia las soluciones. Si un modelo de regresión ajustado representa adecuadamente los datos, sus residuos deberan: Tener varianza constante (homogeneidad de la varianza); Estar aproximadamente distribuidos de forma normal y; Ser independientes el uno del otro. Por tanto los supuestos del modelo de regresión se examinan a partir de los residuos que resultan del ajuste previo. 11.2 Los residuos Los residuos son la base de la mayoría de los métodos de diagnóstico. Estos pueden ser de distinto tipo. Los residuos más básicos son los denominados residuos ordinarios, \\(\\hat{\\epsilon}_{i}\\), el cual se define como la diferencia entre el valor observado, \\(y_{i}\\), y su correspondiente valor estimado por el modelo, \\(\\hat{\\mu}_{i}\\), así: \\[\\begin{align*} \\hat{\\epsilon}_{i} = y_{i} - \\hat{\\mu}_{i}, i = 1, 2, ..., n \\end{align*}\\] donde \\(\\hat{\\mu}_{i}\\) es igual a \\(x^{&#39;}_{i}\\hat{\\beta}\\). A continuación, se presenta una representación gráfica de \\(\\hat{\\epsilon}_{i}\\): Figure 11.1: Representación gráfica de los residuos, del valor estimado y del valor observado. Luego los residuos ordinarios se escalan con el fin de que su interpretación no dependa de las unidades de medida de la variable respuesta. El proceso de estandarización consiste en dividir el residuo ordinario, \\(\\hat{\\epsilon}_{i}\\), por la expresión \\(\\sigma\\sqrt{(1-h_{i})}\\), donde \\({\\sigma}\\) corresponde a la desviación estandar verdadera y \\(h_{i}\\) al leverage (en inglés). Los residuos obtenidos de esta manera se denominan como residuos estandarizados. Sin embargo la verdadera desviación estándar rara vez se conoce. Por lo tanto, el escalado se puede realizar utilizando un estimador del mismo, es decir \\(\\hat{\\sigma}\\). Los residuos obtenidos de esta manera se denominan como residuos estudentizados, los cuales a su vez se dividen en dos: los residuos internamente estudentizados y los residuos externamente estudentizados. La tabla a continuación, resume las formas básicas de los residuos escalados: Formula matemática Estandarizado \\(\\frac{\\hat\\epsilon_i}{\\sigma\\sqrt{(1-h_i)}}\\) Internamente estudentizado \\(\\frac{\\hat\\epsilon_i}{\\hat\\sigma\\sqrt{(1-h_i)}}\\) Externamente estudentizado \\(\\frac{\\hat\\epsilon_i}{\\hat\\sigma_{(-i)}\\sqrt{(1-h_i)}}\\) * En el residuo internamente estudentizado, \\(\\hat\\sigma\\) denota una estimación de \\(\\sigma\\) basada en todas las observaciones;  En el residuo externamente estudentizado, \\(\\hat\\sigma_{(-i)}\\) es una estimación obtenida luego de excluir la i-ésima observación de los cálculos. Se usara la base de datos hsb del paquete merTools para entender mejor de que tratan los residuos, así como también los métodos de diagnosticos que explicaremos más adelante en este capitulo. A continuación podra ver la base de datos a usar: Se puede entender bien la lógica de los que son los residuos ajustando un modelo de regresión simple. El diagnóstico del modelo de regresión aborda la adecuación de un modelo estadístico una vez se han ajustado los datos. De hecho, el ajuste de un modelo debe verse como un proceso iterativo en el que se ajusta el modelo, se evalúan sus residuos y se mejora. Así hasta llegar a un modelo óptimo. Suponga que se quiere poner en relación dos variables: la variable \\(x_{1}\\) que representa el nivel socio-económico de los estudiantes (ses), y la variable \\(y\\), que es el rendimiento de los mismos estudiantes en una prueba de matemáticas (mathach). Para facilitar este análisis (y los posteriores) se asumira que \\(x_{1}\\) es una variable continua que toma valores entre -4 y +4, donde valores cercanos a 0 indican nivel socio-económico medio, cercanos a +4 indican nivel socio-económico alto y cercanos a -4 indican nivel socio-económico bajo. El modelo de regresión simple aplicado a este ejemplo se puede representar así: \\[\\begin{align} \\label{mod2} y_i &amp;\\sim N(\\mu_i, \\sigma^2), \\\\ \\mu_i &amp;= \\beta_0 + \\beta_1 x_{1i}, \\\\ \\sigma^2 &amp;= \\text{constante} \\end{align}\\] El codigó en R para ajustar el anterior modelo se presenta a continuación: Modelo_simple &lt;- lm(mathach ~ ses, data = hsb) summary(Modelo_simple) ## ## Call: ## lm(formula = mathach ~ ses, data = hsb) ## ## Residuals: ## Min 1Q Median 3Q Max ## -19.4382 -4.7580 0.2334 5.0649 15.9007 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 12.74740 0.07569 168.42 &lt;2e-16 *** ## ses 3.18387 0.09712 32.78 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 6.416 on 7183 degrees of freedom ## Multiple R-squared: 0.1301, Adjusted R-squared: 0.13 ## F-statistic: 1075 on 1 and 7183 DF, p-value: &lt; 2.2e-16 Luego, los residuos (en este caso los residuos ordinarios) se pueden obtener con las siguientes funciones genericas: muestra_aleatoria$val_predicho &lt;- predict(Modelo_simple) muestra_aleatoria$res_ordinario &lt;- residuals(Modelo_simple) La gráfica a continuación presenta los valores observados y estimados en el rendimiento de los estudiantes en una prueba de matemáticas según su nivel socio-económico, siendo la misma una representación gráfica similar a la presentada en la Figura 6.1: Tenga en cuenta que se bien el modelo se ajusto con las 7185 valores observados, la gráfica a continuación solo presenta 150 valores. Esto debido a que al no restringir por este valor, la gráfica se presentaba muy saturada de valores observados y estimados. ## Warning: `guides(&lt;scale&gt; = FALSE)` is deprecated. Please use `guides(&lt;scale&gt; = ## &quot;none&quot;)` instead. Figure 11.2: Valores obserados y estimados en el rendimiento en una prueba matemática según el nivel socio-económico del estudiante. La gráfica anterior representa la relación existente entre el rendimiento académico y el nivel socio-económico del estudiante. Claramente se puede observar que a mayor nivel socio-económico, mejor es el rendimiento del estudiante. Una vez ajustado el modelo de regresión, y como se puede observar en la anterior gráfica, se tienen los valores observados (puntos con relleno), los valores estimados (puntos sin relleno) y el residuo (representado por una línea vertical que une a los valores observados con los estimados). Por tanto, puede imaginar ahora que cada dato (valor observado) tiene un valor estimado y un residuo (residuo ordinario en este caso) como se detalla a continuación: Rendimiento real Rendimiento estimado Residuo ordinario 9.670 16.44451 -6.774512 24.488 17.39127 7.096730 12.500 11.01095 1.489052 23.231 15.78590 7.445102 Luego dichos residuos se consideran como elementos clave en la evaluación del modelo ajustado. Estos suelen emplearse en los métodos de diagnosticos del modelo de regresión mediante pruebas de hipótesis acompañadas de inferencia visual (gráficos). Por ejemplo, la figura a continuación muestra una de las gráficas comunmente usadas en los métodos de diagnostico: ## Warning: `guides(&lt;scale&gt; = FALSE)` is deprecated. Please use `guides(&lt;scale&gt; = ## &quot;none&quot;)` instead. Figure 11.3: Gráfica de residuos ordinarios vs Valores estimados. Existe una gran variedad de gráficos (como la presentada anteriormente) lo que refleja el hecho de que ningún gráfico de diagnóstico es apropiado para todos los propósitos. Veremos la interpretación de la misma con más detalle a continuación. 11.3 Diagnóstico del modelo de regresión: prueba de hipótesis e inferencia visual Como es sabido, la inferencia estadística clásica consiste en formular inicialmente un juego de hipótesis (hipótesis nula y alternativa), y calcular posteriormente un estadístico de prueba del cual se deriva un valor p que permitira concluir en relación a las hipótesis planteadas. Este proceso tiene su análogo en inferencia visual. Suponga que el interés consiste en verificar alguna suposición sobre el modelo ajustado, por ejemplo, la homogeneidad de la varianza residual. Para ello se plantea como hipótesis nula el cumplimiento de dicha homogeneidad, mientras que la hipótesis alternativa abarca cualquier violación de este supuesto. Para la inferencia visual, el estadístico de prueba corresponde a una gráfica que muestra un aspecto del supuesto que se desea verifcar, y permite al observador distinguir entre escenarios bajo la hipótesis nula y la alternativa. A continuación se mostrará como llevar a cabo el diagnóstico del modelo de regresión empleando tanto pruebas de hipótesis como inferencia visual. Para ello, haremos uso de nuevo de la base de datos anteriormente mencionada hsb. 11.3.1 Ajustando el modelo Vimos anteriormente en este capitulo que era posible determinar si el rendimiento de los estudiantes en una prueba de matemáticas (mathach) estaba relacionada con su nivel socio-económico (ses). Se considerará ahora la posibilidad de que la relación entre el rendimiento y el nivel socio-económico del estudiante varien según las características de la escuela, específicamente, si la escuela es una escuela pública o una escuela privada (schtype). Un buen punto de partida consiste es ver la relación entre el rendimiento y el nivel socio-económico por separado para cada escuela: Figure 11.4: Diagrama de dispersión del rendimiento matemático según el nivel socio-económico en escuelas públicas. Figure 11.5: Diagrama de dispersión del rendimiento matemático según el nivel socio-económico en escuelas privadas. En cada panel, la línea representa un ajuste lineal por mínimos cuadrados a los datos. El número en la parte superior corresponde a la identificación de la escuela (en este caso se han elegido doce escuelas para cada tipo). Claramente parece haber una diferencia entre la escuelas públicas y privadas: las líneas para las escuelas públicas parecen tener pendientes más pronunciadas. Esto hace pensar que un modelo de efectos mixtos con intercepto y pendiente aleatoria podría ser adecuado para modelar este tipo de datos. Por tal motivo, el modelo de regresión de efectos mixtos aplicado a este ejemplo se puede representar así: \\[\\begin{align*} y_{ij} &amp;\\sim N(\\mu_{ij}, \\sigma^2), \\\\ \\mu_{ij} &amp;= \\beta_0 + \\beta_1 x_{ij} + b_{0i} + b_{1i} x_{ij}, \\\\ \\left ( \\begin{matrix} b_{0} \\\\ b_{1} \\end{matrix} \\right ) &amp;\\sim N\\left [ \\left ( \\begin{matrix} 0 \\\\ 0 \\end{matrix} \\right ), \\left ( \\begin{matrix} \\sigma^2_{b0} &amp; \\sigma_{b01} \\\\ \\sigma_{b01} &amp; \\sigma^2_{b1} \\end{matrix} \\right ) \\right ] \\end{align*}\\] Esta ecuación representa la relación existente entre el rendimiento acádemico y el nivel socio-económico de los estudiantes. La variable respuesta, \\(y_{ij}\\), es el rendimiento del estudiante, \\(i\\), en la escuela \\(j\\). El codigó en R para ajustar el anterior modelo se presenta a continuación. Se hara uso del paquete lme4 ya mencionado en el capitulo 3 del presente libro: library(lme4) Modelo_mixto &lt;- lmer(mathach ~ ses + (ses | schtype), REML = TRUE, data = hsb) La siguiente figura, obtenida a partir del modelo anteriormente ajustado, pone de manifiesto la posibilidad real y plausible de que el intercepto y la pendiente varíen según las características de cada escuela (privada o pública): Figure 11.6: Grafica del modelo de regresión ajustado para dos escuelas. Luego de ajustado el modelo de regresión, el procedimiento a seguir corresponde a evaluar el cumplimiento de los supuestos del mismo mediante métodos de diagnóstico. 11.3.2 Varianza constante de los residuos mediante inferencia visual Uno de los supuestos del modelo de regresión es la varianza constante de los residuos. Para comprobar dicho supuesto, se suele emplear la gráfica de residuos contra los valores estimados. La misma es considerada como la gráfica de diagnóstico más básica. A continuación podrá observar varios ejemplos de la misma: Figure 11.7: Representación visual de la gráfica de residuos contra los valores estimados. Si se cumple el supuesto de varianza constante de los residuos, estos se dispersarían de forma aleatoria alrededor de la línea central (como si se tratara de una nube de puntos) sin un patrón obvio, como se puede observar en la figura 6.7 A. La varianza no constante se diagnosticaría si la variabilidad de los residuos en el gráfico mostraran un patrón no aleatorio, como por ejemplo, si hubiera una curvatura presente (figura 6.7 B), o bien, si los residuos cambiaran de forma abrupta a medida que aumentan los valores estimados. Finalmente, un patrón inusual puede ser causado por un valor atípico. En el ejemplo visual anterior (figura 6.7 C), se muestra un valor atípico obvio. En el ejemplo planteado usando la base de datos hsb, esta gráfica se muestra en las figuras 6.8 A y 6.8 C, basados en dos tipos de residuos (ordinarios y pearson): Figure 11.8: Gráficos residuales para el modelo de efectos mixtos (a) entre los residuos ordinarios contra los valores estimados (b) residuos ordinarios en cada tipo de escuela (c) residuos pearson contra los valores estimados (d) residuos pearson en cada tipo de escuela. En relación al código presentado anteriormente, tenga en cuenta lo siguiente: Las gráficas se realizaron usando la función ggplot (aquí subrayado en color amarillo) del paquete ggplot2; Luego en la asignación estética (aes), se proporcionó los valores estimados y los residuos pearson u ordinarios (aquí subrayados en color azul), datos que se obtuvieron mediante previo ajuste del modelo; La línea discontinua en las gráficas superior e inferior izquierda, es la línea horizontal a través de \\(\\hat{\\epsilon}_{i} = 0\\) (es decir, donde la diferencia entre los valores observados y estimados son iguales a cero), siendo el mismo el caso ideal; La línea continua en rojo en las gráficas superior e inferior izquierda, obtenidas a partir de la función stat_smoot (aquí subrayado en amarillo), representan una curva suave ajustada mediante el método loess, que indica la relación de los valores estimados con los residuos. En general, los gráficos anteriores se evalúan de forma informal con respecto a la presencia o ausencia de patrones específicos y/o puntos de datos periféricos o aislados. Respecto a la línea de referencia en cero y la línea ajustada mediante el método de loess, estas deberían parecerse. Por otro lado en cuanto al gráfico de caja y bigotes (parte superior e inferior derecha de la anterior figura), si estas tienen aproximadamente el mismo centro y distancia intercuartil, indicarían el cumplimiento de varianza constante de los residuos. 11.3.3 Varianza constante de los residuos mediante prueba de hipótesis Por lo general, es suficiente con interpretar de forma visual una gráfica de residuos contra valores estimados para comprobar la validez del supuesto de varianza constante de los residuos. Sin embargo, existen pruebas que pueden proporcionar una justificación adicional en el análisis. Dichas pruebas plantean el siguiente constraste de hipótesis: \\[H_{0}: \\sigma^{2}_{\\epsilon_{1}} = \\sigma^{2}_{\\epsilon_{2}}\\] \\[H_{A}: \\sigma^{2}_{\\epsilon_{1}} \\ne \\sigma^{2}_{\\epsilon_{2}}\\] Así, \\(H_{0}\\) (la hipótesis nula) sugiere una varianza constante de los residuos. A continuación se mencionan algunas de estas pruebas: Prueba Función en R Paquete en R Contraste de razón de varianzas var.test stats Prueba de Levene leveneTest car Prueba de Bartlett bartlett.test stats Prueba de Brown-Forsyth hov HH Prueba de Fligner-Killeen fligner.test stats * La diferencias entre estas pruebas es el estadístico de centralidad que utilizan, así como también la sensibilidad o no al cumplimiento del supuesto de normalidad. Para el contraste de hipótesis, cada una de las pruebas entrega un valor-P. Si el valor-P cumple con la condición de ser menor que un nivel de significancia impuesto arbitrariamente, este se considera como un resultado estadisticamente significativo y, por lo tanto, permite rechazar la hipótesis nula, dando como resultado el no cumplimiento de la varianza constante de los residuos. Ejemplo La función help y el operador de ayuda ? en R proporcionan acceso a las páginas de documentación para funciones de R, conjuntos de datos y otros objetos, así por ejemplo para acceder a la documentación de la función var.test del paquete stats, se puede ingresar el comando help(var.test) o help(\"var.test\"), o ?var.test o ?\"var.test\" (por tanto, las comillas son opcionales). Haciendo uso de cualquiera de los dos comandos de ayuda anteriores, se plantea como ejemplo acceder a la documentación de la función leveneTest del paquete car, y con ella evaluar por medio de la prueba de Brown-Forsyth si las varianzas de los errores de los dos tipos de escuela (privada y pública) de la base de datos hsb cumplen con el supuesto de varianza constante de los errores. Suponga un nivel de significancia igual a 0.05. Solución. Para acceder a la documentación de ayuda de la función leveneTest del paquete car: help(&quot;leveneTest&quot;, package = &quot;car&quot;) Dicha documentación indica que el argumento y corresponde a la variable respuesta, group corresponde a la variable (factor) al que se desea evaluar la homogeneidad, y center donde se define el estadístico de centralidad. Para el ejemplo: library(car) leveneTest(y = hsb$res_ordinario, group = hsb$schtype, center = &#39;median&#39;) ## Levene&#39;s Test for Homogeneity of Variance (center = &quot;median&quot;) ## Df F value Pr(&gt;F) ## group 1 20.102 7.456e-06 *** ## 7183 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Por lo tanto como el valor-P (7.456e-06) fue menor al nivel de significancia (0.05), se rechaza \\(H_{0}\\), lo que permite concluir que los dos tipos de escuela (privada y pública) presentan diferencias estadísticas significativas en la varianza de los errores. 11.3.4 Distribución normal de los residuos mediante inferencia visual Los análisis de normalidad, también denominados como contraste de normalidad, son otro tipo de supuesto del modelo de regresión. Al igual que el supuesto de varianza constante de los residuos, en el análisis de normalidad se suele emplear representaciones gráficas. Esta representación consiste en la gráfica de probabilidad normal de los residuos, también denominada como gráfico cuantil cuantil. A continuación podrá observar un ejemplo de dichas representaciones en el caso del cumplimiento o no del supuesto de normalidad: Figure 11.9: Ejemplo de distribución normal de los residuos y de aquellos residuos que no cumplen con este supuesto. Si se cumple el supuesto de normalidad de los residuos, los puntos que constituyen la gráfica de probabilidad normal deberían alinearse entorno a la línea recta, como se puede observar en la figura 6.9 A (a la izquierda). Esta interpretación se evidencia al representar su equivalente mediante un histograma (figura 6.9 A a la derecha). Las posibles causas de alejamiento a la normalidad se mencionan a continuación: La variable respuesta podría tener muchos valores pequeños y pocos valores grandes, dando una representación de asimetría positiva (figura 6.9 B), o lo contrario, pocos valores pequeños y muchos valores grandes (asimetría negativa); Al ajustarse el modelo y representar los residuos resultantes mediante un histograma, se podría observar una distribución de colas livianas producto de obtener pocos residuos de gran magnitud (figura 6.9 C), o bien, muchos residuos de gran magnitud podría conducir a una distribución de colas pesadas. El gráfico cuantil cuantil tiene dos ejes, uno para los cuantiles que se generan a partir del conjunto de datos (cuantiles de la distribución observada) y uno para los cuantiles generados a partir de la distribución normal (cuantiles teóricos de la distribución normal). En el ejemplo planteado usando la base de datos hsb, la gráfica de probabilidad normal de los residuos se muestra en la figura a continuación. Figure 11.10: Gráfico cuantil cuantil para el modelo de efectos mixtos previamente ajustado. En relación al código presentado anteriormente, tenga en cuenta lo siguiente: En la asignación estética (aes) usando el paquete ggplot2, se proporcionó los residuos pearson (aquí subrayados en color azul), datos que se obtuvieron mediante previo ajuste del modelo; A partir de la función stat_qq (aquí subrayado en color amarillo), se dibuja la línea de puntos el cual indica la ubicación de los datos de acuerdo a los cuantiles de la distribución normal y de la distribución observada; Con la función stat_qq_line (aquí subrayado en color amarillo), se dibuja una línea recta. Si los puntos estan cerca a la misma, significa que los datos y la distribución normal tienen cuantiles comparables y se cumple el supuesto de normalidad de los residuos. Ejemplo En algunos casos es deseable identificar la distribución que siguen los datos en lugar de identificar la distribución que no siguen. Aswath Damodaran en el documento probabilistic approaches: scenario analysis, decision trees and simulation discute las características clave de las distribuciones más comunes, y en una de las figuras presentadas en dicho documento proporciona un diagrama de árbol para elegir una distribución. Un ejemplo del mismo (para datos continuos) se presenta a continuación: Figure 11.11: Diagrama de árbol para elegir el tipo de distribución de los datos, adaptado de Aswath Damodaran. Al observar la figura 6.10 se puede concluir que el rendimiento en la evaluación en la prueba de matemáticas (mathach) de la base de datos hsb no cumple el supuesto de normalidad, una vez se aprecia que los puntos no están del todo alineados entorno a la recta, observándose unas ligeras desviaciones en las colas. En este sentido y haciendo uso del diagrama de árbol presentado con anterioridad, elija la distribución que más se acerca a la distribución presentada por dicho datos. Para ello le puede resultar útil construir un histograma. Solución. ggplot(data = hsb, aes(x = res_pearson)) + geom_histogram(aes(y = ..density..), bins = 8, colour = &quot;yellow&quot;, fill = &quot;yellow&quot;, alpha = 0.4) + geom_density(size = 1.0, colour = &quot;black&quot;) + labs(x = &quot;Residuos Pearson&quot;, y = &quot;Frecuencia&quot;) + theme_bw() + theme(axis.text = element_text(size = 12, face = &quot;bold&quot;), axis.title = element_text(size = 12, face = &quot;bold&quot;), plot.title = element_text(size = 12, face = &quot;bold&quot;)) Figure 11.12: . Verificar la distribución de los datos es uno de los primeros pasos en el análisis de datos. Al conocer dicha distribución se obtiene información sobre algunas de las propiedades estadísticas de los datos, las cuales se vuelven útiles, por ejemplo, cuando se necesita justificar si una prueba estadística en particular es apropiada. 11.3.5 Distribución normal de los residuos mediante prueba de hipótesis En el supuesto de normalidad de los residuos es posible realizar contraste de hipótesis que determinan si los datos siguen una distribución normal. Al igual que el supuesto de varianza constante, la prueba de distribución normal tiene una hipótesis nula (\\(H_{0}\\)) y una hipótesis alternativa (\\(H_{A}\\)): \\[H_{0}: e \\sim N(0, \\sigma^{2})\\] \\[H_{A}: e \\nsim N(0, \\sigma^{2})\\] Así, \\(H_{0}\\) (la hipótesis nula) sugiere una distribución normal de los residuos. A continuación se mencionan algunas de las pruebas estadísticas usadas para comprobar la validez del supuesto de normalidad de los residuos: Prueba Función en R Paquete en R Shapiro-Wilk shapiro.test stats Kolmogorov-Smirnov ks.test stats Lillefors lillie.test nortest Jarque-Bera jarque.bera.test tseries De las anteriores pruebas de distribución, un valor-P menor a un nivel de significancia previamente definido indica el rechazo de la hipótesis nula, lo que permite concluir que los datos no siguen la distribución normal de los residuos. En relación a los resultados de las pruebas de normalidad, es importante tener en cuenta que al tratarse de valores-P, cuanto mayor es el tamaño de la muestra más poder estadístico tienen y más fácil es encontrar evidencias en contra de la hipótesis nula. Al mismo tiempo, cuanto mayor es el tamaño de la muestra, menos sensible es la prueba a la falta de normalidad. Por esta razón, es importante no basar las conclusiones únicamente en el valor-P de la prueba, sino también considerar la representación gráfica y el tamaño de la muestra. "],["blobs.html", "12 Otro material interesante", " 12 Otro material interesante En este capítulo se listan algunos blogs y publicaciones interesantes relacionados con modelos mixtos. A Practical Guide to Mixed Models in R. Introduction to linear mixed models. "],["references.html", "References", " References "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
